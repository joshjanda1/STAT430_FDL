{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw04-joshlj2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKG2r_QRX5Px",
        "colab_type": "text"
      },
      "source": [
        "# Overview \n",
        "\n",
        "Please see the [homework policy](https://fdl.thecoatlessprofessor.com/syllabus/#homework)\n",
        "for detailed instructions and some grading notes. Failure to follow instructions\n",
        "will result in point reductions. In particular, make sure to commit each \n",
        "exercise as you complete them. \n",
        "\n",
        "> \"Machine intelligence is the last invention that humanity will ever need to make.\"\n",
        ">\n",
        "> -- Nick Bostrom\n",
        "\n",
        "## Grading\n",
        "\n",
        "The rubric CAs will use to grade this assignment is:\n",
        "\n",
        "| Task                                                   | Pts |\n",
        "|:-------------------------------------------------------|----:|\n",
        "| Making a Homemade Neural Network from Scratch!         | 100 |\n",
        "| Cruisin' Keras                                         | 20  |\n",
        "| PyTorch et al are friends not food                     | 30  |\n",
        "| Total                                                  | 150 |\n",
        "\n",
        "## Objectives \n",
        "\n",
        "The objectives behind this homework assignment are as follows:\n",
        "\n",
        "- Implement functions in Python;\n",
        "- Constructing neural networks;\n",
        "- Designing PyTorch modules; and\n",
        "- Establishing sequential layers with Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XEKpojMyMB1",
        "colab_type": "text"
      },
      "source": [
        "# Assignment - Homework 4\n",
        "STAT 430 - FDL, Spring 2020\n",
        "\n",
        "Due: **Sunday, April 12th, 2020 at 6:00 PM**\n",
        "\n",
        "- **Author:** Josh Janda\n",
        "- **NetID:** joshlj2\n",
        "\n",
        "### Collaborators\n",
        "\n",
        "If you worked with any other student in preparing these answers, please\n",
        "make sure to list their full names and NetIDs (e.g. `FirstName LastName (NetID)` ).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5YYth3yyVsm",
        "colab_type": "code",
        "outputId": "f7923871-afda-40b7-a31a-7964b06c69a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(\"Diagnostics: \")\n",
        "\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  is_google_colab = True\n",
        "  import sys\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "\n",
        "  %tensorflow_version 2.x\n",
        "  import tensorflow as tf\n",
        "\n",
        "  import torch\n",
        "  import torch.nn as nn\n",
        "  import torch.nn.functional as F\n",
        "  import torch.optim as optim\n",
        "  from torchvision import datasets, transforms\n",
        "  from torch.optim.lr_scheduler import StepLR\n",
        "  # Detect if a GPU is present with CUDA support\n",
        "  use_cuda = torch.cuda.is_available()\n",
        "\n",
        "  print(f\"python: {sys.version}\")\n",
        "  print(f\"pandas: {np.__version__}\")\n",
        "  print(f\"tensorflow: {tf.__version__}\")\n",
        "  print(f\"pytorch: {torch.__version__}\")\n",
        "  print(f\"GPU Enabled: {use_cuda}\")\n",
        "  print(\"Notebook is on Google CoLab\")\n",
        "except:\n",
        "  is_google_colab = False\n",
        "  print(\"Notebook is being run locally or through another source.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diagnostics: \n",
            "python: 3.6.9 (default, Nov  7 2019, 10:44:02) \n",
            "[GCC 8.3.0]\n",
            "pandas: 1.18.2\n",
            "tensorflow: 2.2.0-rc2\n",
            "pytorch: 1.4.0\n",
            "GPU Enabled: True\n",
            "Notebook is on Google CoLab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaHGju8mV4ER",
        "colab_type": "text"
      },
      "source": [
        "## [50 points] Exercise 1 - Making a Homemade Neural Network from Scratch!\n",
        "\n",
        "In this exercise block, we'll build a neural network that consists of two hidden layers and an output layer.\n",
        "\n",
        "In the first and second hidden layers, there will be _unknown_ number of neurons. Let the neurons in the first hidden layer be denoted as $n_j^{(1)}$. Within the second hidden layer and output layer, let there be $n_c^{(2)}$ neurons. Both hidden layers should include a bias term to make the counts respectively $n_j^{(1)} + 1$ and $n_c^{(2)} + 1$.  For the non-linear activation functions, let the first hidden layer use \n",
        "$g^{(1)} (x) = \\mathrm{ReLU}(x)$, the second hidden layer be $g^{(2)} (x) = \\sigma(x)$. Finally, in the output layer, apply the $\\mathrm{softmax}(x)$ to obtain exactly $n_c^{(2)}$ neurons that correspond to $C$ classes. \n",
        "\n",
        "We'll use the categorical cross-entropy cost function of \n",
        "\n",
        "$$\n",
        "J\\left(\\boldsymbol{W}\\right) = -\\frac{1}{N} \\sum_{i=1}^{N} { \\sum_{c=1}^{C} { y_{ic} \\log\\left({ \\hat y_{ic} }\\right)  }}\n",
        "$$\n",
        "\n",
        "where,\n",
        "\n",
        "- $\\boldsymbol{W}$ represents the weights of the neural network -- including the bias term,\n",
        "- $N$ represents the number of examples the network is being trained with,\n",
        "- $y_{ic}$ is the true label in $c \\in C$, and;\n",
        "- $\\hat y_{ic}$ is the predicted label probability in $c \\in C$.\n",
        "\n",
        "Within this part, we'll construct functions that: \n",
        "\n",
        "1. Initialize the parameters of the network.\n",
        "1. Train\n",
        "  - Perform forward propagation\n",
        "  - Compute cost function\n",
        "  - Perform backward propagation\n",
        "  - Update network parameters\n",
        "1. Predict\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAJAIGQUgtpr",
        "colab_type": "text"
      },
      "source": [
        "### (a) (10 points) Sketching the computational graph\n",
        "\n",
        "Sketch the computational graph for the described neural network. For each layer on the graph, write out the forward propagation equations in matrix equation form. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-jwPNmRhKC6",
        "colab_type": "text"
      },
      "source": [
        "![](https://i.imgur.com/SQR5AVT.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T_HQIIwmuB2",
        "colab_type": "text"
      },
      "source": [
        "### (b) (10 points) Deriving the backward propagation equations\n",
        "\n",
        "Within this step, derive the backward propagation equations for the network\n",
        "by obtaining the necessary partial derivatives.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU4h_HGrmr_Y",
        "colab_type": "text"
      },
      "source": [
        "![](https://i.imgur.com/6xJ8fpA.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB3jHSalEfPl",
        "colab_type": "text"
      },
      "source": [
        "### (c) (5 points) Training Data Reshaping\n",
        "\n",
        "Reshaping data is a common requirement for working with neural networks. Previously, the assumption about data in neural networks\n",
        "was that there is exactly _one_ example or image. In practice, there needs to\n",
        "be a large amount of data for the neural network to function. Previously, $X$ was defined to be a single input vector: \n",
        "\n",
        "$$\n",
        "X_{m \\times 1} = \\begin{bmatrix}\n",
        "\\vert \\\\\n",
        "X^{[1]}  \\\\\n",
        "\\vert  \\\\\n",
        "\\end{bmatrix}_{m \\times 1}\n",
        "$$\n",
        "\n",
        "To enable multiple training examples, let's define $X$ to be:\n",
        "\n",
        "$$\n",
        "X_{m \\times n_e} = \\begin{bmatrix}\n",
        "\\vert & \\vert & \\vert \\\\\n",
        "X^{[1]} & X^{[2]} & X^{[3]} \\\\\n",
        "\\vert & \\vert & \\vert \\\\\n",
        "\\end{bmatrix}_{m \\times n_e}\n",
        "$$\n",
        "\n",
        "where $m$ is the number of inputs and $n_e$ is the number of observations. Therefore, $Z^{(1)}$ would now look like:\n",
        "\n",
        "$$\n",
        "Z^{(1)} = \\begin{bmatrix}\n",
        "\\vert & \\vert & \\vert \\\\\n",
        "Z^{(1)[1]} & Z^{(1)[2]} & Z^{(1)[3]} \\\\\n",
        "\\vert & \\vert & \\vert \\\\\n",
        "\\end{bmatrix}_{n_h \\times n_e}\n",
        "$$\n",
        "\n",
        "Let the parentheses -- $()$ -- denote the layer number and the square brackets\n",
        "-- $[]$ -- be the training data example.\n",
        "\n",
        "Having said this, please reshape the MNIST training data from:\n",
        "\n",
        "$$\\text{Examples }\\times \\text{Height } \\times \\text{Width }$$\n",
        "\n",
        "To being shaped as:\n",
        "\n",
        "$$\\underbrace{\\left(\\text{Height } \\cdot \\text{Width }\\right)}_{=m} \\times \\underbrace{\\text{Examples }}_{=n_e}$$\n",
        "\n",
        "\n",
        "Through this process, the data is being flattened:\n",
        "\n",
        "$$\\underbrace{\\left(\\text{Height } \\cdot \\text{Width }\\right)}_{=m}$$\n",
        "\n",
        "_Hints:_\n",
        "\n",
        "- Change a data's shape is possible with [`np.reshape(data, (-1, data.shape[0]))`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html#numpy.reshape)\n",
        "- Arrays can be transposed with [`data.T`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.T.html)\n",
        "\n",
        "When in doubt, work with a small example first, before the full data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOuMoDie0qvo",
        "colab_type": "code",
        "outputId": "4434ca7b-a2fd-4a49-8049-7acf95416f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# Not graded code, acts a small test case\n",
        "import numpy as np\n",
        "a = np.arange(24).reshape((4, 3, 2))\n",
        "print(f\"Contents of `a`:\\n {a}\\n\")\n",
        "print(f\"Dimensions of `a`:\\n {a.shape}\\n\")\n",
        "\n",
        "b = np.arange(3)\n",
        "print(f\"Contents of `b`:\\n {b}\\n\")\n",
        "print(f\"Dimensions of `b`:\\n {b.shape}\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Contents of `a`:\n",
            " [[[ 0  1]\n",
            "  [ 2  3]\n",
            "  [ 4  5]]\n",
            "\n",
            " [[ 6  7]\n",
            "  [ 8  9]\n",
            "  [10 11]]\n",
            "\n",
            " [[12 13]\n",
            "  [14 15]\n",
            "  [16 17]]\n",
            "\n",
            " [[18 19]\n",
            "  [20 21]\n",
            "  [22 23]]]\n",
            "\n",
            "Dimensions of `a`:\n",
            " (4, 3, 2)\n",
            "\n",
            "Contents of `b`:\n",
            " [0 1 2]\n",
            "\n",
            "Dimensions of `b`:\n",
            " (3,)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfUQFLEhjvpO",
        "colab_type": "code",
        "outputId": "3141f1dc-ad82-4f30-d985-527c88421641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "# Load the MNIST data via a helper\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "# Perform scaling\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 784).T\n",
        "x_test = x_test.reshape(x_test.shape[0], 784).T\n",
        "\n",
        "# Grading helper:\n",
        "print(f'X has dimensions: {x_train.shape}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "X has dimensions: (784, 60000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jPbd7Mayonm",
        "colab_type": "text"
      },
      "source": [
        "### (d) (5 points) Test Data Reshaping\n",
        "\n",
        "Encode the label data ($Y$) using one-hot encoding. \n",
        "\n",
        "The data has the following labels:\n",
        "\n",
        "| Label|Class       |\n",
        "|-----:|:-----------|\n",
        "|     0|T-shirt/top |\n",
        "|     1|Trouser     |\n",
        "|     2|Pullover    |\n",
        "|     3|Dress       |\n",
        "|     4|Coat        |\n",
        "|     5|Sandal      |\n",
        "|     6|Shirt       |\n",
        "|     7|Sneaker     |\n",
        "|     8|Bag         |\n",
        "|     9|Ankle boot  |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZfyz4od8oVl",
        "colab_type": "code",
        "outputId": "b67f8ef0-4cac-4248-b714-d7be52e9390f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_train_ohc = tf.keras.utils.to_categorical(y_train)   \n",
        "y_test_ohc = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "# Grading helper\n",
        "print(f'Y has dimensions: {y_train_ohc.shape}')\n",
        "print(f'Number of Images: {y_train_ohc.shape[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y has dimensions: (60000, 10)\n",
            "Number of Images: 60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tOycmv9RKeF",
        "colab_type": "text"
      },
      "source": [
        "### (e) (5 points) He initialization\n",
        "\n",
        "Create a function to initialize weight parameters for a given layer in the neural network. The weight initialization should use [He's initialization](https://arxiv.org/abs/1502.01852) given by:\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "W &\\sim N(0, 1) \\\\\n",
        "W &:= W\\sqrt{\\frac{2}{n^{(l-1)}}}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "where $N(0,1)$ is the standard normal distribution, $n^{(l-1)}$ denotes the number of input weights, and $n^{(l)}$ is the\n",
        "number of output weights.\n",
        "\n",
        "Implementation Guidelines:\n",
        "\n",
        "- **Arguments:**\n",
        "    - `n_in`: Number of input weights\n",
        "    - `n_out`: Number of output weights\n",
        "- **Return:**\n",
        "    - `W` a matrix of dimension $n^{(l)} \\times n^{(l-1)}$\n",
        "\n",
        "_Hints:_ NumPy has a built in way of generating random data with [`np.random.randn(n, p)`](https://numpy.org/doc/1.18/reference/random/generated/numpy.random.randn.html)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOCkiOCVHyUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def he_initializer(n_in, n_out):\n",
        "\n",
        "  W = np.random.randn(n_out, n_in)\n",
        "  W *= np.sqrt(2 / (n_in))\n",
        "\n",
        "  return W"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_ljdhD5RNyR",
        "colab_type": "text"
      },
      "source": [
        "### (f) (5 points) Parameter Initialization\n",
        "\n",
        "Using the function in **(e)** construct a function \n",
        "that initializes both the weights and the bias terms for each layer. The bias values should be initialized with 0 and the weights should be initialized with the function developed in **(e)**.\n",
        "\n",
        "Implementation Guidelines:\n",
        "\n",
        "- **Arguments:**\n",
        "    - `m`: Number of input neurons\n",
        "    - `n_h`: Number of hidden neurons\n",
        "    - `n_y`: Number of output neurons\n",
        "- **Return:**\n",
        "    - `cache_parameters` with a dictionary data structure that contains:\n",
        "       - `W^(1)` a matrix of dimension `n_h X m`\n",
        "       - `b^(1)` a matrix of dimension `n_h X 1`\n",
        "       - `W^(2)` a matrix of dimension `n_y X n_h`\n",
        "       - `b^(2)` a matrix of dimension `n_y X 1`\n",
        "\n",
        "_Hint:_ \n",
        "\n",
        "- NumPy has a built in way of generating a zero vector with [`np.zeros((n, p))`](https://numpy.org/doc/1.18/reference/generated/numpy.zeros.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ97Ta3ERNhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialization(m, n_h, n_y):\n",
        "\n",
        "  W1 = he_initializer(m, n_h)\n",
        "  b1 = np.zeros((n_h, 1))\n",
        "\n",
        "  W2 = he_initializer(n_h, n_y)\n",
        "  b2 = np.zeros((n_y, 1))\n",
        "\n",
        "  cache_parameters = {\n",
        "      'W1' : W1, 'b1' : b1,\n",
        "      'W2' : W2, 'b2' : b2\n",
        "      }\n",
        "\n",
        "  return cache_parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1ltf2EIHy17",
        "colab_type": "text"
      },
      "source": [
        "### (g) (10 points) Activation Functions\n",
        "\n",
        "Implement the ReLU, Sigmoid, and Softmax activation functions alongside their derivatives.\n",
        "\n",
        "Implementation Guidelines for each function:\n",
        "\n",
        "- **Arguments:**\n",
        "    - `X` a matrix of dimension `a X b`.\n",
        "- **Return:**\n",
        "    - Appropriately \"activated\" or \"derivative\" matrix of dimension `a X b`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs-Pl34dIDYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(z):\n",
        "  a = np.maximum(0, z)\n",
        "  return a\n",
        "  \n",
        "def relu_prime(z):\n",
        "  prime = np.greater(z, 0).astype(int)\n",
        "  return prime\n",
        "\n",
        "def sigmoid(z):\n",
        "  a = 1 / (1 + np.exp(-z)) \n",
        "  return a\n",
        "\n",
        "def sigmoid_prime(z):\n",
        "  prime = sigmoid(z)*(1 - sigmoid(z))\n",
        "  return prime\n",
        "\n",
        "def softmax(z):\n",
        "  shift = z - np.max(z)\n",
        "  exp_shift = np.exp(shift)\n",
        "  return exp_shift / exp_shift.sum(axis = 0)\n",
        "\n",
        "def softmax_prime(z, y):\n",
        "  return z - y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqyZe-QtIQUU",
        "colab_type": "text"
      },
      "source": [
        "### (h) (10 points) Forward propagation\n",
        "\n",
        "Implement a function that performs the forward propagation\n",
        "and caches (saves) the value computed at each node on the computational graph. \n",
        "\n",
        "Implementation Guidelines:\n",
        "\n",
        "- **Arguments:**\n",
        "    - `X` a matrix of dimension `m X n_e`.\n",
        "    - `cache_parameters` with a dictionary data structure.\n",
        "- **Return:**\n",
        "    - `SM` a matrix of dimension `n_y X n_e`\n",
        "    - `cache_forward` with a dictionary data structure that contains:\n",
        "       - `Z^{(1)}`\n",
        "       - `A^{(1)}`\n",
        "       - `Z^{(2)}`\n",
        "       - `A^{(2)}`\n",
        "       - `SM`\n",
        "\n",
        "_Note:_ $A^{(2)} \\rightarrow SM$ to provide the softmax output that gives $\\hat y$. \n",
        "\n",
        "\n",
        "_Hint:_\n",
        "\n",
        "- Recall that items in a dictionary data structure can be accessed with `data[\"item\"]`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DJCHduKIQsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_prop(x, cache_parameters):\n",
        "  \n",
        "  z1 = cache_parameters['W1'] @ x + cache_parameters['b1'] #64x60000\n",
        "  a1 = relu(z1) #64x60000\n",
        "\n",
        "  z2 = cache_parameters['W2'] @ a1 + cache_parameters['b2'] #10x60000\n",
        "  a2 = sigmoid(z2) #10x60000\n",
        "\n",
        "  sm = softmax(a2) #10x60000\n",
        "  cache_forward = {\n",
        "      'z1' : z1, 'a1' : a1,\n",
        "      'z2' : z2, 'a2' : a2, 'sm' : sm\n",
        "  }\n",
        "  return sm, cache_forward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBjuQYYQRnyK",
        "colab_type": "text"
      },
      "source": [
        "**Why is it important to store the values computed in the prediction step?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1doOOF-JYoVg",
        "colab_type": "text"
      },
      "source": [
        "It is important to store the values computed in the prediction step as we need them to compute the cross-entropy loss function and backprop. All other variables are needed to compute derivatives for backpropogation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkApLxJLRptJ",
        "colab_type": "text"
      },
      "source": [
        "### (i) (10 points) Backward propagation\n",
        "\n",
        "Implement a function that performs the backward propagation\n",
        "at each node on the computational graph. \n",
        "\n",
        "\n",
        "- **Arguments:**\n",
        "    - `Y` a matrix of dimension `1 X n_e`.\n",
        "    - `X` a matrix of dimension `m X n_e`.\n",
        "    - `cache_parameters` a data dictionary.\n",
        "    - `cache_forward` a data dictionary.\n",
        "- **Return:**\n",
        "    - `cache_grad` with a dictionary data structure that contains:\n",
        "       - `dW2`\n",
        "       - `db2`\n",
        "       - `dW1`\n",
        "       - `db1`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3x6MU63SH82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def back_prop(y, x, cache_parameters, cache_forward):\n",
        "\n",
        "  a2_grad = softmax_prime(cache_forward['sm'], y) #10x60000\n",
        "  z2_grad = a2_grad * sigmoid_prime(cache_forward['z2'])\n",
        "  w2_grad = z2_grad @ cache_forward['a1'].T\n",
        "  b2_grad = z2_grad.sum(axis = 1, keepdims = True)\n",
        "  z1_grad = (cache_parameters['W2'].T @ z2_grad) * relu_prime(cache_forward['z1'])\n",
        "  w1_grad = z1_grad @ x_train.T\n",
        "  b1_grad = z1_grad.sum(axis = 1, keepdims = True) #64x1\n",
        "\n",
        "  cache_grad = {\n",
        "      'dW2' : w2_grad, 'db2' : b2_grad,\n",
        "      'dW1' : w1_grad, 'db1' : b1_grad\n",
        "  }\n",
        "\n",
        "  return cache_grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdEVy74LWuzZ",
        "colab_type": "text"
      },
      "source": [
        "### (j) (10 points) Parameter Update\n",
        "\n",
        "With the backward propagation calculations in hand, the\n",
        "next step is to update the parameters in the neural network. The update\n",
        "step should be performed using **Batch Gradient Descent (BGD)**.\n",
        "\n",
        "- **Arguments:**\n",
        "    - `alpha` the learning rate parameter.\n",
        "    - `cache_parameters` a data dictionary containing parameters.\n",
        "    - `cache_forward` a data dictionary containing forward propagation.\n",
        "    - `cache_grad` a data dictionary containing the gradients.\n",
        "- **Return:**\n",
        "    - `cache_parameters` an updated version of the dictionary data structure that contains:\n",
        "       - `W2`\n",
        "       - `b2`\n",
        "       - `W1`\n",
        "       - `b1`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4xL4yL4ZTJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bgd(alpha, cache_parameters, cache_grad):\n",
        "\n",
        "  w2 = cache_parameters['W2']\n",
        "  w2_grad = cache_grad['dW2']\n",
        "  b2 = cache_parameters['b2']\n",
        "  b2_grad = cache_grad['db2']\n",
        "  w1 = cache_parameters['W1']\n",
        "  w1_grad = cache_grad['dW1']\n",
        "  b1 = cache_parameters['b1']\n",
        "  b1_grad = cache_grad['db1']\n",
        "\n",
        "  w2 = w2 - (alpha * w2_grad)\n",
        "  b2 = b2 - (alpha * b2_grad)\n",
        "  w1 = w1 - (alpha * w1_grad)\n",
        "  b1 = b1 - (alpha * b1_grad)\n",
        "\n",
        "  cache_parameters = {\n",
        "      'W2' : w2, 'b2' : b2,\n",
        "      'W1' : w1, 'b1' : b1\n",
        "  }\n",
        "  return cache_parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW1eYDOqZX7X",
        "colab_type": "text"
      },
      "source": [
        "### (k) (10 points) Train the model\n",
        "\n",
        "Create a function that encases all of the prior functions. This function should\n",
        "perform the training and provide side-effects of the training process. \n",
        "\n",
        "- **Arguments:**\n",
        "    - `Y` a matrix of dimension `n_e X C`.\n",
        "    - `X` a matrix of dimension `m X n_e`.\n",
        "    - `n_h` number of neurons in the hidden layer.\n",
        "    - `alpha` the learning rate parameter. Default `1e-4`. (Check)\n",
        "    - `epochs` the total number of times to train. Default `100000`.\n",
        "- **Side-effect**\n",
        "    - Every 1000 iterations output the iteration number and the present cost.\n",
        "- **Return:**\n",
        "    - `cost_history` the cost values from each iteration of the training step.\n",
        "    - `cache_parameters` with a dictionary data structure that contains:\n",
        "       - `W2`\n",
        "       - `b2`\n",
        "       - `W1`\n",
        "       - `b1`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZILJ40lqfxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_entropy(actual, predictions):\n",
        "\n",
        "  N = predictions.shape[1]\n",
        "  cross_entropy = -np.sum(actual*np.log(predictions + 1e-12)) / N\n",
        "\n",
        "  return cross_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F27T8jPZYVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(X, y, n_h, alpha = 1e-4, epochs = 1000):\n",
        "\n",
        "  cache_parameters = initialization(X.shape[0], n_h, y.shape[0])\n",
        "  cost_history = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    sm, cache_forward = forward_prop(X, cache_parameters)\n",
        "    cache_grad = back_prop(y, X, cache_parameters, cache_forward)\n",
        "    cache_parameters = bgd(alpha, cache_parameters, cache_grad)\n",
        "    cost = cross_entropy(y, sm)\n",
        "    cost_history.append(cost)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "\n",
        "      print(f'Iteration: {epoch} - Cost: {cost}')\n",
        "    \n",
        "  return cost_history, cache_parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur07yy0ZvXKN",
        "colab_type": "text"
      },
      "source": [
        "### (l) (5 points) Build the model and visualize it!\n",
        "\n",
        "In this exercise, perform the full network training on the MNIST Fashion data.\n",
        "Retrieve and visualize the cost function history across the number of epochs. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on-b7AATvYH2",
        "colab_type": "code",
        "outputId": "8ddb12b6-74b3-451c-c9c7-44c699088b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#10000 epochs as training times out before reaching 100k..\n",
        "cost_history, cache_parameters = train(x_train, y_train_ohc.T, 64, alpha = 1e-4, epochs = 10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0 - Cost: 2.2950560073279975\n",
            "Iteration: 100 - Cost: 1.6563021955594983\n",
            "Iteration: 200 - Cost: 1.6353553401222127\n",
            "Iteration: 300 - Cost: 1.6213732677745065\n",
            "Iteration: 400 - Cost: 1.5987370745203262\n",
            "Iteration: 500 - Cost: 1.5955406768269325\n",
            "Iteration: 600 - Cost: 1.5944810358621841\n",
            "Iteration: 700 - Cost: 1.58339463775358\n",
            "Iteration: 800 - Cost: 1.593317927640202\n",
            "Iteration: 900 - Cost: 1.583247645617192\n",
            "Iteration: 1000 - Cost: 1.575121934781817\n",
            "Iteration: 1100 - Cost: 1.5742055174608556\n",
            "Iteration: 1200 - Cost: 1.5727115150489959\n",
            "Iteration: 1300 - Cost: 1.5741837995163437\n",
            "Iteration: 1400 - Cost: 1.5707001362781279\n",
            "Iteration: 1500 - Cost: 1.5688217394917605\n",
            "Iteration: 1600 - Cost: 1.5684912554111778\n",
            "Iteration: 1700 - Cost: 1.5661127259640737\n",
            "Iteration: 1800 - Cost: 1.565123566591059\n",
            "Iteration: 1900 - Cost: 1.5678863915973347\n",
            "Iteration: 2000 - Cost: 1.5631998725282332\n",
            "Iteration: 2100 - Cost: 1.5625862243422515\n",
            "Iteration: 2200 - Cost: 1.5621043321216412\n",
            "Iteration: 2300 - Cost: 1.5622762783385138\n",
            "Iteration: 2400 - Cost: 1.559600190647226\n",
            "Iteration: 2500 - Cost: 1.5612212523733124\n",
            "Iteration: 2600 - Cost: 1.5587453199292272\n",
            "Iteration: 2700 - Cost: 1.5579113993617357\n",
            "Iteration: 2800 - Cost: 1.5594716471391177\n",
            "Iteration: 2900 - Cost: 1.556350511116691\n",
            "Iteration: 3000 - Cost: 1.5588410163759092\n",
            "Iteration: 3100 - Cost: 1.5415132049729214\n",
            "Iteration: 3200 - Cost: 1.5341260100403993\n",
            "Iteration: 3300 - Cost: 1.5355128914317782\n",
            "Iteration: 3400 - Cost: 1.5317783093049033\n",
            "Iteration: 3500 - Cost: 1.5357521277095043\n",
            "Iteration: 3600 - Cost: 1.5301797657674292\n",
            "Iteration: 3700 - Cost: 1.5318872930731346\n",
            "Iteration: 3800 - Cost: 1.5285203636712712\n",
            "Iteration: 3900 - Cost: 1.5298176415699667\n",
            "Iteration: 4000 - Cost: 1.5279334439987204\n",
            "Iteration: 4100 - Cost: 1.5289983223368009\n",
            "Iteration: 4200 - Cost: 1.5265873674508044\n",
            "Iteration: 4300 - Cost: 1.5258621770147023\n",
            "Iteration: 4400 - Cost: 1.5253733188128191\n",
            "Iteration: 4500 - Cost: 1.5277005469881468\n",
            "Iteration: 4600 - Cost: 1.5256741231941926\n",
            "Iteration: 4700 - Cost: 1.527092509120954\n",
            "Iteration: 4800 - Cost: 1.526966899003282\n",
            "Iteration: 4900 - Cost: 1.5218301030131187\n",
            "Iteration: 5000 - Cost: 1.5243830001538\n",
            "Iteration: 5100 - Cost: 1.5260374566150072\n",
            "Iteration: 5200 - Cost: 1.522316859886519\n",
            "Iteration: 5300 - Cost: 1.5229732724833318\n",
            "Iteration: 5400 - Cost: 1.5237986519660724\n",
            "Iteration: 5500 - Cost: 1.5232293642275465\n",
            "Iteration: 5600 - Cost: 1.5250679496862953\n",
            "Iteration: 5700 - Cost: 1.5204301678201868\n",
            "Iteration: 5800 - Cost: 1.5199499636878242\n",
            "Iteration: 5900 - Cost: 1.5197790948940826\n",
            "Iteration: 6000 - Cost: 1.5233889142652484\n",
            "Iteration: 6100 - Cost: 1.5227411907905712\n",
            "Iteration: 6200 - Cost: 1.5184329915396582\n",
            "Iteration: 6300 - Cost: 1.5192176021548724\n",
            "Iteration: 6400 - Cost: 1.523227714135928\n",
            "Iteration: 6500 - Cost: 1.517581637048624\n",
            "Iteration: 6600 - Cost: 1.5204796914627057\n",
            "Iteration: 6700 - Cost: 1.5178286905977298\n",
            "Iteration: 6800 - Cost: 1.5171186348828785\n",
            "Iteration: 6900 - Cost: 1.5168926113332697\n",
            "Iteration: 7000 - Cost: 1.518975448047925\n",
            "Iteration: 7100 - Cost: 1.5173910773160146\n",
            "Iteration: 7200 - Cost: 1.5245817961447707\n",
            "Iteration: 7300 - Cost: 1.517054809756833\n",
            "Iteration: 7400 - Cost: 1.5177581990515416\n",
            "Iteration: 7500 - Cost: 1.5151177832774256\n",
            "Iteration: 7600 - Cost: 1.5141106728049911\n",
            "Iteration: 7700 - Cost: 1.5145943698370223\n",
            "Iteration: 7800 - Cost: 1.5158830784270287\n",
            "Iteration: 7900 - Cost: 1.5138591811490802\n",
            "Iteration: 8000 - Cost: 1.5136533655603412\n",
            "Iteration: 8100 - Cost: 1.5137717242335196\n",
            "Iteration: 8200 - Cost: 1.5139039210365834\n",
            "Iteration: 8300 - Cost: 1.512489659644522\n",
            "Iteration: 8400 - Cost: 1.5126114253185015\n",
            "Iteration: 8500 - Cost: 1.515756293301596\n",
            "Iteration: 8600 - Cost: 1.5120540679483019\n",
            "Iteration: 8700 - Cost: 1.5180969705636045\n",
            "Iteration: 8800 - Cost: 1.5157758642879788\n",
            "Iteration: 8900 - Cost: 1.5173991556847988\n",
            "Iteration: 9000 - Cost: 1.5114623498831425\n",
            "Iteration: 9100 - Cost: 1.5131663920819054\n",
            "Iteration: 9200 - Cost: 1.511050710552531\n",
            "Iteration: 9300 - Cost: 1.5111101952093033\n",
            "Iteration: 9400 - Cost: 1.5141509715037316\n",
            "Iteration: 9500 - Cost: 1.5120142819870257\n",
            "Iteration: 9600 - Cost: 1.5125231635213967\n",
            "Iteration: 9700 - Cost: 1.516624100392893\n",
            "Iteration: 9800 - Cost: 1.5203219841092999\n",
            "Iteration: 9900 - Cost: 1.510289591077175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJxkbLXVv_Ou",
        "colab_type": "code",
        "outputId": "62fd5d3b-a18f-40a9-e7a4-4328945211dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "# Must have variable named as `cost_history` with 1 dimension.\n",
        "plt.plot(cost_history)\n",
        "plt.ylabel('Cost Function')\n",
        "plt.xlabel('Number of Iterations')\n",
        "plt.title('Network Training Overview')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tImazUr9YJ-T",
        "colab_type": "text"
      },
      "source": [
        "### (m) (5 points) Predict!\n",
        "\n",
        "Use the model parameters obtained from training the network in **(i)** to make predictions on the data. Consider creating a prediction function to aide in this\n",
        "task.\n",
        "\n",
        "- **Arguments:**\n",
        "    - `Y` a matrix of dimension `n_e X K`.\n",
        "    - `X` a matrix of dimension `m X n_e`.\n",
        "    - `cache_parameters` a dictionary data structure that contains estimated parameters.\n",
        "- **Return:**\n",
        "    - `prediction` predicted values\n",
        "\n",
        "_Hint:_ Logic for this was rewritten during the forward propagation step. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP26WRk3a5mR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(X, cache_parameters):\n",
        "\n",
        "  sm, _ = forward_prop(X, cache_parameters)\n",
        "  predictions = sm.argmax(axis = 0)\n",
        "\n",
        "  return predictions\n",
        "\n",
        "predictions = predict(x_test, cache_parameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlJNt2w7a7GX",
        "colab_type": "text"
      },
      "source": [
        "The following should be used to show the image alongside of its predicted\n",
        "class.\n",
        "\n",
        "Note: \n",
        "\n",
        "- [`np.argmax(data)`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html) returns the index of the highest value.\n",
        "- [`np.max(data)`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.max.html) returns the highest value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1mGiMjfYXfd",
        "colab_type": "code",
        "outputId": "464ce4b1-f58d-4d03-8252-1a7313e3b5f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fashion_mnist_viz = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "# Load the MNIST data via a helper\n",
        "(x_train_viz, y_train_viz), (x_test_viz, y_test_viz) = fashion_mnist_viz.load_data()\n",
        "# Perform scaling\n",
        "x_train_viz, x_test_viz = x_train_viz / 255.0, x_test_viz / 255.0\n",
        "\n",
        "# Set seed for reproducibility\n",
        "################################################\n",
        "# Change to the last four digits of your UIN\n",
        "################################################\n",
        "np.random.seed(8173)\n",
        "\n",
        "# Obtain a set of indices to obtain predictions\n",
        "idx = list(np.random.randint(x_test_viz.shape[1], size = 10))\n",
        "\n",
        "for i in range(10):\n",
        "  obs = idx[i]                      # Retrieve the index\n",
        "  plt.subplot(2, 5, i+1)            # Create a subplot\n",
        "  img = x_test_viz[obs].reshape((28,28))# Examples x Width x Height\n",
        "  pred = predictions[i]\n",
        "  plt.imshow(img, cmap='gray')      # Plot gray scale\n",
        "  plt.title(f'ID: {obs} \\n Act: {y_test_viz[obs]}\\n Pred: {pred} ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bxhSMXWfD5O",
        "colab_type": "text"
      },
      "source": [
        "## [20 points] Exercise 2 - Cruisin' Keras!\n",
        "\n",
        "In this exercise block, we'll implement the same neural network from **Exercise 1** but using Keras. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llUnqwrSfLyA",
        "colab_type": "text"
      },
      "source": [
        "### (a) (10 points) Structuring a model in keras\n",
        "\n",
        "Structure a two-layer sequential model in Keras that mirrors the guidelines in **Exercise 1**. Show the model layer information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrGut3Q8gsrA",
        "colab_type": "code",
        "outputId": "f4adfc53-9daf-4e63-867d-afa6a7841f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "                                 keras.layers.InputLayer(input_shape = [784], name = 'input'),\n",
        "                                 keras.layers.Dense(64, kernel_initializer = 'he_normal', activation = 'relu', name = 'relu'),\n",
        "                                 keras.layers.Dense(10, kernel_initializer = 'he_normal', activation = 'sigmoid', name = 'sigmoid'),\n",
        "                                 keras.layers.Activation('softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "relu (Dense)                 (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "sigmoid (Dense)              (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdgvsQGpfdZn",
        "colab_type": "text"
      },
      "source": [
        "### (b) (10 points) Model Training\n",
        "\n",
        "Train the neural network within Keras. Training should be done in a similar \n",
        "manner to **Exercise 1 (j) and (k)**. Unlike before, please construct a graph that shows training and test behavior. This information is available on\n",
        "the `model.fit` call."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgc-msBhgtRQ",
        "colab_type": "code",
        "outputId": "1b2f21f2-0082-465b-9519-ab226f2538dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = keras.optimizers.SGD(learning_rate = 1e-4),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "# Perform scaling\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 784)\n",
        "x_test = x_test.reshape(x_test.shape[0], 784)\n",
        "#10000 epochs as training times out before finishing 100k...\n",
        "history = model.fit(x_train, y_train_ohc, batch_size = x_train.shape[0], epochs = 10000, validation_data = (x_test, y_test_ohc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2181 - accuracy: 0.2798 - val_loss: 2.2199 - val_accuracy: 0.2724\n",
            "Epoch 7502/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2181 - accuracy: 0.2798 - val_loss: 2.2199 - val_accuracy: 0.2724\n",
            "Epoch 7503/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2181 - accuracy: 0.2799 - val_loss: 2.2199 - val_accuracy: 0.2726\n",
            "Epoch 7504/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2181 - accuracy: 0.2799 - val_loss: 2.2199 - val_accuracy: 0.2726\n",
            "Epoch 7505/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2180 - accuracy: 0.2799 - val_loss: 2.2199 - val_accuracy: 0.2726\n",
            "Epoch 7506/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2180 - accuracy: 0.2799 - val_loss: 2.2199 - val_accuracy: 0.2726\n",
            "Epoch 7507/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2180 - accuracy: 0.2799 - val_loss: 2.2199 - val_accuracy: 0.2726\n",
            "Epoch 7508/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2180 - accuracy: 0.2800 - val_loss: 2.2199 - val_accuracy: 0.2726\n",
            "Epoch 7509/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2180 - accuracy: 0.2800 - val_loss: 2.2198 - val_accuracy: 0.2726\n",
            "Epoch 7510/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2180 - accuracy: 0.2801 - val_loss: 2.2198 - val_accuracy: 0.2726\n",
            "Epoch 7511/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2180 - accuracy: 0.2801 - val_loss: 2.2198 - val_accuracy: 0.2726\n",
            "Epoch 7512/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2180 - accuracy: 0.2801 - val_loss: 2.2198 - val_accuracy: 0.2726\n",
            "Epoch 7513/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2180 - accuracy: 0.2801 - val_loss: 2.2198 - val_accuracy: 0.2726\n",
            "Epoch 7514/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2180 - accuracy: 0.2801 - val_loss: 2.2198 - val_accuracy: 0.2726\n",
            "Epoch 7515/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2180 - accuracy: 0.2802 - val_loss: 2.2198 - val_accuracy: 0.2726\n",
            "Epoch 7516/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2179 - accuracy: 0.2802 - val_loss: 2.2198 - val_accuracy: 0.2726\n",
            "Epoch 7517/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2179 - accuracy: 0.2803 - val_loss: 2.2198 - val_accuracy: 0.2726\n",
            "Epoch 7518/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2179 - accuracy: 0.2803 - val_loss: 2.2198 - val_accuracy: 0.2726\n",
            "Epoch 7519/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2179 - accuracy: 0.2803 - val_loss: 2.2197 - val_accuracy: 0.2726\n",
            "Epoch 7520/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2179 - accuracy: 0.2803 - val_loss: 2.2197 - val_accuracy: 0.2726\n",
            "Epoch 7521/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2179 - accuracy: 0.2804 - val_loss: 2.2197 - val_accuracy: 0.2727\n",
            "Epoch 7522/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2179 - accuracy: 0.2804 - val_loss: 2.2197 - val_accuracy: 0.2728\n",
            "Epoch 7523/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2179 - accuracy: 0.2804 - val_loss: 2.2197 - val_accuracy: 0.2728\n",
            "Epoch 7524/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2179 - accuracy: 0.2804 - val_loss: 2.2197 - val_accuracy: 0.2728\n",
            "Epoch 7525/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2179 - accuracy: 0.2804 - val_loss: 2.2197 - val_accuracy: 0.2728\n",
            "Epoch 7526/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2178 - accuracy: 0.2804 - val_loss: 2.2197 - val_accuracy: 0.2728\n",
            "Epoch 7527/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2178 - accuracy: 0.2804 - val_loss: 2.2197 - val_accuracy: 0.2728\n",
            "Epoch 7528/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2178 - accuracy: 0.2804 - val_loss: 2.2197 - val_accuracy: 0.2728\n",
            "Epoch 7529/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2178 - accuracy: 0.2805 - val_loss: 2.2196 - val_accuracy: 0.2729\n",
            "Epoch 7530/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2178 - accuracy: 0.2805 - val_loss: 2.2196 - val_accuracy: 0.2729\n",
            "Epoch 7531/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.2178 - accuracy: 0.2805 - val_loss: 2.2196 - val_accuracy: 0.2730\n",
            "Epoch 7532/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2178 - accuracy: 0.2805 - val_loss: 2.2196 - val_accuracy: 0.2730\n",
            "Epoch 7533/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2178 - accuracy: 0.2805 - val_loss: 2.2196 - val_accuracy: 0.2730\n",
            "Epoch 7534/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2178 - accuracy: 0.2806 - val_loss: 2.2196 - val_accuracy: 0.2730\n",
            "Epoch 7535/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2178 - accuracy: 0.2806 - val_loss: 2.2196 - val_accuracy: 0.2730\n",
            "Epoch 7536/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2177 - accuracy: 0.2806 - val_loss: 2.2196 - val_accuracy: 0.2730\n",
            "Epoch 7537/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2177 - accuracy: 0.2806 - val_loss: 2.2196 - val_accuracy: 0.2730\n",
            "Epoch 7538/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2177 - accuracy: 0.2807 - val_loss: 2.2196 - val_accuracy: 0.2730\n",
            "Epoch 7539/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2177 - accuracy: 0.2807 - val_loss: 2.2195 - val_accuracy: 0.2730\n",
            "Epoch 7540/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2177 - accuracy: 0.2807 - val_loss: 2.2195 - val_accuracy: 0.2730\n",
            "Epoch 7541/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2177 - accuracy: 0.2807 - val_loss: 2.2195 - val_accuracy: 0.2730\n",
            "Epoch 7542/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2177 - accuracy: 0.2808 - val_loss: 2.2195 - val_accuracy: 0.2730\n",
            "Epoch 7543/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2177 - accuracy: 0.2808 - val_loss: 2.2195 - val_accuracy: 0.2730\n",
            "Epoch 7544/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2177 - accuracy: 0.2809 - val_loss: 2.2195 - val_accuracy: 0.2730\n",
            "Epoch 7545/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2177 - accuracy: 0.2809 - val_loss: 2.2195 - val_accuracy: 0.2730\n",
            "Epoch 7546/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2176 - accuracy: 0.2809 - val_loss: 2.2195 - val_accuracy: 0.2730\n",
            "Epoch 7547/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2176 - accuracy: 0.2809 - val_loss: 2.2195 - val_accuracy: 0.2731\n",
            "Epoch 7548/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2176 - accuracy: 0.2810 - val_loss: 2.2195 - val_accuracy: 0.2731\n",
            "Epoch 7549/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2176 - accuracy: 0.2810 - val_loss: 2.2195 - val_accuracy: 0.2731\n",
            "Epoch 7550/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2176 - accuracy: 0.2810 - val_loss: 2.2194 - val_accuracy: 0.2731\n",
            "Epoch 7551/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2176 - accuracy: 0.2811 - val_loss: 2.2194 - val_accuracy: 0.2731\n",
            "Epoch 7552/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2176 - accuracy: 0.2811 - val_loss: 2.2194 - val_accuracy: 0.2732\n",
            "Epoch 7553/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2176 - accuracy: 0.2811 - val_loss: 2.2194 - val_accuracy: 0.2732\n",
            "Epoch 7554/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2176 - accuracy: 0.2811 - val_loss: 2.2194 - val_accuracy: 0.2732\n",
            "Epoch 7555/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2176 - accuracy: 0.2812 - val_loss: 2.2194 - val_accuracy: 0.2732\n",
            "Epoch 7556/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2175 - accuracy: 0.2812 - val_loss: 2.2194 - val_accuracy: 0.2732\n",
            "Epoch 7557/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2175 - accuracy: 0.2812 - val_loss: 2.2194 - val_accuracy: 0.2733\n",
            "Epoch 7558/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2175 - accuracy: 0.2812 - val_loss: 2.2194 - val_accuracy: 0.2733\n",
            "Epoch 7559/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2175 - accuracy: 0.2812 - val_loss: 2.2194 - val_accuracy: 0.2734\n",
            "Epoch 7560/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2175 - accuracy: 0.2812 - val_loss: 2.2193 - val_accuracy: 0.2735\n",
            "Epoch 7561/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2175 - accuracy: 0.2813 - val_loss: 2.2193 - val_accuracy: 0.2735\n",
            "Epoch 7562/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2175 - accuracy: 0.2813 - val_loss: 2.2193 - val_accuracy: 0.2735\n",
            "Epoch 7563/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2175 - accuracy: 0.2813 - val_loss: 2.2193 - val_accuracy: 0.2736\n",
            "Epoch 7564/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2175 - accuracy: 0.2813 - val_loss: 2.2193 - val_accuracy: 0.2736\n",
            "Epoch 7565/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2175 - accuracy: 0.2813 - val_loss: 2.2193 - val_accuracy: 0.2736\n",
            "Epoch 7566/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2174 - accuracy: 0.2813 - val_loss: 2.2193 - val_accuracy: 0.2736\n",
            "Epoch 7567/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2174 - accuracy: 0.2813 - val_loss: 2.2193 - val_accuracy: 0.2736\n",
            "Epoch 7568/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2174 - accuracy: 0.2814 - val_loss: 2.2193 - val_accuracy: 0.2736\n",
            "Epoch 7569/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.2174 - accuracy: 0.2814 - val_loss: 2.2193 - val_accuracy: 0.2736\n",
            "Epoch 7570/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2174 - accuracy: 0.2815 - val_loss: 2.2192 - val_accuracy: 0.2737\n",
            "Epoch 7571/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2174 - accuracy: 0.2815 - val_loss: 2.2192 - val_accuracy: 0.2737\n",
            "Epoch 7572/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2174 - accuracy: 0.2815 - val_loss: 2.2192 - val_accuracy: 0.2737\n",
            "Epoch 7573/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2174 - accuracy: 0.2815 - val_loss: 2.2192 - val_accuracy: 0.2737\n",
            "Epoch 7574/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2174 - accuracy: 0.2815 - val_loss: 2.2192 - val_accuracy: 0.2737\n",
            "Epoch 7575/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2174 - accuracy: 0.2815 - val_loss: 2.2192 - val_accuracy: 0.2738\n",
            "Epoch 7576/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2174 - accuracy: 0.2815 - val_loss: 2.2192 - val_accuracy: 0.2738\n",
            "Epoch 7577/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2173 - accuracy: 0.2816 - val_loss: 2.2192 - val_accuracy: 0.2738\n",
            "Epoch 7578/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2173 - accuracy: 0.2816 - val_loss: 2.2192 - val_accuracy: 0.2738\n",
            "Epoch 7579/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2173 - accuracy: 0.2816 - val_loss: 2.2192 - val_accuracy: 0.2738\n",
            "Epoch 7580/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2173 - accuracy: 0.2817 - val_loss: 2.2192 - val_accuracy: 0.2738\n",
            "Epoch 7581/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2173 - accuracy: 0.2817 - val_loss: 2.2191 - val_accuracy: 0.2738\n",
            "Epoch 7582/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2173 - accuracy: 0.2817 - val_loss: 2.2191 - val_accuracy: 0.2738\n",
            "Epoch 7583/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2173 - accuracy: 0.2817 - val_loss: 2.2191 - val_accuracy: 0.2739\n",
            "Epoch 7584/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2173 - accuracy: 0.2818 - val_loss: 2.2191 - val_accuracy: 0.2739\n",
            "Epoch 7585/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2173 - accuracy: 0.2818 - val_loss: 2.2191 - val_accuracy: 0.2739\n",
            "Epoch 7586/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2173 - accuracy: 0.2818 - val_loss: 2.2191 - val_accuracy: 0.2739\n",
            "Epoch 7587/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2172 - accuracy: 0.2818 - val_loss: 2.2191 - val_accuracy: 0.2739\n",
            "Epoch 7588/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.2172 - accuracy: 0.2819 - val_loss: 2.2191 - val_accuracy: 0.2739\n",
            "Epoch 7589/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2172 - accuracy: 0.2819 - val_loss: 2.2191 - val_accuracy: 0.2739\n",
            "Epoch 7590/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2172 - accuracy: 0.2819 - val_loss: 2.2191 - val_accuracy: 0.2739\n",
            "Epoch 7591/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2172 - accuracy: 0.2819 - val_loss: 2.2190 - val_accuracy: 0.2739\n",
            "Epoch 7592/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2172 - accuracy: 0.2819 - val_loss: 2.2190 - val_accuracy: 0.2739\n",
            "Epoch 7593/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2172 - accuracy: 0.2819 - val_loss: 2.2190 - val_accuracy: 0.2739\n",
            "Epoch 7594/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2172 - accuracy: 0.2820 - val_loss: 2.2190 - val_accuracy: 0.2739\n",
            "Epoch 7595/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2172 - accuracy: 0.2820 - val_loss: 2.2190 - val_accuracy: 0.2739\n",
            "Epoch 7596/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2172 - accuracy: 0.2820 - val_loss: 2.2190 - val_accuracy: 0.2739\n",
            "Epoch 7597/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2171 - accuracy: 0.2819 - val_loss: 2.2190 - val_accuracy: 0.2739\n",
            "Epoch 7598/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2171 - accuracy: 0.2820 - val_loss: 2.2190 - val_accuracy: 0.2739\n",
            "Epoch 7599/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2171 - accuracy: 0.2820 - val_loss: 2.2190 - val_accuracy: 0.2739\n",
            "Epoch 7600/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2171 - accuracy: 0.2820 - val_loss: 2.2190 - val_accuracy: 0.2739\n",
            "Epoch 7601/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2171 - accuracy: 0.2821 - val_loss: 2.2189 - val_accuracy: 0.2739\n",
            "Epoch 7602/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2171 - accuracy: 0.2821 - val_loss: 2.2189 - val_accuracy: 0.2739\n",
            "Epoch 7603/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2171 - accuracy: 0.2821 - val_loss: 2.2189 - val_accuracy: 0.2739\n",
            "Epoch 7604/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2171 - accuracy: 0.2821 - val_loss: 2.2189 - val_accuracy: 0.2739\n",
            "Epoch 7605/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2171 - accuracy: 0.2822 - val_loss: 2.2189 - val_accuracy: 0.2739\n",
            "Epoch 7606/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2171 - accuracy: 0.2822 - val_loss: 2.2189 - val_accuracy: 0.2739\n",
            "Epoch 7607/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2170 - accuracy: 0.2822 - val_loss: 2.2189 - val_accuracy: 0.2739\n",
            "Epoch 7608/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2170 - accuracy: 0.2822 - val_loss: 2.2189 - val_accuracy: 0.2739\n",
            "Epoch 7609/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2170 - accuracy: 0.2822 - val_loss: 2.2189 - val_accuracy: 0.2739\n",
            "Epoch 7610/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2170 - accuracy: 0.2822 - val_loss: 2.2189 - val_accuracy: 0.2739\n",
            "Epoch 7611/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2170 - accuracy: 0.2822 - val_loss: 2.2189 - val_accuracy: 0.2739\n",
            "Epoch 7612/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2170 - accuracy: 0.2822 - val_loss: 2.2188 - val_accuracy: 0.2739\n",
            "Epoch 7613/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2170 - accuracy: 0.2822 - val_loss: 2.2188 - val_accuracy: 0.2739\n",
            "Epoch 7614/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2170 - accuracy: 0.2823 - val_loss: 2.2188 - val_accuracy: 0.2740\n",
            "Epoch 7615/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2170 - accuracy: 0.2823 - val_loss: 2.2188 - val_accuracy: 0.2740\n",
            "Epoch 7616/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2170 - accuracy: 0.2824 - val_loss: 2.2188 - val_accuracy: 0.2740\n",
            "Epoch 7617/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2170 - accuracy: 0.2824 - val_loss: 2.2188 - val_accuracy: 0.2740\n",
            "Epoch 7618/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2169 - accuracy: 0.2824 - val_loss: 2.2188 - val_accuracy: 0.2740\n",
            "Epoch 7619/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2169 - accuracy: 0.2824 - val_loss: 2.2188 - val_accuracy: 0.2741\n",
            "Epoch 7620/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2169 - accuracy: 0.2824 - val_loss: 2.2188 - val_accuracy: 0.2741\n",
            "Epoch 7621/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2169 - accuracy: 0.2824 - val_loss: 2.2188 - val_accuracy: 0.2741\n",
            "Epoch 7622/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2169 - accuracy: 0.2825 - val_loss: 2.2187 - val_accuracy: 0.2741\n",
            "Epoch 7623/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2169 - accuracy: 0.2825 - val_loss: 2.2187 - val_accuracy: 0.2741\n",
            "Epoch 7624/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2169 - accuracy: 0.2825 - val_loss: 2.2187 - val_accuracy: 0.2742\n",
            "Epoch 7625/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2169 - accuracy: 0.2826 - val_loss: 2.2187 - val_accuracy: 0.2742\n",
            "Epoch 7626/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2169 - accuracy: 0.2826 - val_loss: 2.2187 - val_accuracy: 0.2742\n",
            "Epoch 7627/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2169 - accuracy: 0.2826 - val_loss: 2.2187 - val_accuracy: 0.2742\n",
            "Epoch 7628/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2168 - accuracy: 0.2827 - val_loss: 2.2187 - val_accuracy: 0.2742\n",
            "Epoch 7629/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2168 - accuracy: 0.2827 - val_loss: 2.2187 - val_accuracy: 0.2742\n",
            "Epoch 7630/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2168 - accuracy: 0.2827 - val_loss: 2.2187 - val_accuracy: 0.2742\n",
            "Epoch 7631/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2168 - accuracy: 0.2827 - val_loss: 2.2187 - val_accuracy: 0.2742\n",
            "Epoch 7632/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2168 - accuracy: 0.2828 - val_loss: 2.2186 - val_accuracy: 0.2742\n",
            "Epoch 7633/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2168 - accuracy: 0.2828 - val_loss: 2.2186 - val_accuracy: 0.2743\n",
            "Epoch 7634/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2168 - accuracy: 0.2828 - val_loss: 2.2186 - val_accuracy: 0.2743\n",
            "Epoch 7635/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2168 - accuracy: 0.2828 - val_loss: 2.2186 - val_accuracy: 0.2743\n",
            "Epoch 7636/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2168 - accuracy: 0.2829 - val_loss: 2.2186 - val_accuracy: 0.2744\n",
            "Epoch 7637/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2168 - accuracy: 0.2829 - val_loss: 2.2186 - val_accuracy: 0.2744\n",
            "Epoch 7638/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2167 - accuracy: 0.2830 - val_loss: 2.2186 - val_accuracy: 0.2745\n",
            "Epoch 7639/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2167 - accuracy: 0.2830 - val_loss: 2.2186 - val_accuracy: 0.2745\n",
            "Epoch 7640/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2167 - accuracy: 0.2830 - val_loss: 2.2186 - val_accuracy: 0.2745\n",
            "Epoch 7641/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2167 - accuracy: 0.2830 - val_loss: 2.2186 - val_accuracy: 0.2745\n",
            "Epoch 7642/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2167 - accuracy: 0.2831 - val_loss: 2.2186 - val_accuracy: 0.2745\n",
            "Epoch 7643/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2167 - accuracy: 0.2831 - val_loss: 2.2185 - val_accuracy: 0.2745\n",
            "Epoch 7644/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2167 - accuracy: 0.2831 - val_loss: 2.2185 - val_accuracy: 0.2745\n",
            "Epoch 7645/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2167 - accuracy: 0.2831 - val_loss: 2.2185 - val_accuracy: 0.2745\n",
            "Epoch 7646/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2167 - accuracy: 0.2831 - val_loss: 2.2185 - val_accuracy: 0.2746\n",
            "Epoch 7647/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2167 - accuracy: 0.2831 - val_loss: 2.2185 - val_accuracy: 0.2747\n",
            "Epoch 7648/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2166 - accuracy: 0.2832 - val_loss: 2.2185 - val_accuracy: 0.2747\n",
            "Epoch 7649/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2166 - accuracy: 0.2832 - val_loss: 2.2185 - val_accuracy: 0.2747\n",
            "Epoch 7650/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2166 - accuracy: 0.2832 - val_loss: 2.2185 - val_accuracy: 0.2747\n",
            "Epoch 7651/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2166 - accuracy: 0.2832 - val_loss: 2.2185 - val_accuracy: 0.2748\n",
            "Epoch 7652/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2166 - accuracy: 0.2832 - val_loss: 2.2185 - val_accuracy: 0.2748\n",
            "Epoch 7653/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2166 - accuracy: 0.2833 - val_loss: 2.2184 - val_accuracy: 0.2748\n",
            "Epoch 7654/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2166 - accuracy: 0.2833 - val_loss: 2.2184 - val_accuracy: 0.2748\n",
            "Epoch 7655/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2166 - accuracy: 0.2833 - val_loss: 2.2184 - val_accuracy: 0.2748\n",
            "Epoch 7656/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2166 - accuracy: 0.2833 - val_loss: 2.2184 - val_accuracy: 0.2748\n",
            "Epoch 7657/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2166 - accuracy: 0.2833 - val_loss: 2.2184 - val_accuracy: 0.2748\n",
            "Epoch 7658/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2166 - accuracy: 0.2833 - val_loss: 2.2184 - val_accuracy: 0.2748\n",
            "Epoch 7659/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2165 - accuracy: 0.2833 - val_loss: 2.2184 - val_accuracy: 0.2750\n",
            "Epoch 7660/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2165 - accuracy: 0.2833 - val_loss: 2.2184 - val_accuracy: 0.2750\n",
            "Epoch 7661/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2165 - accuracy: 0.2834 - val_loss: 2.2184 - val_accuracy: 0.2750\n",
            "Epoch 7662/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2165 - accuracy: 0.2834 - val_loss: 2.2184 - val_accuracy: 0.2750\n",
            "Epoch 7663/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2165 - accuracy: 0.2834 - val_loss: 2.2183 - val_accuracy: 0.2750\n",
            "Epoch 7664/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2165 - accuracy: 0.2835 - val_loss: 2.2183 - val_accuracy: 0.2750\n",
            "Epoch 7665/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2165 - accuracy: 0.2835 - val_loss: 2.2183 - val_accuracy: 0.2751\n",
            "Epoch 7666/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2165 - accuracy: 0.2835 - val_loss: 2.2183 - val_accuracy: 0.2751\n",
            "Epoch 7667/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2165 - accuracy: 0.2835 - val_loss: 2.2183 - val_accuracy: 0.2751\n",
            "Epoch 7668/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2165 - accuracy: 0.2836 - val_loss: 2.2183 - val_accuracy: 0.2751\n",
            "Epoch 7669/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2164 - accuracy: 0.2837 - val_loss: 2.2183 - val_accuracy: 0.2752\n",
            "Epoch 7670/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2164 - accuracy: 0.2837 - val_loss: 2.2183 - val_accuracy: 0.2753\n",
            "Epoch 7671/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2164 - accuracy: 0.2837 - val_loss: 2.2183 - val_accuracy: 0.2753\n",
            "Epoch 7672/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2164 - accuracy: 0.2838 - val_loss: 2.2183 - val_accuracy: 0.2753\n",
            "Epoch 7673/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2164 - accuracy: 0.2838 - val_loss: 2.2183 - val_accuracy: 0.2753\n",
            "Epoch 7674/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2164 - accuracy: 0.2839 - val_loss: 2.2182 - val_accuracy: 0.2754\n",
            "Epoch 7675/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2164 - accuracy: 0.2839 - val_loss: 2.2182 - val_accuracy: 0.2754\n",
            "Epoch 7676/10000\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 2.2164 - accuracy: 0.2839 - val_loss: 2.2182 - val_accuracy: 0.2755\n",
            "Epoch 7677/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2164 - accuracy: 0.2839 - val_loss: 2.2182 - val_accuracy: 0.2755\n",
            "Epoch 7678/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2164 - accuracy: 0.2840 - val_loss: 2.2182 - val_accuracy: 0.2755\n",
            "Epoch 7679/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2163 - accuracy: 0.2840 - val_loss: 2.2182 - val_accuracy: 0.2755\n",
            "Epoch 7680/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2163 - accuracy: 0.2840 - val_loss: 2.2182 - val_accuracy: 0.2755\n",
            "Epoch 7681/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2163 - accuracy: 0.2841 - val_loss: 2.2182 - val_accuracy: 0.2755\n",
            "Epoch 7682/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2163 - accuracy: 0.2842 - val_loss: 2.2182 - val_accuracy: 0.2755\n",
            "Epoch 7683/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2163 - accuracy: 0.2842 - val_loss: 2.2182 - val_accuracy: 0.2755\n",
            "Epoch 7684/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2163 - accuracy: 0.2842 - val_loss: 2.2181 - val_accuracy: 0.2755\n",
            "Epoch 7685/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2163 - accuracy: 0.2842 - val_loss: 2.2181 - val_accuracy: 0.2755\n",
            "Epoch 7686/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2163 - accuracy: 0.2842 - val_loss: 2.2181 - val_accuracy: 0.2756\n",
            "Epoch 7687/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2163 - accuracy: 0.2842 - val_loss: 2.2181 - val_accuracy: 0.2756\n",
            "Epoch 7688/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2163 - accuracy: 0.2843 - val_loss: 2.2181 - val_accuracy: 0.2757\n",
            "Epoch 7689/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2163 - accuracy: 0.2843 - val_loss: 2.2181 - val_accuracy: 0.2758\n",
            "Epoch 7690/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2162 - accuracy: 0.2843 - val_loss: 2.2181 - val_accuracy: 0.2758\n",
            "Epoch 7691/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2162 - accuracy: 0.2844 - val_loss: 2.2181 - val_accuracy: 0.2758\n",
            "Epoch 7692/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2162 - accuracy: 0.2844 - val_loss: 2.2181 - val_accuracy: 0.2758\n",
            "Epoch 7693/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2162 - accuracy: 0.2845 - val_loss: 2.2181 - val_accuracy: 0.2758\n",
            "Epoch 7694/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2162 - accuracy: 0.2845 - val_loss: 2.2180 - val_accuracy: 0.2758\n",
            "Epoch 7695/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2162 - accuracy: 0.2845 - val_loss: 2.2180 - val_accuracy: 0.2758\n",
            "Epoch 7696/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2162 - accuracy: 0.2845 - val_loss: 2.2180 - val_accuracy: 0.2758\n",
            "Epoch 7697/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2162 - accuracy: 0.2846 - val_loss: 2.2180 - val_accuracy: 0.2758\n",
            "Epoch 7698/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2162 - accuracy: 0.2846 - val_loss: 2.2180 - val_accuracy: 0.2759\n",
            "Epoch 7699/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2162 - accuracy: 0.2846 - val_loss: 2.2180 - val_accuracy: 0.2759\n",
            "Epoch 7700/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2161 - accuracy: 0.2846 - val_loss: 2.2180 - val_accuracy: 0.2759\n",
            "Epoch 7701/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2161 - accuracy: 0.2847 - val_loss: 2.2180 - val_accuracy: 0.2759\n",
            "Epoch 7702/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2161 - accuracy: 0.2847 - val_loss: 2.2180 - val_accuracy: 0.2759\n",
            "Epoch 7703/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2161 - accuracy: 0.2847 - val_loss: 2.2180 - val_accuracy: 0.2759\n",
            "Epoch 7704/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2161 - accuracy: 0.2847 - val_loss: 2.2180 - val_accuracy: 0.2759\n",
            "Epoch 7705/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2161 - accuracy: 0.2847 - val_loss: 2.2179 - val_accuracy: 0.2759\n",
            "Epoch 7706/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2161 - accuracy: 0.2848 - val_loss: 2.2179 - val_accuracy: 0.2759\n",
            "Epoch 7707/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2161 - accuracy: 0.2848 - val_loss: 2.2179 - val_accuracy: 0.2759\n",
            "Epoch 7708/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2161 - accuracy: 0.2848 - val_loss: 2.2179 - val_accuracy: 0.2760\n",
            "Epoch 7709/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2161 - accuracy: 0.2849 - val_loss: 2.2179 - val_accuracy: 0.2760\n",
            "Epoch 7710/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2160 - accuracy: 0.2849 - val_loss: 2.2179 - val_accuracy: 0.2760\n",
            "Epoch 7711/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2160 - accuracy: 0.2849 - val_loss: 2.2179 - val_accuracy: 0.2761\n",
            "Epoch 7712/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2160 - accuracy: 0.2849 - val_loss: 2.2179 - val_accuracy: 0.2761\n",
            "Epoch 7713/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2160 - accuracy: 0.2849 - val_loss: 2.2179 - val_accuracy: 0.2761\n",
            "Epoch 7714/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2160 - accuracy: 0.2850 - val_loss: 2.2179 - val_accuracy: 0.2761\n",
            "Epoch 7715/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2160 - accuracy: 0.2850 - val_loss: 2.2178 - val_accuracy: 0.2762\n",
            "Epoch 7716/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2160 - accuracy: 0.2850 - val_loss: 2.2178 - val_accuracy: 0.2762\n",
            "Epoch 7717/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2160 - accuracy: 0.2850 - val_loss: 2.2178 - val_accuracy: 0.2763\n",
            "Epoch 7718/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2160 - accuracy: 0.2851 - val_loss: 2.2178 - val_accuracy: 0.2763\n",
            "Epoch 7719/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2160 - accuracy: 0.2851 - val_loss: 2.2178 - val_accuracy: 0.2763\n",
            "Epoch 7720/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2160 - accuracy: 0.2851 - val_loss: 2.2178 - val_accuracy: 0.2763\n",
            "Epoch 7721/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2159 - accuracy: 0.2851 - val_loss: 2.2178 - val_accuracy: 0.2763\n",
            "Epoch 7722/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2159 - accuracy: 0.2852 - val_loss: 2.2178 - val_accuracy: 0.2764\n",
            "Epoch 7723/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2159 - accuracy: 0.2852 - val_loss: 2.2178 - val_accuracy: 0.2764\n",
            "Epoch 7724/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2159 - accuracy: 0.2853 - val_loss: 2.2178 - val_accuracy: 0.2764\n",
            "Epoch 7725/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2159 - accuracy: 0.2853 - val_loss: 2.2178 - val_accuracy: 0.2764\n",
            "Epoch 7726/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2159 - accuracy: 0.2853 - val_loss: 2.2177 - val_accuracy: 0.2764\n",
            "Epoch 7727/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2159 - accuracy: 0.2853 - val_loss: 2.2177 - val_accuracy: 0.2764\n",
            "Epoch 7728/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2159 - accuracy: 0.2853 - val_loss: 2.2177 - val_accuracy: 0.2764\n",
            "Epoch 7729/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2159 - accuracy: 0.2853 - val_loss: 2.2177 - val_accuracy: 0.2764\n",
            "Epoch 7730/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2159 - accuracy: 0.2853 - val_loss: 2.2177 - val_accuracy: 0.2764\n",
            "Epoch 7731/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2158 - accuracy: 0.2853 - val_loss: 2.2177 - val_accuracy: 0.2765\n",
            "Epoch 7732/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2158 - accuracy: 0.2854 - val_loss: 2.2177 - val_accuracy: 0.2765\n",
            "Epoch 7733/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2158 - accuracy: 0.2854 - val_loss: 2.2177 - val_accuracy: 0.2765\n",
            "Epoch 7734/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2158 - accuracy: 0.2854 - val_loss: 2.2177 - val_accuracy: 0.2765\n",
            "Epoch 7735/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2158 - accuracy: 0.2854 - val_loss: 2.2177 - val_accuracy: 0.2765\n",
            "Epoch 7736/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2158 - accuracy: 0.2854 - val_loss: 2.2176 - val_accuracy: 0.2766\n",
            "Epoch 7737/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2158 - accuracy: 0.2854 - val_loss: 2.2176 - val_accuracy: 0.2766\n",
            "Epoch 7738/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2158 - accuracy: 0.2855 - val_loss: 2.2176 - val_accuracy: 0.2766\n",
            "Epoch 7739/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2158 - accuracy: 0.2855 - val_loss: 2.2176 - val_accuracy: 0.2766\n",
            "Epoch 7740/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2158 - accuracy: 0.2855 - val_loss: 2.2176 - val_accuracy: 0.2767\n",
            "Epoch 7741/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2157 - accuracy: 0.2855 - val_loss: 2.2176 - val_accuracy: 0.2767\n",
            "Epoch 7742/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2157 - accuracy: 0.2855 - val_loss: 2.2176 - val_accuracy: 0.2767\n",
            "Epoch 7743/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2157 - accuracy: 0.2856 - val_loss: 2.2176 - val_accuracy: 0.2767\n",
            "Epoch 7744/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2157 - accuracy: 0.2856 - val_loss: 2.2176 - val_accuracy: 0.2767\n",
            "Epoch 7745/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2157 - accuracy: 0.2857 - val_loss: 2.2176 - val_accuracy: 0.2767\n",
            "Epoch 7746/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2157 - accuracy: 0.2857 - val_loss: 2.2176 - val_accuracy: 0.2768\n",
            "Epoch 7747/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2157 - accuracy: 0.2857 - val_loss: 2.2175 - val_accuracy: 0.2768\n",
            "Epoch 7748/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2157 - accuracy: 0.2857 - val_loss: 2.2175 - val_accuracy: 0.2768\n",
            "Epoch 7749/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2157 - accuracy: 0.2857 - val_loss: 2.2175 - val_accuracy: 0.2768\n",
            "Epoch 7750/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2157 - accuracy: 0.2858 - val_loss: 2.2175 - val_accuracy: 0.2768\n",
            "Epoch 7751/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2157 - accuracy: 0.2858 - val_loss: 2.2175 - val_accuracy: 0.2769\n",
            "Epoch 7752/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2156 - accuracy: 0.2858 - val_loss: 2.2175 - val_accuracy: 0.2770\n",
            "Epoch 7753/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2156 - accuracy: 0.2859 - val_loss: 2.2175 - val_accuracy: 0.2771\n",
            "Epoch 7754/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2156 - accuracy: 0.2859 - val_loss: 2.2175 - val_accuracy: 0.2771\n",
            "Epoch 7755/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2156 - accuracy: 0.2859 - val_loss: 2.2175 - val_accuracy: 0.2771\n",
            "Epoch 7756/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2156 - accuracy: 0.2860 - val_loss: 2.2175 - val_accuracy: 0.2771\n",
            "Epoch 7757/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2156 - accuracy: 0.2860 - val_loss: 2.2174 - val_accuracy: 0.2771\n",
            "Epoch 7758/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2156 - accuracy: 0.2860 - val_loss: 2.2174 - val_accuracy: 0.2771\n",
            "Epoch 7759/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2156 - accuracy: 0.2860 - val_loss: 2.2174 - val_accuracy: 0.2772\n",
            "Epoch 7760/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2156 - accuracy: 0.2860 - val_loss: 2.2174 - val_accuracy: 0.2773\n",
            "Epoch 7761/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2156 - accuracy: 0.2861 - val_loss: 2.2174 - val_accuracy: 0.2773\n",
            "Epoch 7762/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2155 - accuracy: 0.2861 - val_loss: 2.2174 - val_accuracy: 0.2773\n",
            "Epoch 7763/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2155 - accuracy: 0.2862 - val_loss: 2.2174 - val_accuracy: 0.2773\n",
            "Epoch 7764/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2155 - accuracy: 0.2862 - val_loss: 2.2174 - val_accuracy: 0.2773\n",
            "Epoch 7765/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2155 - accuracy: 0.2862 - val_loss: 2.2174 - val_accuracy: 0.2774\n",
            "Epoch 7766/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2155 - accuracy: 0.2862 - val_loss: 2.2174 - val_accuracy: 0.2775\n",
            "Epoch 7767/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2155 - accuracy: 0.2862 - val_loss: 2.2173 - val_accuracy: 0.2776\n",
            "Epoch 7768/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2155 - accuracy: 0.2863 - val_loss: 2.2173 - val_accuracy: 0.2777\n",
            "Epoch 7769/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2155 - accuracy: 0.2863 - val_loss: 2.2173 - val_accuracy: 0.2778\n",
            "Epoch 7770/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2155 - accuracy: 0.2863 - val_loss: 2.2173 - val_accuracy: 0.2778\n",
            "Epoch 7771/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2155 - accuracy: 0.2864 - val_loss: 2.2173 - val_accuracy: 0.2778\n",
            "Epoch 7772/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2154 - accuracy: 0.2864 - val_loss: 2.2173 - val_accuracy: 0.2778\n",
            "Epoch 7773/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2154 - accuracy: 0.2864 - val_loss: 2.2173 - val_accuracy: 0.2778\n",
            "Epoch 7774/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2154 - accuracy: 0.2864 - val_loss: 2.2173 - val_accuracy: 0.2778\n",
            "Epoch 7775/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2154 - accuracy: 0.2865 - val_loss: 2.2173 - val_accuracy: 0.2778\n",
            "Epoch 7776/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2154 - accuracy: 0.2865 - val_loss: 2.2173 - val_accuracy: 0.2778\n",
            "Epoch 7777/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2154 - accuracy: 0.2865 - val_loss: 2.2173 - val_accuracy: 0.2778\n",
            "Epoch 7778/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2154 - accuracy: 0.2866 - val_loss: 2.2172 - val_accuracy: 0.2778\n",
            "Epoch 7779/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2154 - accuracy: 0.2866 - val_loss: 2.2172 - val_accuracy: 0.2779\n",
            "Epoch 7780/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2154 - accuracy: 0.2866 - val_loss: 2.2172 - val_accuracy: 0.2779\n",
            "Epoch 7781/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2154 - accuracy: 0.2866 - val_loss: 2.2172 - val_accuracy: 0.2780\n",
            "Epoch 7782/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2154 - accuracy: 0.2866 - val_loss: 2.2172 - val_accuracy: 0.2780\n",
            "Epoch 7783/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2153 - accuracy: 0.2867 - val_loss: 2.2172 - val_accuracy: 0.2781\n",
            "Epoch 7784/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2153 - accuracy: 0.2867 - val_loss: 2.2172 - val_accuracy: 0.2781\n",
            "Epoch 7785/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2153 - accuracy: 0.2867 - val_loss: 2.2172 - val_accuracy: 0.2781\n",
            "Epoch 7786/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2153 - accuracy: 0.2867 - val_loss: 2.2172 - val_accuracy: 0.2781\n",
            "Epoch 7787/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2153 - accuracy: 0.2867 - val_loss: 2.2172 - val_accuracy: 0.2781\n",
            "Epoch 7788/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2153 - accuracy: 0.2867 - val_loss: 2.2171 - val_accuracy: 0.2781\n",
            "Epoch 7789/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2153 - accuracy: 0.2867 - val_loss: 2.2171 - val_accuracy: 0.2782\n",
            "Epoch 7790/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2153 - accuracy: 0.2867 - val_loss: 2.2171 - val_accuracy: 0.2782\n",
            "Epoch 7791/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2153 - accuracy: 0.2868 - val_loss: 2.2171 - val_accuracy: 0.2782\n",
            "Epoch 7792/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2153 - accuracy: 0.2868 - val_loss: 2.2171 - val_accuracy: 0.2782\n",
            "Epoch 7793/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2152 - accuracy: 0.2869 - val_loss: 2.2171 - val_accuracy: 0.2782\n",
            "Epoch 7794/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2152 - accuracy: 0.2869 - val_loss: 2.2171 - val_accuracy: 0.2782\n",
            "Epoch 7795/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2152 - accuracy: 0.2869 - val_loss: 2.2171 - val_accuracy: 0.2783\n",
            "Epoch 7796/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2152 - accuracy: 0.2869 - val_loss: 2.2171 - val_accuracy: 0.2783\n",
            "Epoch 7797/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2152 - accuracy: 0.2869 - val_loss: 2.2171 - val_accuracy: 0.2783\n",
            "Epoch 7798/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2152 - accuracy: 0.2869 - val_loss: 2.2171 - val_accuracy: 0.2783\n",
            "Epoch 7799/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2152 - accuracy: 0.2869 - val_loss: 2.2170 - val_accuracy: 0.2783\n",
            "Epoch 7800/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2152 - accuracy: 0.2869 - val_loss: 2.2170 - val_accuracy: 0.2784\n",
            "Epoch 7801/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2152 - accuracy: 0.2869 - val_loss: 2.2170 - val_accuracy: 0.2784\n",
            "Epoch 7802/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2152 - accuracy: 0.2869 - val_loss: 2.2170 - val_accuracy: 0.2784\n",
            "Epoch 7803/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2151 - accuracy: 0.2870 - val_loss: 2.2170 - val_accuracy: 0.2784\n",
            "Epoch 7804/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2151 - accuracy: 0.2870 - val_loss: 2.2170 - val_accuracy: 0.2784\n",
            "Epoch 7805/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2151 - accuracy: 0.2870 - val_loss: 2.2170 - val_accuracy: 0.2785\n",
            "Epoch 7806/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2151 - accuracy: 0.2870 - val_loss: 2.2170 - val_accuracy: 0.2785\n",
            "Epoch 7807/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2151 - accuracy: 0.2870 - val_loss: 2.2170 - val_accuracy: 0.2785\n",
            "Epoch 7808/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2151 - accuracy: 0.2871 - val_loss: 2.2170 - val_accuracy: 0.2785\n",
            "Epoch 7809/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2151 - accuracy: 0.2871 - val_loss: 2.2169 - val_accuracy: 0.2784\n",
            "Epoch 7810/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2151 - accuracy: 0.2871 - val_loss: 2.2169 - val_accuracy: 0.2784\n",
            "Epoch 7811/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2151 - accuracy: 0.2871 - val_loss: 2.2169 - val_accuracy: 0.2784\n",
            "Epoch 7812/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2151 - accuracy: 0.2871 - val_loss: 2.2169 - val_accuracy: 0.2784\n",
            "Epoch 7813/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2151 - accuracy: 0.2872 - val_loss: 2.2169 - val_accuracy: 0.2784\n",
            "Epoch 7814/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2150 - accuracy: 0.2873 - val_loss: 2.2169 - val_accuracy: 0.2784\n",
            "Epoch 7815/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2150 - accuracy: 0.2873 - val_loss: 2.2169 - val_accuracy: 0.2784\n",
            "Epoch 7816/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2150 - accuracy: 0.2873 - val_loss: 2.2169 - val_accuracy: 0.2784\n",
            "Epoch 7817/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2150 - accuracy: 0.2873 - val_loss: 2.2169 - val_accuracy: 0.2785\n",
            "Epoch 7818/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2150 - accuracy: 0.2873 - val_loss: 2.2169 - val_accuracy: 0.2785\n",
            "Epoch 7819/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2150 - accuracy: 0.2874 - val_loss: 2.2169 - val_accuracy: 0.2786\n",
            "Epoch 7820/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2150 - accuracy: 0.2874 - val_loss: 2.2168 - val_accuracy: 0.2786\n",
            "Epoch 7821/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2150 - accuracy: 0.2874 - val_loss: 2.2168 - val_accuracy: 0.2786\n",
            "Epoch 7822/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2150 - accuracy: 0.2874 - val_loss: 2.2168 - val_accuracy: 0.2786\n",
            "Epoch 7823/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2150 - accuracy: 0.2874 - val_loss: 2.2168 - val_accuracy: 0.2788\n",
            "Epoch 7824/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2149 - accuracy: 0.2874 - val_loss: 2.2168 - val_accuracy: 0.2788\n",
            "Epoch 7825/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2149 - accuracy: 0.2875 - val_loss: 2.2168 - val_accuracy: 0.2788\n",
            "Epoch 7826/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2149 - accuracy: 0.2875 - val_loss: 2.2168 - val_accuracy: 0.2788\n",
            "Epoch 7827/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2149 - accuracy: 0.2875 - val_loss: 2.2168 - val_accuracy: 0.2789\n",
            "Epoch 7828/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2149 - accuracy: 0.2875 - val_loss: 2.2168 - val_accuracy: 0.2789\n",
            "Epoch 7829/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2149 - accuracy: 0.2875 - val_loss: 2.2168 - val_accuracy: 0.2789\n",
            "Epoch 7830/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2149 - accuracy: 0.2875 - val_loss: 2.2167 - val_accuracy: 0.2789\n",
            "Epoch 7831/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2149 - accuracy: 0.2875 - val_loss: 2.2167 - val_accuracy: 0.2789\n",
            "Epoch 7832/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2149 - accuracy: 0.2876 - val_loss: 2.2167 - val_accuracy: 0.2789\n",
            "Epoch 7833/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2149 - accuracy: 0.2876 - val_loss: 2.2167 - val_accuracy: 0.2789\n",
            "Epoch 7834/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2149 - accuracy: 0.2876 - val_loss: 2.2167 - val_accuracy: 0.2789\n",
            "Epoch 7835/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2148 - accuracy: 0.2877 - val_loss: 2.2167 - val_accuracy: 0.2790\n",
            "Epoch 7836/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2148 - accuracy: 0.2877 - val_loss: 2.2167 - val_accuracy: 0.2791\n",
            "Epoch 7837/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2148 - accuracy: 0.2877 - val_loss: 2.2167 - val_accuracy: 0.2792\n",
            "Epoch 7838/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2148 - accuracy: 0.2877 - val_loss: 2.2167 - val_accuracy: 0.2792\n",
            "Epoch 7839/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2148 - accuracy: 0.2878 - val_loss: 2.2167 - val_accuracy: 0.2792\n",
            "Epoch 7840/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2148 - accuracy: 0.2878 - val_loss: 2.2167 - val_accuracy: 0.2792\n",
            "Epoch 7841/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2148 - accuracy: 0.2878 - val_loss: 2.2166 - val_accuracy: 0.2792\n",
            "Epoch 7842/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2148 - accuracy: 0.2878 - val_loss: 2.2166 - val_accuracy: 0.2792\n",
            "Epoch 7843/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2148 - accuracy: 0.2878 - val_loss: 2.2166 - val_accuracy: 0.2794\n",
            "Epoch 7844/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2148 - accuracy: 0.2879 - val_loss: 2.2166 - val_accuracy: 0.2796\n",
            "Epoch 7845/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2147 - accuracy: 0.2879 - val_loss: 2.2166 - val_accuracy: 0.2797\n",
            "Epoch 7846/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2147 - accuracy: 0.2879 - val_loss: 2.2166 - val_accuracy: 0.2798\n",
            "Epoch 7847/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2147 - accuracy: 0.2880 - val_loss: 2.2166 - val_accuracy: 0.2798\n",
            "Epoch 7848/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2147 - accuracy: 0.2880 - val_loss: 2.2166 - val_accuracy: 0.2798\n",
            "Epoch 7849/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2147 - accuracy: 0.2880 - val_loss: 2.2166 - val_accuracy: 0.2798\n",
            "Epoch 7850/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2147 - accuracy: 0.2880 - val_loss: 2.2166 - val_accuracy: 0.2798\n",
            "Epoch 7851/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2147 - accuracy: 0.2881 - val_loss: 2.2165 - val_accuracy: 0.2799\n",
            "Epoch 7852/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2147 - accuracy: 0.2881 - val_loss: 2.2165 - val_accuracy: 0.2799\n",
            "Epoch 7853/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2147 - accuracy: 0.2881 - val_loss: 2.2165 - val_accuracy: 0.2799\n",
            "Epoch 7854/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2147 - accuracy: 0.2881 - val_loss: 2.2165 - val_accuracy: 0.2799\n",
            "Epoch 7855/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2146 - accuracy: 0.2881 - val_loss: 2.2165 - val_accuracy: 0.2799\n",
            "Epoch 7856/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2146 - accuracy: 0.2882 - val_loss: 2.2165 - val_accuracy: 0.2799\n",
            "Epoch 7857/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2146 - accuracy: 0.2882 - val_loss: 2.2165 - val_accuracy: 0.2799\n",
            "Epoch 7858/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2146 - accuracy: 0.2882 - val_loss: 2.2165 - val_accuracy: 0.2800\n",
            "Epoch 7859/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2146 - accuracy: 0.2883 - val_loss: 2.2165 - val_accuracy: 0.2800\n",
            "Epoch 7860/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2146 - accuracy: 0.2883 - val_loss: 2.2165 - val_accuracy: 0.2800\n",
            "Epoch 7861/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2146 - accuracy: 0.2883 - val_loss: 2.2165 - val_accuracy: 0.2800\n",
            "Epoch 7862/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2146 - accuracy: 0.2883 - val_loss: 2.2164 - val_accuracy: 0.2800\n",
            "Epoch 7863/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2146 - accuracy: 0.2883 - val_loss: 2.2164 - val_accuracy: 0.2801\n",
            "Epoch 7864/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2146 - accuracy: 0.2884 - val_loss: 2.2164 - val_accuracy: 0.2801\n",
            "Epoch 7865/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2146 - accuracy: 0.2884 - val_loss: 2.2164 - val_accuracy: 0.2801\n",
            "Epoch 7866/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2145 - accuracy: 0.2884 - val_loss: 2.2164 - val_accuracy: 0.2801\n",
            "Epoch 7867/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2145 - accuracy: 0.2884 - val_loss: 2.2164 - val_accuracy: 0.2801\n",
            "Epoch 7868/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2145 - accuracy: 0.2885 - val_loss: 2.2164 - val_accuracy: 0.2801\n",
            "Epoch 7869/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2145 - accuracy: 0.2885 - val_loss: 2.2164 - val_accuracy: 0.2802\n",
            "Epoch 7870/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2145 - accuracy: 0.2885 - val_loss: 2.2164 - val_accuracy: 0.2802\n",
            "Epoch 7871/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2145 - accuracy: 0.2885 - val_loss: 2.2164 - val_accuracy: 0.2802\n",
            "Epoch 7872/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2145 - accuracy: 0.2885 - val_loss: 2.2163 - val_accuracy: 0.2802\n",
            "Epoch 7873/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2145 - accuracy: 0.2885 - val_loss: 2.2163 - val_accuracy: 0.2802\n",
            "Epoch 7874/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2145 - accuracy: 0.2886 - val_loss: 2.2163 - val_accuracy: 0.2802\n",
            "Epoch 7875/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2145 - accuracy: 0.2886 - val_loss: 2.2163 - val_accuracy: 0.2804\n",
            "Epoch 7876/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2144 - accuracy: 0.2886 - val_loss: 2.2163 - val_accuracy: 0.2804\n",
            "Epoch 7877/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2144 - accuracy: 0.2886 - val_loss: 2.2163 - val_accuracy: 0.2805\n",
            "Epoch 7878/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2144 - accuracy: 0.2886 - val_loss: 2.2163 - val_accuracy: 0.2805\n",
            "Epoch 7879/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2144 - accuracy: 0.2887 - val_loss: 2.2163 - val_accuracy: 0.2805\n",
            "Epoch 7880/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2144 - accuracy: 0.2887 - val_loss: 2.2163 - val_accuracy: 0.2805\n",
            "Epoch 7881/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2144 - accuracy: 0.2887 - val_loss: 2.2163 - val_accuracy: 0.2805\n",
            "Epoch 7882/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2144 - accuracy: 0.2887 - val_loss: 2.2163 - val_accuracy: 0.2805\n",
            "Epoch 7883/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2144 - accuracy: 0.2888 - val_loss: 2.2162 - val_accuracy: 0.2805\n",
            "Epoch 7884/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2144 - accuracy: 0.2888 - val_loss: 2.2162 - val_accuracy: 0.2805\n",
            "Epoch 7885/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2144 - accuracy: 0.2888 - val_loss: 2.2162 - val_accuracy: 0.2805\n",
            "Epoch 7886/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2144 - accuracy: 0.2888 - val_loss: 2.2162 - val_accuracy: 0.2805\n",
            "Epoch 7887/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2143 - accuracy: 0.2888 - val_loss: 2.2162 - val_accuracy: 0.2806\n",
            "Epoch 7888/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2143 - accuracy: 0.2889 - val_loss: 2.2162 - val_accuracy: 0.2806\n",
            "Epoch 7889/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2143 - accuracy: 0.2889 - val_loss: 2.2162 - val_accuracy: 0.2807\n",
            "Epoch 7890/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2143 - accuracy: 0.2889 - val_loss: 2.2162 - val_accuracy: 0.2807\n",
            "Epoch 7891/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2143 - accuracy: 0.2890 - val_loss: 2.2162 - val_accuracy: 0.2807\n",
            "Epoch 7892/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2143 - accuracy: 0.2890 - val_loss: 2.2162 - val_accuracy: 0.2807\n",
            "Epoch 7893/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2143 - accuracy: 0.2890 - val_loss: 2.2161 - val_accuracy: 0.2807\n",
            "Epoch 7894/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2143 - accuracy: 0.2891 - val_loss: 2.2161 - val_accuracy: 0.2807\n",
            "Epoch 7895/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2143 - accuracy: 0.2891 - val_loss: 2.2161 - val_accuracy: 0.2809\n",
            "Epoch 7896/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2143 - accuracy: 0.2892 - val_loss: 2.2161 - val_accuracy: 0.2809\n",
            "Epoch 7897/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2142 - accuracy: 0.2892 - val_loss: 2.2161 - val_accuracy: 0.2809\n",
            "Epoch 7898/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2142 - accuracy: 0.2892 - val_loss: 2.2161 - val_accuracy: 0.2809\n",
            "Epoch 7899/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2142 - accuracy: 0.2892 - val_loss: 2.2161 - val_accuracy: 0.2809\n",
            "Epoch 7900/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2142 - accuracy: 0.2892 - val_loss: 2.2161 - val_accuracy: 0.2810\n",
            "Epoch 7901/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2142 - accuracy: 0.2892 - val_loss: 2.2161 - val_accuracy: 0.2810\n",
            "Epoch 7902/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2142 - accuracy: 0.2892 - val_loss: 2.2161 - val_accuracy: 0.2810\n",
            "Epoch 7903/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2142 - accuracy: 0.2893 - val_loss: 2.2161 - val_accuracy: 0.2811\n",
            "Epoch 7904/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2142 - accuracy: 0.2893 - val_loss: 2.2160 - val_accuracy: 0.2811\n",
            "Epoch 7905/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2142 - accuracy: 0.2893 - val_loss: 2.2160 - val_accuracy: 0.2811\n",
            "Epoch 7906/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2142 - accuracy: 0.2894 - val_loss: 2.2160 - val_accuracy: 0.2812\n",
            "Epoch 7907/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2142 - accuracy: 0.2894 - val_loss: 2.2160 - val_accuracy: 0.2812\n",
            "Epoch 7908/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2141 - accuracy: 0.2894 - val_loss: 2.2160 - val_accuracy: 0.2813\n",
            "Epoch 7909/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2141 - accuracy: 0.2895 - val_loss: 2.2160 - val_accuracy: 0.2813\n",
            "Epoch 7910/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2141 - accuracy: 0.2895 - val_loss: 2.2160 - val_accuracy: 0.2813\n",
            "Epoch 7911/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2141 - accuracy: 0.2895 - val_loss: 2.2160 - val_accuracy: 0.2813\n",
            "Epoch 7912/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2141 - accuracy: 0.2895 - val_loss: 2.2160 - val_accuracy: 0.2814\n",
            "Epoch 7913/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2141 - accuracy: 0.2896 - val_loss: 2.2160 - val_accuracy: 0.2814\n",
            "Epoch 7914/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2141 - accuracy: 0.2896 - val_loss: 2.2159 - val_accuracy: 0.2814\n",
            "Epoch 7915/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2141 - accuracy: 0.2896 - val_loss: 2.2159 - val_accuracy: 0.2815\n",
            "Epoch 7916/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2141 - accuracy: 0.2896 - val_loss: 2.2159 - val_accuracy: 0.2815\n",
            "Epoch 7917/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2141 - accuracy: 0.2896 - val_loss: 2.2159 - val_accuracy: 0.2815\n",
            "Epoch 7918/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2140 - accuracy: 0.2896 - val_loss: 2.2159 - val_accuracy: 0.2815\n",
            "Epoch 7919/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2140 - accuracy: 0.2896 - val_loss: 2.2159 - val_accuracy: 0.2815\n",
            "Epoch 7920/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2140 - accuracy: 0.2896 - val_loss: 2.2159 - val_accuracy: 0.2816\n",
            "Epoch 7921/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2140 - accuracy: 0.2897 - val_loss: 2.2159 - val_accuracy: 0.2816\n",
            "Epoch 7922/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2140 - accuracy: 0.2897 - val_loss: 2.2159 - val_accuracy: 0.2816\n",
            "Epoch 7923/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2140 - accuracy: 0.2897 - val_loss: 2.2159 - val_accuracy: 0.2816\n",
            "Epoch 7924/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2140 - accuracy: 0.2898 - val_loss: 2.2159 - val_accuracy: 0.2817\n",
            "Epoch 7925/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2140 - accuracy: 0.2898 - val_loss: 2.2158 - val_accuracy: 0.2817\n",
            "Epoch 7926/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2140 - accuracy: 0.2898 - val_loss: 2.2158 - val_accuracy: 0.2817\n",
            "Epoch 7927/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2140 - accuracy: 0.2898 - val_loss: 2.2158 - val_accuracy: 0.2817\n",
            "Epoch 7928/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2139 - accuracy: 0.2898 - val_loss: 2.2158 - val_accuracy: 0.2818\n",
            "Epoch 7929/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2139 - accuracy: 0.2898 - val_loss: 2.2158 - val_accuracy: 0.2820\n",
            "Epoch 7930/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2139 - accuracy: 0.2898 - val_loss: 2.2158 - val_accuracy: 0.2820\n",
            "Epoch 7931/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2139 - accuracy: 0.2899 - val_loss: 2.2158 - val_accuracy: 0.2821\n",
            "Epoch 7932/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2139 - accuracy: 0.2899 - val_loss: 2.2158 - val_accuracy: 0.2821\n",
            "Epoch 7933/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2139 - accuracy: 0.2899 - val_loss: 2.2158 - val_accuracy: 0.2821\n",
            "Epoch 7934/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2139 - accuracy: 0.2899 - val_loss: 2.2158 - val_accuracy: 0.2822\n",
            "Epoch 7935/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2139 - accuracy: 0.2900 - val_loss: 2.2157 - val_accuracy: 0.2822\n",
            "Epoch 7936/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2139 - accuracy: 0.2900 - val_loss: 2.2157 - val_accuracy: 0.2822\n",
            "Epoch 7937/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2139 - accuracy: 0.2900 - val_loss: 2.2157 - val_accuracy: 0.2822\n",
            "Epoch 7938/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2139 - accuracy: 0.2900 - val_loss: 2.2157 - val_accuracy: 0.2822\n",
            "Epoch 7939/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2138 - accuracy: 0.2900 - val_loss: 2.2157 - val_accuracy: 0.2822\n",
            "Epoch 7940/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2138 - accuracy: 0.2900 - val_loss: 2.2157 - val_accuracy: 0.2823\n",
            "Epoch 7941/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2138 - accuracy: 0.2900 - val_loss: 2.2157 - val_accuracy: 0.2823\n",
            "Epoch 7942/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2138 - accuracy: 0.2901 - val_loss: 2.2157 - val_accuracy: 0.2823\n",
            "Epoch 7943/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2138 - accuracy: 0.2901 - val_loss: 2.2157 - val_accuracy: 0.2823\n",
            "Epoch 7944/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2138 - accuracy: 0.2901 - val_loss: 2.2157 - val_accuracy: 0.2823\n",
            "Epoch 7945/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2138 - accuracy: 0.2902 - val_loss: 2.2157 - val_accuracy: 0.2823\n",
            "Epoch 7946/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2138 - accuracy: 0.2902 - val_loss: 2.2156 - val_accuracy: 0.2822\n",
            "Epoch 7947/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2138 - accuracy: 0.2902 - val_loss: 2.2156 - val_accuracy: 0.2822\n",
            "Epoch 7948/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2138 - accuracy: 0.2903 - val_loss: 2.2156 - val_accuracy: 0.2822\n",
            "Epoch 7949/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2137 - accuracy: 0.2903 - val_loss: 2.2156 - val_accuracy: 0.2822\n",
            "Epoch 7950/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2137 - accuracy: 0.2903 - val_loss: 2.2156 - val_accuracy: 0.2822\n",
            "Epoch 7951/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2137 - accuracy: 0.2903 - val_loss: 2.2156 - val_accuracy: 0.2822\n",
            "Epoch 7952/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2137 - accuracy: 0.2903 - val_loss: 2.2156 - val_accuracy: 0.2822\n",
            "Epoch 7953/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2137 - accuracy: 0.2904 - val_loss: 2.2156 - val_accuracy: 0.2822\n",
            "Epoch 7954/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2137 - accuracy: 0.2904 - val_loss: 2.2156 - val_accuracy: 0.2823\n",
            "Epoch 7955/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2137 - accuracy: 0.2904 - val_loss: 2.2156 - val_accuracy: 0.2823\n",
            "Epoch 7956/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2137 - accuracy: 0.2904 - val_loss: 2.2156 - val_accuracy: 0.2822\n",
            "Epoch 7957/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2137 - accuracy: 0.2904 - val_loss: 2.2155 - val_accuracy: 0.2822\n",
            "Epoch 7958/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2137 - accuracy: 0.2904 - val_loss: 2.2155 - val_accuracy: 0.2822\n",
            "Epoch 7959/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2137 - accuracy: 0.2905 - val_loss: 2.2155 - val_accuracy: 0.2822\n",
            "Epoch 7960/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2136 - accuracy: 0.2905 - val_loss: 2.2155 - val_accuracy: 0.2822\n",
            "Epoch 7961/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2136 - accuracy: 0.2905 - val_loss: 2.2155 - val_accuracy: 0.2822\n",
            "Epoch 7962/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2136 - accuracy: 0.2905 - val_loss: 2.2155 - val_accuracy: 0.2822\n",
            "Epoch 7963/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2136 - accuracy: 0.2905 - val_loss: 2.2155 - val_accuracy: 0.2822\n",
            "Epoch 7964/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2136 - accuracy: 0.2905 - val_loss: 2.2155 - val_accuracy: 0.2822\n",
            "Epoch 7965/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2136 - accuracy: 0.2905 - val_loss: 2.2155 - val_accuracy: 0.2822\n",
            "Epoch 7966/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2136 - accuracy: 0.2906 - val_loss: 2.2155 - val_accuracy: 0.2822\n",
            "Epoch 7967/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2136 - accuracy: 0.2906 - val_loss: 2.2154 - val_accuracy: 0.2823\n",
            "Epoch 7968/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2136 - accuracy: 0.2906 - val_loss: 2.2154 - val_accuracy: 0.2824\n",
            "Epoch 7969/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2136 - accuracy: 0.2907 - val_loss: 2.2154 - val_accuracy: 0.2824\n",
            "Epoch 7970/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2135 - accuracy: 0.2907 - val_loss: 2.2154 - val_accuracy: 0.2824\n",
            "Epoch 7971/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2135 - accuracy: 0.2908 - val_loss: 2.2154 - val_accuracy: 0.2824\n",
            "Epoch 7972/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2135 - accuracy: 0.2908 - val_loss: 2.2154 - val_accuracy: 0.2825\n",
            "Epoch 7973/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2135 - accuracy: 0.2908 - val_loss: 2.2154 - val_accuracy: 0.2825\n",
            "Epoch 7974/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2135 - accuracy: 0.2908 - val_loss: 2.2154 - val_accuracy: 0.2825\n",
            "Epoch 7975/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2135 - accuracy: 0.2908 - val_loss: 2.2154 - val_accuracy: 0.2825\n",
            "Epoch 7976/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2135 - accuracy: 0.2909 - val_loss: 2.2154 - val_accuracy: 0.2825\n",
            "Epoch 7977/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2135 - accuracy: 0.2909 - val_loss: 2.2154 - val_accuracy: 0.2825\n",
            "Epoch 7978/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2135 - accuracy: 0.2909 - val_loss: 2.2153 - val_accuracy: 0.2826\n",
            "Epoch 7979/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2135 - accuracy: 0.2910 - val_loss: 2.2153 - val_accuracy: 0.2826\n",
            "Epoch 7980/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2135 - accuracy: 0.2910 - val_loss: 2.2153 - val_accuracy: 0.2826\n",
            "Epoch 7981/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2134 - accuracy: 0.2910 - val_loss: 2.2153 - val_accuracy: 0.2826\n",
            "Epoch 7982/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2134 - accuracy: 0.2910 - val_loss: 2.2153 - val_accuracy: 0.2827\n",
            "Epoch 7983/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2134 - accuracy: 0.2911 - val_loss: 2.2153 - val_accuracy: 0.2828\n",
            "Epoch 7984/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2134 - accuracy: 0.2911 - val_loss: 2.2153 - val_accuracy: 0.2828\n",
            "Epoch 7985/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2134 - accuracy: 0.2911 - val_loss: 2.2153 - val_accuracy: 0.2828\n",
            "Epoch 7986/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2134 - accuracy: 0.2912 - val_loss: 2.2153 - val_accuracy: 0.2828\n",
            "Epoch 7987/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2134 - accuracy: 0.2912 - val_loss: 2.2153 - val_accuracy: 0.2828\n",
            "Epoch 7988/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2134 - accuracy: 0.2912 - val_loss: 2.2152 - val_accuracy: 0.2828\n",
            "Epoch 7989/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2134 - accuracy: 0.2912 - val_loss: 2.2152 - val_accuracy: 0.2828\n",
            "Epoch 7990/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2134 - accuracy: 0.2912 - val_loss: 2.2152 - val_accuracy: 0.2828\n",
            "Epoch 7991/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2133 - accuracy: 0.2912 - val_loss: 2.2152 - val_accuracy: 0.2828\n",
            "Epoch 7992/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2133 - accuracy: 0.2913 - val_loss: 2.2152 - val_accuracy: 0.2828\n",
            "Epoch 7993/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2133 - accuracy: 0.2913 - val_loss: 2.2152 - val_accuracy: 0.2829\n",
            "Epoch 7994/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2133 - accuracy: 0.2914 - val_loss: 2.2152 - val_accuracy: 0.2829\n",
            "Epoch 7995/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2133 - accuracy: 0.2914 - val_loss: 2.2152 - val_accuracy: 0.2829\n",
            "Epoch 7996/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2133 - accuracy: 0.2915 - val_loss: 2.2152 - val_accuracy: 0.2829\n",
            "Epoch 7997/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2133 - accuracy: 0.2915 - val_loss: 2.2152 - val_accuracy: 0.2829\n",
            "Epoch 7998/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2133 - accuracy: 0.2915 - val_loss: 2.2152 - val_accuracy: 0.2829\n",
            "Epoch 7999/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2133 - accuracy: 0.2916 - val_loss: 2.2151 - val_accuracy: 0.2829\n",
            "Epoch 8000/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2133 - accuracy: 0.2916 - val_loss: 2.2151 - val_accuracy: 0.2829\n",
            "Epoch 8001/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2133 - accuracy: 0.2916 - val_loss: 2.2151 - val_accuracy: 0.2829\n",
            "Epoch 8002/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2132 - accuracy: 0.2916 - val_loss: 2.2151 - val_accuracy: 0.2829\n",
            "Epoch 8003/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2132 - accuracy: 0.2917 - val_loss: 2.2151 - val_accuracy: 0.2829\n",
            "Epoch 8004/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2132 - accuracy: 0.2917 - val_loss: 2.2151 - val_accuracy: 0.2829\n",
            "Epoch 8005/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2132 - accuracy: 0.2917 - val_loss: 2.2151 - val_accuracy: 0.2830\n",
            "Epoch 8006/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2132 - accuracy: 0.2918 - val_loss: 2.2151 - val_accuracy: 0.2830\n",
            "Epoch 8007/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2132 - accuracy: 0.2918 - val_loss: 2.2151 - val_accuracy: 0.2830\n",
            "Epoch 8008/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2132 - accuracy: 0.2918 - val_loss: 2.2151 - val_accuracy: 0.2830\n",
            "Epoch 8009/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2132 - accuracy: 0.2918 - val_loss: 2.2151 - val_accuracy: 0.2830\n",
            "Epoch 8010/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2132 - accuracy: 0.2918 - val_loss: 2.2150 - val_accuracy: 0.2831\n",
            "Epoch 8011/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2132 - accuracy: 0.2919 - val_loss: 2.2150 - val_accuracy: 0.2831\n",
            "Epoch 8012/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2132 - accuracy: 0.2919 - val_loss: 2.2150 - val_accuracy: 0.2831\n",
            "Epoch 8013/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2131 - accuracy: 0.2919 - val_loss: 2.2150 - val_accuracy: 0.2831\n",
            "Epoch 8014/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2131 - accuracy: 0.2919 - val_loss: 2.2150 - val_accuracy: 0.2831\n",
            "Epoch 8015/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2131 - accuracy: 0.2919 - val_loss: 2.2150 - val_accuracy: 0.2832\n",
            "Epoch 8016/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2131 - accuracy: 0.2919 - val_loss: 2.2150 - val_accuracy: 0.2832\n",
            "Epoch 8017/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2131 - accuracy: 0.2919 - val_loss: 2.2150 - val_accuracy: 0.2832\n",
            "Epoch 8018/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2131 - accuracy: 0.2919 - val_loss: 2.2150 - val_accuracy: 0.2832\n",
            "Epoch 8019/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2131 - accuracy: 0.2919 - val_loss: 2.2150 - val_accuracy: 0.2832\n",
            "Epoch 8020/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2131 - accuracy: 0.2920 - val_loss: 2.2149 - val_accuracy: 0.2833\n",
            "Epoch 8021/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2131 - accuracy: 0.2919 - val_loss: 2.2149 - val_accuracy: 0.2833\n",
            "Epoch 8022/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2131 - accuracy: 0.2919 - val_loss: 2.2149 - val_accuracy: 0.2833\n",
            "Epoch 8023/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2130 - accuracy: 0.2920 - val_loss: 2.2149 - val_accuracy: 0.2834\n",
            "Epoch 8024/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2130 - accuracy: 0.2920 - val_loss: 2.2149 - val_accuracy: 0.2834\n",
            "Epoch 8025/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2130 - accuracy: 0.2920 - val_loss: 2.2149 - val_accuracy: 0.2834\n",
            "Epoch 8026/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2130 - accuracy: 0.2920 - val_loss: 2.2149 - val_accuracy: 0.2835\n",
            "Epoch 8027/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2130 - accuracy: 0.2920 - val_loss: 2.2149 - val_accuracy: 0.2836\n",
            "Epoch 8028/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2130 - accuracy: 0.2921 - val_loss: 2.2149 - val_accuracy: 0.2836\n",
            "Epoch 8029/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2130 - accuracy: 0.2920 - val_loss: 2.2149 - val_accuracy: 0.2836\n",
            "Epoch 8030/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2130 - accuracy: 0.2921 - val_loss: 2.2149 - val_accuracy: 0.2836\n",
            "Epoch 8031/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.2130 - accuracy: 0.2921 - val_loss: 2.2148 - val_accuracy: 0.2836\n",
            "Epoch 8032/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2130 - accuracy: 0.2921 - val_loss: 2.2148 - val_accuracy: 0.2835\n",
            "Epoch 8033/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2130 - accuracy: 0.2921 - val_loss: 2.2148 - val_accuracy: 0.2835\n",
            "Epoch 8034/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2129 - accuracy: 0.2921 - val_loss: 2.2148 - val_accuracy: 0.2835\n",
            "Epoch 8035/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2129 - accuracy: 0.2921 - val_loss: 2.2148 - val_accuracy: 0.2835\n",
            "Epoch 8036/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2129 - accuracy: 0.2921 - val_loss: 2.2148 - val_accuracy: 0.2836\n",
            "Epoch 8037/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2129 - accuracy: 0.2922 - val_loss: 2.2148 - val_accuracy: 0.2836\n",
            "Epoch 8038/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2129 - accuracy: 0.2922 - val_loss: 2.2148 - val_accuracy: 0.2836\n",
            "Epoch 8039/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2129 - accuracy: 0.2922 - val_loss: 2.2148 - val_accuracy: 0.2837\n",
            "Epoch 8040/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2129 - accuracy: 0.2922 - val_loss: 2.2148 - val_accuracy: 0.2837\n",
            "Epoch 8041/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2129 - accuracy: 0.2923 - val_loss: 2.2147 - val_accuracy: 0.2837\n",
            "Epoch 8042/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2129 - accuracy: 0.2923 - val_loss: 2.2147 - val_accuracy: 0.2837\n",
            "Epoch 8043/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2129 - accuracy: 0.2923 - val_loss: 2.2147 - val_accuracy: 0.2837\n",
            "Epoch 8044/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2128 - accuracy: 0.2923 - val_loss: 2.2147 - val_accuracy: 0.2837\n",
            "Epoch 8045/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2128 - accuracy: 0.2923 - val_loss: 2.2147 - val_accuracy: 0.2837\n",
            "Epoch 8046/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2128 - accuracy: 0.2924 - val_loss: 2.2147 - val_accuracy: 0.2837\n",
            "Epoch 8047/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2128 - accuracy: 0.2925 - val_loss: 2.2147 - val_accuracy: 0.2837\n",
            "Epoch 8048/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2128 - accuracy: 0.2925 - val_loss: 2.2147 - val_accuracy: 0.2837\n",
            "Epoch 8049/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2128 - accuracy: 0.2925 - val_loss: 2.2147 - val_accuracy: 0.2837\n",
            "Epoch 8050/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2128 - accuracy: 0.2925 - val_loss: 2.2147 - val_accuracy: 0.2837\n",
            "Epoch 8051/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2128 - accuracy: 0.2925 - val_loss: 2.2147 - val_accuracy: 0.2838\n",
            "Epoch 8052/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2128 - accuracy: 0.2926 - val_loss: 2.2146 - val_accuracy: 0.2838\n",
            "Epoch 8053/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2128 - accuracy: 0.2926 - val_loss: 2.2146 - val_accuracy: 0.2838\n",
            "Epoch 8054/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2128 - accuracy: 0.2927 - val_loss: 2.2146 - val_accuracy: 0.2839\n",
            "Epoch 8055/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2127 - accuracy: 0.2927 - val_loss: 2.2146 - val_accuracy: 0.2839\n",
            "Epoch 8056/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2127 - accuracy: 0.2927 - val_loss: 2.2146 - val_accuracy: 0.2839\n",
            "Epoch 8057/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2127 - accuracy: 0.2927 - val_loss: 2.2146 - val_accuracy: 0.2839\n",
            "Epoch 8058/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2127 - accuracy: 0.2928 - val_loss: 2.2146 - val_accuracy: 0.2839\n",
            "Epoch 8059/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2127 - accuracy: 0.2928 - val_loss: 2.2146 - val_accuracy: 0.2839\n",
            "Epoch 8060/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2127 - accuracy: 0.2928 - val_loss: 2.2146 - val_accuracy: 0.2838\n",
            "Epoch 8061/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2127 - accuracy: 0.2928 - val_loss: 2.2146 - val_accuracy: 0.2838\n",
            "Epoch 8062/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2127 - accuracy: 0.2928 - val_loss: 2.2146 - val_accuracy: 0.2838\n",
            "Epoch 8063/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2127 - accuracy: 0.2928 - val_loss: 2.2145 - val_accuracy: 0.2838\n",
            "Epoch 8064/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2127 - accuracy: 0.2929 - val_loss: 2.2145 - val_accuracy: 0.2838\n",
            "Epoch 8065/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2126 - accuracy: 0.2929 - val_loss: 2.2145 - val_accuracy: 0.2838\n",
            "Epoch 8066/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2126 - accuracy: 0.2929 - val_loss: 2.2145 - val_accuracy: 0.2838\n",
            "Epoch 8067/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2126 - accuracy: 0.2929 - val_loss: 2.2145 - val_accuracy: 0.2838\n",
            "Epoch 8068/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2126 - accuracy: 0.2930 - val_loss: 2.2145 - val_accuracy: 0.2838\n",
            "Epoch 8069/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2126 - accuracy: 0.2930 - val_loss: 2.2145 - val_accuracy: 0.2838\n",
            "Epoch 8070/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2126 - accuracy: 0.2930 - val_loss: 2.2145 - val_accuracy: 0.2838\n",
            "Epoch 8071/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2126 - accuracy: 0.2930 - val_loss: 2.2145 - val_accuracy: 0.2838\n",
            "Epoch 8072/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2126 - accuracy: 0.2930 - val_loss: 2.2145 - val_accuracy: 0.2838\n",
            "Epoch 8073/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2126 - accuracy: 0.2930 - val_loss: 2.2144 - val_accuracy: 0.2839\n",
            "Epoch 8074/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2126 - accuracy: 0.2931 - val_loss: 2.2144 - val_accuracy: 0.2839\n",
            "Epoch 8075/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2126 - accuracy: 0.2932 - val_loss: 2.2144 - val_accuracy: 0.2839\n",
            "Epoch 8076/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2125 - accuracy: 0.2932 - val_loss: 2.2144 - val_accuracy: 0.2840\n",
            "Epoch 8077/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2125 - accuracy: 0.2932 - val_loss: 2.2144 - val_accuracy: 0.2842\n",
            "Epoch 8078/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2125 - accuracy: 0.2932 - val_loss: 2.2144 - val_accuracy: 0.2842\n",
            "Epoch 8079/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2125 - accuracy: 0.2933 - val_loss: 2.2144 - val_accuracy: 0.2842\n",
            "Epoch 8080/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2125 - accuracy: 0.2933 - val_loss: 2.2144 - val_accuracy: 0.2842\n",
            "Epoch 8081/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2125 - accuracy: 0.2934 - val_loss: 2.2144 - val_accuracy: 0.2842\n",
            "Epoch 8082/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2125 - accuracy: 0.2934 - val_loss: 2.2144 - val_accuracy: 0.2843\n",
            "Epoch 8083/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2125 - accuracy: 0.2934 - val_loss: 2.2144 - val_accuracy: 0.2845\n",
            "Epoch 8084/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2125 - accuracy: 0.2934 - val_loss: 2.2143 - val_accuracy: 0.2845\n",
            "Epoch 8085/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2125 - accuracy: 0.2934 - val_loss: 2.2143 - val_accuracy: 0.2845\n",
            "Epoch 8086/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2124 - accuracy: 0.2935 - val_loss: 2.2143 - val_accuracy: 0.2845\n",
            "Epoch 8087/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2124 - accuracy: 0.2935 - val_loss: 2.2143 - val_accuracy: 0.2846\n",
            "Epoch 8088/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2124 - accuracy: 0.2935 - val_loss: 2.2143 - val_accuracy: 0.2846\n",
            "Epoch 8089/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2124 - accuracy: 0.2935 - val_loss: 2.2143 - val_accuracy: 0.2847\n",
            "Epoch 8090/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2124 - accuracy: 0.2936 - val_loss: 2.2143 - val_accuracy: 0.2847\n",
            "Epoch 8091/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2124 - accuracy: 0.2936 - val_loss: 2.2143 - val_accuracy: 0.2847\n",
            "Epoch 8092/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2124 - accuracy: 0.2936 - val_loss: 2.2143 - val_accuracy: 0.2847\n",
            "Epoch 8093/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2124 - accuracy: 0.2936 - val_loss: 2.2143 - val_accuracy: 0.2847\n",
            "Epoch 8094/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2124 - accuracy: 0.2937 - val_loss: 2.2143 - val_accuracy: 0.2847\n",
            "Epoch 8095/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2124 - accuracy: 0.2937 - val_loss: 2.2142 - val_accuracy: 0.2847\n",
            "Epoch 8096/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2124 - accuracy: 0.2937 - val_loss: 2.2142 - val_accuracy: 0.2848\n",
            "Epoch 8097/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2123 - accuracy: 0.2937 - val_loss: 2.2142 - val_accuracy: 0.2848\n",
            "Epoch 8098/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2123 - accuracy: 0.2937 - val_loss: 2.2142 - val_accuracy: 0.2848\n",
            "Epoch 8099/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2123 - accuracy: 0.2937 - val_loss: 2.2142 - val_accuracy: 0.2848\n",
            "Epoch 8100/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2123 - accuracy: 0.2938 - val_loss: 2.2142 - val_accuracy: 0.2848\n",
            "Epoch 8101/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2123 - accuracy: 0.2938 - val_loss: 2.2142 - val_accuracy: 0.2848\n",
            "Epoch 8102/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2123 - accuracy: 0.2938 - val_loss: 2.2142 - val_accuracy: 0.2850\n",
            "Epoch 8103/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2123 - accuracy: 0.2939 - val_loss: 2.2142 - val_accuracy: 0.2850\n",
            "Epoch 8104/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2123 - accuracy: 0.2939 - val_loss: 2.2142 - val_accuracy: 0.2850\n",
            "Epoch 8105/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2123 - accuracy: 0.2939 - val_loss: 2.2141 - val_accuracy: 0.2851\n",
            "Epoch 8106/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2123 - accuracy: 0.2939 - val_loss: 2.2141 - val_accuracy: 0.2852\n",
            "Epoch 8107/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2123 - accuracy: 0.2939 - val_loss: 2.2141 - val_accuracy: 0.2853\n",
            "Epoch 8108/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2122 - accuracy: 0.2939 - val_loss: 2.2141 - val_accuracy: 0.2853\n",
            "Epoch 8109/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2122 - accuracy: 0.2940 - val_loss: 2.2141 - val_accuracy: 0.2855\n",
            "Epoch 8110/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2122 - accuracy: 0.2940 - val_loss: 2.2141 - val_accuracy: 0.2855\n",
            "Epoch 8111/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2122 - accuracy: 0.2940 - val_loss: 2.2141 - val_accuracy: 0.2855\n",
            "Epoch 8112/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2122 - accuracy: 0.2941 - val_loss: 2.2141 - val_accuracy: 0.2856\n",
            "Epoch 8113/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2122 - accuracy: 0.2941 - val_loss: 2.2141 - val_accuracy: 0.2856\n",
            "Epoch 8114/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2122 - accuracy: 0.2942 - val_loss: 2.2141 - val_accuracy: 0.2857\n",
            "Epoch 8115/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2122 - accuracy: 0.2942 - val_loss: 2.2141 - val_accuracy: 0.2857\n",
            "Epoch 8116/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2122 - accuracy: 0.2942 - val_loss: 2.2140 - val_accuracy: 0.2858\n",
            "Epoch 8117/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2122 - accuracy: 0.2942 - val_loss: 2.2140 - val_accuracy: 0.2859\n",
            "Epoch 8118/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2121 - accuracy: 0.2942 - val_loss: 2.2140 - val_accuracy: 0.2859\n",
            "Epoch 8119/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2121 - accuracy: 0.2942 - val_loss: 2.2140 - val_accuracy: 0.2861\n",
            "Epoch 8120/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2121 - accuracy: 0.2942 - val_loss: 2.2140 - val_accuracy: 0.2861\n",
            "Epoch 8121/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2121 - accuracy: 0.2943 - val_loss: 2.2140 - val_accuracy: 0.2861\n",
            "Epoch 8122/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2121 - accuracy: 0.2943 - val_loss: 2.2140 - val_accuracy: 0.2861\n",
            "Epoch 8123/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2121 - accuracy: 0.2943 - val_loss: 2.2140 - val_accuracy: 0.2861\n",
            "Epoch 8124/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2121 - accuracy: 0.2943 - val_loss: 2.2140 - val_accuracy: 0.2861\n",
            "Epoch 8125/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2121 - accuracy: 0.2944 - val_loss: 2.2140 - val_accuracy: 0.2861\n",
            "Epoch 8126/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2121 - accuracy: 0.2944 - val_loss: 2.2140 - val_accuracy: 0.2861\n",
            "Epoch 8127/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2121 - accuracy: 0.2944 - val_loss: 2.2139 - val_accuracy: 0.2861\n",
            "Epoch 8128/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2121 - accuracy: 0.2944 - val_loss: 2.2139 - val_accuracy: 0.2861\n",
            "Epoch 8129/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2120 - accuracy: 0.2944 - val_loss: 2.2139 - val_accuracy: 0.2861\n",
            "Epoch 8130/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2120 - accuracy: 0.2944 - val_loss: 2.2139 - val_accuracy: 0.2861\n",
            "Epoch 8131/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2120 - accuracy: 0.2944 - val_loss: 2.2139 - val_accuracy: 0.2861\n",
            "Epoch 8132/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2120 - accuracy: 0.2944 - val_loss: 2.2139 - val_accuracy: 0.2861\n",
            "Epoch 8133/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2120 - accuracy: 0.2945 - val_loss: 2.2139 - val_accuracy: 0.2861\n",
            "Epoch 8134/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2120 - accuracy: 0.2945 - val_loss: 2.2139 - val_accuracy: 0.2862\n",
            "Epoch 8135/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2120 - accuracy: 0.2945 - val_loss: 2.2139 - val_accuracy: 0.2862\n",
            "Epoch 8136/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2120 - accuracy: 0.2945 - val_loss: 2.2139 - val_accuracy: 0.2863\n",
            "Epoch 8137/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2120 - accuracy: 0.2946 - val_loss: 2.2138 - val_accuracy: 0.2863\n",
            "Epoch 8138/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2120 - accuracy: 0.2946 - val_loss: 2.2138 - val_accuracy: 0.2863\n",
            "Epoch 8139/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2119 - accuracy: 0.2946 - val_loss: 2.2138 - val_accuracy: 0.2864\n",
            "Epoch 8140/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2119 - accuracy: 0.2946 - val_loss: 2.2138 - val_accuracy: 0.2864\n",
            "Epoch 8141/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2119 - accuracy: 0.2946 - val_loss: 2.2138 - val_accuracy: 0.2865\n",
            "Epoch 8142/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2119 - accuracy: 0.2946 - val_loss: 2.2138 - val_accuracy: 0.2866\n",
            "Epoch 8143/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2119 - accuracy: 0.2946 - val_loss: 2.2138 - val_accuracy: 0.2866\n",
            "Epoch 8144/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2119 - accuracy: 0.2946 - val_loss: 2.2138 - val_accuracy: 0.2866\n",
            "Epoch 8145/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2119 - accuracy: 0.2946 - val_loss: 2.2138 - val_accuracy: 0.2866\n",
            "Epoch 8146/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2119 - accuracy: 0.2946 - val_loss: 2.2138 - val_accuracy: 0.2866\n",
            "Epoch 8147/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2119 - accuracy: 0.2947 - val_loss: 2.2138 - val_accuracy: 0.2868\n",
            "Epoch 8148/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2119 - accuracy: 0.2947 - val_loss: 2.2137 - val_accuracy: 0.2868\n",
            "Epoch 8149/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2119 - accuracy: 0.2947 - val_loss: 2.2137 - val_accuracy: 0.2869\n",
            "Epoch 8150/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2118 - accuracy: 0.2947 - val_loss: 2.2137 - val_accuracy: 0.2869\n",
            "Epoch 8151/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2118 - accuracy: 0.2947 - val_loss: 2.2137 - val_accuracy: 0.2869\n",
            "Epoch 8152/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2118 - accuracy: 0.2947 - val_loss: 2.2137 - val_accuracy: 0.2869\n",
            "Epoch 8153/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2118 - accuracy: 0.2947 - val_loss: 2.2137 - val_accuracy: 0.2870\n",
            "Epoch 8154/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2118 - accuracy: 0.2947 - val_loss: 2.2137 - val_accuracy: 0.2871\n",
            "Epoch 8155/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2118 - accuracy: 0.2948 - val_loss: 2.2137 - val_accuracy: 0.2871\n",
            "Epoch 8156/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2118 - accuracy: 0.2948 - val_loss: 2.2137 - val_accuracy: 0.2871\n",
            "Epoch 8157/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2118 - accuracy: 0.2948 - val_loss: 2.2137 - val_accuracy: 0.2871\n",
            "Epoch 8158/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2118 - accuracy: 0.2948 - val_loss: 2.2137 - val_accuracy: 0.2871\n",
            "Epoch 8159/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2118 - accuracy: 0.2948 - val_loss: 2.2136 - val_accuracy: 0.2871\n",
            "Epoch 8160/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2118 - accuracy: 0.2949 - val_loss: 2.2136 - val_accuracy: 0.2872\n",
            "Epoch 8161/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2117 - accuracy: 0.2949 - val_loss: 2.2136 - val_accuracy: 0.2873\n",
            "Epoch 8162/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2117 - accuracy: 0.2949 - val_loss: 2.2136 - val_accuracy: 0.2873\n",
            "Epoch 8163/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2117 - accuracy: 0.2950 - val_loss: 2.2136 - val_accuracy: 0.2873\n",
            "Epoch 8164/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2117 - accuracy: 0.2950 - val_loss: 2.2136 - val_accuracy: 0.2873\n",
            "Epoch 8165/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2117 - accuracy: 0.2950 - val_loss: 2.2136 - val_accuracy: 0.2873\n",
            "Epoch 8166/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2117 - accuracy: 0.2950 - val_loss: 2.2136 - val_accuracy: 0.2874\n",
            "Epoch 8167/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2117 - accuracy: 0.2951 - val_loss: 2.2136 - val_accuracy: 0.2874\n",
            "Epoch 8168/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2117 - accuracy: 0.2951 - val_loss: 2.2136 - val_accuracy: 0.2874\n",
            "Epoch 8169/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2117 - accuracy: 0.2951 - val_loss: 2.2136 - val_accuracy: 0.2874\n",
            "Epoch 8170/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2117 - accuracy: 0.2951 - val_loss: 2.2135 - val_accuracy: 0.2874\n",
            "Epoch 8171/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2116 - accuracy: 0.2951 - val_loss: 2.2135 - val_accuracy: 0.2874\n",
            "Epoch 8172/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2116 - accuracy: 0.2952 - val_loss: 2.2135 - val_accuracy: 0.2875\n",
            "Epoch 8173/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2116 - accuracy: 0.2952 - val_loss: 2.2135 - val_accuracy: 0.2875\n",
            "Epoch 8174/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2116 - accuracy: 0.2952 - val_loss: 2.2135 - val_accuracy: 0.2875\n",
            "Epoch 8175/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2116 - accuracy: 0.2952 - val_loss: 2.2135 - val_accuracy: 0.2875\n",
            "Epoch 8176/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2116 - accuracy: 0.2952 - val_loss: 2.2135 - val_accuracy: 0.2875\n",
            "Epoch 8177/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2116 - accuracy: 0.2953 - val_loss: 2.2135 - val_accuracy: 0.2875\n",
            "Epoch 8178/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2116 - accuracy: 0.2953 - val_loss: 2.2135 - val_accuracy: 0.2875\n",
            "Epoch 8179/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2116 - accuracy: 0.2953 - val_loss: 2.2135 - val_accuracy: 0.2875\n",
            "Epoch 8180/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2116 - accuracy: 0.2953 - val_loss: 2.2134 - val_accuracy: 0.2875\n",
            "Epoch 8181/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2116 - accuracy: 0.2953 - val_loss: 2.2134 - val_accuracy: 0.2875\n",
            "Epoch 8182/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2115 - accuracy: 0.2954 - val_loss: 2.2134 - val_accuracy: 0.2875\n",
            "Epoch 8183/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2115 - accuracy: 0.2954 - val_loss: 2.2134 - val_accuracy: 0.2875\n",
            "Epoch 8184/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2115 - accuracy: 0.2955 - val_loss: 2.2134 - val_accuracy: 0.2875\n",
            "Epoch 8185/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2115 - accuracy: 0.2955 - val_loss: 2.2134 - val_accuracy: 0.2875\n",
            "Epoch 8186/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2115 - accuracy: 0.2955 - val_loss: 2.2134 - val_accuracy: 0.2876\n",
            "Epoch 8187/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2115 - accuracy: 0.2955 - val_loss: 2.2134 - val_accuracy: 0.2876\n",
            "Epoch 8188/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2115 - accuracy: 0.2956 - val_loss: 2.2134 - val_accuracy: 0.2876\n",
            "Epoch 8189/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2115 - accuracy: 0.2956 - val_loss: 2.2134 - val_accuracy: 0.2876\n",
            "Epoch 8190/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2115 - accuracy: 0.2956 - val_loss: 2.2134 - val_accuracy: 0.2876\n",
            "Epoch 8191/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2115 - accuracy: 0.2957 - val_loss: 2.2133 - val_accuracy: 0.2876\n",
            "Epoch 8192/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2115 - accuracy: 0.2957 - val_loss: 2.2133 - val_accuracy: 0.2876\n",
            "Epoch 8193/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2114 - accuracy: 0.2957 - val_loss: 2.2133 - val_accuracy: 0.2877\n",
            "Epoch 8194/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2114 - accuracy: 0.2957 - val_loss: 2.2133 - val_accuracy: 0.2877\n",
            "Epoch 8195/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2114 - accuracy: 0.2957 - val_loss: 2.2133 - val_accuracy: 0.2877\n",
            "Epoch 8196/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2114 - accuracy: 0.2958 - val_loss: 2.2133 - val_accuracy: 0.2878\n",
            "Epoch 8197/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2114 - accuracy: 0.2958 - val_loss: 2.2133 - val_accuracy: 0.2880\n",
            "Epoch 8198/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2114 - accuracy: 0.2958 - val_loss: 2.2133 - val_accuracy: 0.2881\n",
            "Epoch 8199/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2114 - accuracy: 0.2958 - val_loss: 2.2133 - val_accuracy: 0.2881\n",
            "Epoch 8200/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2114 - accuracy: 0.2958 - val_loss: 2.2133 - val_accuracy: 0.2881\n",
            "Epoch 8201/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2114 - accuracy: 0.2958 - val_loss: 2.2133 - val_accuracy: 0.2882\n",
            "Epoch 8202/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2114 - accuracy: 0.2959 - val_loss: 2.2132 - val_accuracy: 0.2882\n",
            "Epoch 8203/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2113 - accuracy: 0.2959 - val_loss: 2.2132 - val_accuracy: 0.2882\n",
            "Epoch 8204/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 2.2113 - accuracy: 0.2959 - val_loss: 2.2132 - val_accuracy: 0.2882\n",
            "Epoch 8205/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2113 - accuracy: 0.2959 - val_loss: 2.2132 - val_accuracy: 0.2882\n",
            "Epoch 8206/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2113 - accuracy: 0.2960 - val_loss: 2.2132 - val_accuracy: 0.2882\n",
            "Epoch 8207/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2113 - accuracy: 0.2960 - val_loss: 2.2132 - val_accuracy: 0.2882\n",
            "Epoch 8208/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2113 - accuracy: 0.2961 - val_loss: 2.2132 - val_accuracy: 0.2882\n",
            "Epoch 8209/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2113 - accuracy: 0.2961 - val_loss: 2.2132 - val_accuracy: 0.2882\n",
            "Epoch 8210/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2113 - accuracy: 0.2961 - val_loss: 2.2132 - val_accuracy: 0.2882\n",
            "Epoch 8211/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2113 - accuracy: 0.2961 - val_loss: 2.2132 - val_accuracy: 0.2882\n",
            "Epoch 8212/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2113 - accuracy: 0.2961 - val_loss: 2.2132 - val_accuracy: 0.2882\n",
            "Epoch 8213/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2113 - accuracy: 0.2962 - val_loss: 2.2131 - val_accuracy: 0.2883\n",
            "Epoch 8214/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2112 - accuracy: 0.2962 - val_loss: 2.2131 - val_accuracy: 0.2883\n",
            "Epoch 8215/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2112 - accuracy: 0.2962 - val_loss: 2.2131 - val_accuracy: 0.2883\n",
            "Epoch 8216/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2112 - accuracy: 0.2962 - val_loss: 2.2131 - val_accuracy: 0.2883\n",
            "Epoch 8217/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2112 - accuracy: 0.2962 - val_loss: 2.2131 - val_accuracy: 0.2883\n",
            "Epoch 8218/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2112 - accuracy: 0.2962 - val_loss: 2.2131 - val_accuracy: 0.2883\n",
            "Epoch 8219/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2112 - accuracy: 0.2963 - val_loss: 2.2131 - val_accuracy: 0.2883\n",
            "Epoch 8220/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2112 - accuracy: 0.2963 - val_loss: 2.2131 - val_accuracy: 0.2883\n",
            "Epoch 8221/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2112 - accuracy: 0.2963 - val_loss: 2.2131 - val_accuracy: 0.2884\n",
            "Epoch 8222/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2112 - accuracy: 0.2963 - val_loss: 2.2131 - val_accuracy: 0.2885\n",
            "Epoch 8223/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2112 - accuracy: 0.2963 - val_loss: 2.2130 - val_accuracy: 0.2885\n",
            "Epoch 8224/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2112 - accuracy: 0.2963 - val_loss: 2.2130 - val_accuracy: 0.2885\n",
            "Epoch 8225/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2111 - accuracy: 0.2964 - val_loss: 2.2130 - val_accuracy: 0.2885\n",
            "Epoch 8226/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2111 - accuracy: 0.2964 - val_loss: 2.2130 - val_accuracy: 0.2885\n",
            "Epoch 8227/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2111 - accuracy: 0.2964 - val_loss: 2.2130 - val_accuracy: 0.2886\n",
            "Epoch 8228/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2111 - accuracy: 0.2964 - val_loss: 2.2130 - val_accuracy: 0.2886\n",
            "Epoch 8229/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2111 - accuracy: 0.2965 - val_loss: 2.2130 - val_accuracy: 0.2887\n",
            "Epoch 8230/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2111 - accuracy: 0.2965 - val_loss: 2.2130 - val_accuracy: 0.2887\n",
            "Epoch 8231/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2111 - accuracy: 0.2965 - val_loss: 2.2130 - val_accuracy: 0.2887\n",
            "Epoch 8232/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.2111 - accuracy: 0.2966 - val_loss: 2.2130 - val_accuracy: 0.2887\n",
            "Epoch 8233/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2111 - accuracy: 0.2966 - val_loss: 2.2130 - val_accuracy: 0.2887\n",
            "Epoch 8234/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2111 - accuracy: 0.2966 - val_loss: 2.2129 - val_accuracy: 0.2888\n",
            "Epoch 8235/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2110 - accuracy: 0.2966 - val_loss: 2.2129 - val_accuracy: 0.2888\n",
            "Epoch 8236/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2110 - accuracy: 0.2967 - val_loss: 2.2129 - val_accuracy: 0.2888\n",
            "Epoch 8237/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2110 - accuracy: 0.2967 - val_loss: 2.2129 - val_accuracy: 0.2889\n",
            "Epoch 8238/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2110 - accuracy: 0.2967 - val_loss: 2.2129 - val_accuracy: 0.2889\n",
            "Epoch 8239/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2110 - accuracy: 0.2967 - val_loss: 2.2129 - val_accuracy: 0.2889\n",
            "Epoch 8240/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2110 - accuracy: 0.2967 - val_loss: 2.2129 - val_accuracy: 0.2889\n",
            "Epoch 8241/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2110 - accuracy: 0.2968 - val_loss: 2.2129 - val_accuracy: 0.2889\n",
            "Epoch 8242/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2110 - accuracy: 0.2968 - val_loss: 2.2129 - val_accuracy: 0.2889\n",
            "Epoch 8243/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2110 - accuracy: 0.2968 - val_loss: 2.2129 - val_accuracy: 0.2891\n",
            "Epoch 8244/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2110 - accuracy: 0.2968 - val_loss: 2.2129 - val_accuracy: 0.2892\n",
            "Epoch 8245/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2110 - accuracy: 0.2968 - val_loss: 2.2128 - val_accuracy: 0.2892\n",
            "Epoch 8246/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2109 - accuracy: 0.2969 - val_loss: 2.2128 - val_accuracy: 0.2892\n",
            "Epoch 8247/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2109 - accuracy: 0.2969 - val_loss: 2.2128 - val_accuracy: 0.2892\n",
            "Epoch 8248/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2109 - accuracy: 0.2969 - val_loss: 2.2128 - val_accuracy: 0.2892\n",
            "Epoch 8249/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2109 - accuracy: 0.2969 - val_loss: 2.2128 - val_accuracy: 0.2894\n",
            "Epoch 8250/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2109 - accuracy: 0.2969 - val_loss: 2.2128 - val_accuracy: 0.2894\n",
            "Epoch 8251/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2109 - accuracy: 0.2970 - val_loss: 2.2128 - val_accuracy: 0.2896\n",
            "Epoch 8252/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2109 - accuracy: 0.2970 - val_loss: 2.2128 - val_accuracy: 0.2895\n",
            "Epoch 8253/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2109 - accuracy: 0.2970 - val_loss: 2.2128 - val_accuracy: 0.2896\n",
            "Epoch 8254/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2109 - accuracy: 0.2970 - val_loss: 2.2128 - val_accuracy: 0.2896\n",
            "Epoch 8255/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2109 - accuracy: 0.2970 - val_loss: 2.2128 - val_accuracy: 0.2896\n",
            "Epoch 8256/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2109 - accuracy: 0.2970 - val_loss: 2.2127 - val_accuracy: 0.2896\n",
            "Epoch 8257/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2108 - accuracy: 0.2970 - val_loss: 2.2127 - val_accuracy: 0.2896\n",
            "Epoch 8258/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2108 - accuracy: 0.2971 - val_loss: 2.2127 - val_accuracy: 0.2896\n",
            "Epoch 8259/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2108 - accuracy: 0.2971 - val_loss: 2.2127 - val_accuracy: 0.2896\n",
            "Epoch 8260/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2108 - accuracy: 0.2972 - val_loss: 2.2127 - val_accuracy: 0.2897\n",
            "Epoch 8261/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2108 - accuracy: 0.2972 - val_loss: 2.2127 - val_accuracy: 0.2898\n",
            "Epoch 8262/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2108 - accuracy: 0.2972 - val_loss: 2.2127 - val_accuracy: 0.2898\n",
            "Epoch 8263/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2108 - accuracy: 0.2972 - val_loss: 2.2127 - val_accuracy: 0.2898\n",
            "Epoch 8264/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2108 - accuracy: 0.2972 - val_loss: 2.2127 - val_accuracy: 0.2898\n",
            "Epoch 8265/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2108 - accuracy: 0.2973 - val_loss: 2.2127 - val_accuracy: 0.2898\n",
            "Epoch 8266/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2108 - accuracy: 0.2973 - val_loss: 2.2127 - val_accuracy: 0.2898\n",
            "Epoch 8267/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2108 - accuracy: 0.2973 - val_loss: 2.2126 - val_accuracy: 0.2898\n",
            "Epoch 8268/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2107 - accuracy: 0.2973 - val_loss: 2.2126 - val_accuracy: 0.2899\n",
            "Epoch 8269/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2107 - accuracy: 0.2974 - val_loss: 2.2126 - val_accuracy: 0.2899\n",
            "Epoch 8270/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2107 - accuracy: 0.2974 - val_loss: 2.2126 - val_accuracy: 0.2899\n",
            "Epoch 8271/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2107 - accuracy: 0.2975 - val_loss: 2.2126 - val_accuracy: 0.2900\n",
            "Epoch 8272/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2107 - accuracy: 0.2975 - val_loss: 2.2126 - val_accuracy: 0.2900\n",
            "Epoch 8273/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2107 - accuracy: 0.2975 - val_loss: 2.2126 - val_accuracy: 0.2900\n",
            "Epoch 8274/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2107 - accuracy: 0.2975 - val_loss: 2.2126 - val_accuracy: 0.2900\n",
            "Epoch 8275/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2107 - accuracy: 0.2975 - val_loss: 2.2126 - val_accuracy: 0.2900\n",
            "Epoch 8276/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2107 - accuracy: 0.2976 - val_loss: 2.2126 - val_accuracy: 0.2900\n",
            "Epoch 8277/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2107 - accuracy: 0.2976 - val_loss: 2.2125 - val_accuracy: 0.2900\n",
            "Epoch 8278/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2106 - accuracy: 0.2977 - val_loss: 2.2125 - val_accuracy: 0.2900\n",
            "Epoch 8279/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2106 - accuracy: 0.2977 - val_loss: 2.2125 - val_accuracy: 0.2901\n",
            "Epoch 8280/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2106 - accuracy: 0.2977 - val_loss: 2.2125 - val_accuracy: 0.2901\n",
            "Epoch 8281/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2106 - accuracy: 0.2977 - val_loss: 2.2125 - val_accuracy: 0.2901\n",
            "Epoch 8282/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2106 - accuracy: 0.2977 - val_loss: 2.2125 - val_accuracy: 0.2902\n",
            "Epoch 8283/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2106 - accuracy: 0.2977 - val_loss: 2.2125 - val_accuracy: 0.2902\n",
            "Epoch 8284/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2106 - accuracy: 0.2977 - val_loss: 2.2125 - val_accuracy: 0.2902\n",
            "Epoch 8285/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2106 - accuracy: 0.2978 - val_loss: 2.2125 - val_accuracy: 0.2902\n",
            "Epoch 8286/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2106 - accuracy: 0.2978 - val_loss: 2.2125 - val_accuracy: 0.2902\n",
            "Epoch 8287/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2106 - accuracy: 0.2979 - val_loss: 2.2125 - val_accuracy: 0.2902\n",
            "Epoch 8288/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2106 - accuracy: 0.2979 - val_loss: 2.2124 - val_accuracy: 0.2904\n",
            "Epoch 8289/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2105 - accuracy: 0.2979 - val_loss: 2.2124 - val_accuracy: 0.2904\n",
            "Epoch 8290/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.2105 - accuracy: 0.2979 - val_loss: 2.2124 - val_accuracy: 0.2905\n",
            "Epoch 8291/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2105 - accuracy: 0.2979 - val_loss: 2.2124 - val_accuracy: 0.2905\n",
            "Epoch 8292/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2105 - accuracy: 0.2979 - val_loss: 2.2124 - val_accuracy: 0.2905\n",
            "Epoch 8293/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2105 - accuracy: 0.2980 - val_loss: 2.2124 - val_accuracy: 0.2905\n",
            "Epoch 8294/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2105 - accuracy: 0.2980 - val_loss: 2.2124 - val_accuracy: 0.2905\n",
            "Epoch 8295/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2105 - accuracy: 0.2980 - val_loss: 2.2124 - val_accuracy: 0.2905\n",
            "Epoch 8296/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2105 - accuracy: 0.2981 - val_loss: 2.2124 - val_accuracy: 0.2905\n",
            "Epoch 8297/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2105 - accuracy: 0.2981 - val_loss: 2.2124 - val_accuracy: 0.2905\n",
            "Epoch 8298/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2105 - accuracy: 0.2981 - val_loss: 2.2124 - val_accuracy: 0.2905\n",
            "Epoch 8299/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2105 - accuracy: 0.2982 - val_loss: 2.2123 - val_accuracy: 0.2905\n",
            "Epoch 8300/10000\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 2.2104 - accuracy: 0.2982 - val_loss: 2.2123 - val_accuracy: 0.2905\n",
            "Epoch 8301/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2104 - accuracy: 0.2982 - val_loss: 2.2123 - val_accuracy: 0.2905\n",
            "Epoch 8302/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2104 - accuracy: 0.2982 - val_loss: 2.2123 - val_accuracy: 0.2905\n",
            "Epoch 8303/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2104 - accuracy: 0.2982 - val_loss: 2.2123 - val_accuracy: 0.2905\n",
            "Epoch 8304/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2104 - accuracy: 0.2983 - val_loss: 2.2123 - val_accuracy: 0.2905\n",
            "Epoch 8305/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2104 - accuracy: 0.2983 - val_loss: 2.2123 - val_accuracy: 0.2905\n",
            "Epoch 8306/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2104 - accuracy: 0.2983 - val_loss: 2.2123 - val_accuracy: 0.2905\n",
            "Epoch 8307/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2104 - accuracy: 0.2983 - val_loss: 2.2123 - val_accuracy: 0.2905\n",
            "Epoch 8308/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2104 - accuracy: 0.2983 - val_loss: 2.2123 - val_accuracy: 0.2905\n",
            "Epoch 8309/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2104 - accuracy: 0.2984 - val_loss: 2.2123 - val_accuracy: 0.2905\n",
            "Epoch 8310/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.2104 - accuracy: 0.2984 - val_loss: 2.2122 - val_accuracy: 0.2906\n",
            "Epoch 8311/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2103 - accuracy: 0.2984 - val_loss: 2.2122 - val_accuracy: 0.2906\n",
            "Epoch 8312/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2103 - accuracy: 0.2984 - val_loss: 2.2122 - val_accuracy: 0.2906\n",
            "Epoch 8313/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2103 - accuracy: 0.2984 - val_loss: 2.2122 - val_accuracy: 0.2907\n",
            "Epoch 8314/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2103 - accuracy: 0.2984 - val_loss: 2.2122 - val_accuracy: 0.2907\n",
            "Epoch 8315/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2103 - accuracy: 0.2985 - val_loss: 2.2122 - val_accuracy: 0.2908\n",
            "Epoch 8316/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2103 - accuracy: 0.2985 - val_loss: 2.2122 - val_accuracy: 0.2908\n",
            "Epoch 8317/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2103 - accuracy: 0.2985 - val_loss: 2.2122 - val_accuracy: 0.2908\n",
            "Epoch 8318/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2103 - accuracy: 0.2986 - val_loss: 2.2122 - val_accuracy: 0.2908\n",
            "Epoch 8319/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2103 - accuracy: 0.2986 - val_loss: 2.2122 - val_accuracy: 0.2907\n",
            "Epoch 8320/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2103 - accuracy: 0.2986 - val_loss: 2.2122 - val_accuracy: 0.2907\n",
            "Epoch 8321/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2102 - accuracy: 0.2986 - val_loss: 2.2121 - val_accuracy: 0.2907\n",
            "Epoch 8322/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2102 - accuracy: 0.2986 - val_loss: 2.2121 - val_accuracy: 0.2907\n",
            "Epoch 8323/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2102 - accuracy: 0.2986 - val_loss: 2.2121 - val_accuracy: 0.2907\n",
            "Epoch 8324/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2102 - accuracy: 0.2987 - val_loss: 2.2121 - val_accuracy: 0.2908\n",
            "Epoch 8325/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2102 - accuracy: 0.2987 - val_loss: 2.2121 - val_accuracy: 0.2910\n",
            "Epoch 8326/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2102 - accuracy: 0.2987 - val_loss: 2.2121 - val_accuracy: 0.2911\n",
            "Epoch 8327/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2102 - accuracy: 0.2987 - val_loss: 2.2121 - val_accuracy: 0.2912\n",
            "Epoch 8328/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2102 - accuracy: 0.2988 - val_loss: 2.2121 - val_accuracy: 0.2912\n",
            "Epoch 8329/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2102 - accuracy: 0.2988 - val_loss: 2.2121 - val_accuracy: 0.2912\n",
            "Epoch 8330/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2102 - accuracy: 0.2988 - val_loss: 2.2121 - val_accuracy: 0.2912\n",
            "Epoch 8331/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2102 - accuracy: 0.2988 - val_loss: 2.2121 - val_accuracy: 0.2912\n",
            "Epoch 8332/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2101 - accuracy: 0.2989 - val_loss: 2.2120 - val_accuracy: 0.2913\n",
            "Epoch 8333/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2101 - accuracy: 0.2989 - val_loss: 2.2120 - val_accuracy: 0.2913\n",
            "Epoch 8334/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2101 - accuracy: 0.2989 - val_loss: 2.2120 - val_accuracy: 0.2913\n",
            "Epoch 8335/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2101 - accuracy: 0.2990 - val_loss: 2.2120 - val_accuracy: 0.2913\n",
            "Epoch 8336/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2101 - accuracy: 0.2991 - val_loss: 2.2120 - val_accuracy: 0.2913\n",
            "Epoch 8337/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2101 - accuracy: 0.2991 - val_loss: 2.2120 - val_accuracy: 0.2914\n",
            "Epoch 8338/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2101 - accuracy: 0.2991 - val_loss: 2.2120 - val_accuracy: 0.2915\n",
            "Epoch 8339/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2101 - accuracy: 0.2991 - val_loss: 2.2120 - val_accuracy: 0.2915\n",
            "Epoch 8340/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2101 - accuracy: 0.2991 - val_loss: 2.2120 - val_accuracy: 0.2915\n",
            "Epoch 8341/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2101 - accuracy: 0.2991 - val_loss: 2.2120 - val_accuracy: 0.2915\n",
            "Epoch 8342/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2101 - accuracy: 0.2992 - val_loss: 2.2119 - val_accuracy: 0.2915\n",
            "Epoch 8343/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2100 - accuracy: 0.2992 - val_loss: 2.2119 - val_accuracy: 0.2915\n",
            "Epoch 8344/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2100 - accuracy: 0.2992 - val_loss: 2.2119 - val_accuracy: 0.2915\n",
            "Epoch 8345/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2100 - accuracy: 0.2993 - val_loss: 2.2119 - val_accuracy: 0.2915\n",
            "Epoch 8346/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2100 - accuracy: 0.2993 - val_loss: 2.2119 - val_accuracy: 0.2917\n",
            "Epoch 8347/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2100 - accuracy: 0.2993 - val_loss: 2.2119 - val_accuracy: 0.2917\n",
            "Epoch 8348/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2100 - accuracy: 0.2993 - val_loss: 2.2119 - val_accuracy: 0.2917\n",
            "Epoch 8349/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2100 - accuracy: 0.2993 - val_loss: 2.2119 - val_accuracy: 0.2917\n",
            "Epoch 8350/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2100 - accuracy: 0.2993 - val_loss: 2.2119 - val_accuracy: 0.2919\n",
            "Epoch 8351/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2100 - accuracy: 0.2994 - val_loss: 2.2119 - val_accuracy: 0.2919\n",
            "Epoch 8352/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2100 - accuracy: 0.2994 - val_loss: 2.2119 - val_accuracy: 0.2920\n",
            "Epoch 8353/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2100 - accuracy: 0.2994 - val_loss: 2.2118 - val_accuracy: 0.2920\n",
            "Epoch 8354/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2099 - accuracy: 0.2995 - val_loss: 2.2118 - val_accuracy: 0.2920\n",
            "Epoch 8355/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2099 - accuracy: 0.2995 - val_loss: 2.2118 - val_accuracy: 0.2920\n",
            "Epoch 8356/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2099 - accuracy: 0.2995 - val_loss: 2.2118 - val_accuracy: 0.2920\n",
            "Epoch 8357/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2099 - accuracy: 0.2995 - val_loss: 2.2118 - val_accuracy: 0.2920\n",
            "Epoch 8358/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2099 - accuracy: 0.2995 - val_loss: 2.2118 - val_accuracy: 0.2920\n",
            "Epoch 8359/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2099 - accuracy: 0.2996 - val_loss: 2.2118 - val_accuracy: 0.2920\n",
            "Epoch 8360/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2099 - accuracy: 0.2996 - val_loss: 2.2118 - val_accuracy: 0.2920\n",
            "Epoch 8361/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2099 - accuracy: 0.2996 - val_loss: 2.2118 - val_accuracy: 0.2920\n",
            "Epoch 8362/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2099 - accuracy: 0.2996 - val_loss: 2.2118 - val_accuracy: 0.2921\n",
            "Epoch 8363/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2099 - accuracy: 0.2997 - val_loss: 2.2118 - val_accuracy: 0.2921\n",
            "Epoch 8364/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2099 - accuracy: 0.2997 - val_loss: 2.2117 - val_accuracy: 0.2922\n",
            "Epoch 8365/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2098 - accuracy: 0.2997 - val_loss: 2.2117 - val_accuracy: 0.2922\n",
            "Epoch 8366/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2098 - accuracy: 0.2997 - val_loss: 2.2117 - val_accuracy: 0.2922\n",
            "Epoch 8367/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2098 - accuracy: 0.2997 - val_loss: 2.2117 - val_accuracy: 0.2922\n",
            "Epoch 8368/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2098 - accuracy: 0.2998 - val_loss: 2.2117 - val_accuracy: 0.2922\n",
            "Epoch 8369/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2098 - accuracy: 0.2998 - val_loss: 2.2117 - val_accuracy: 0.2922\n",
            "Epoch 8370/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2098 - accuracy: 0.2998 - val_loss: 2.2117 - val_accuracy: 0.2922\n",
            "Epoch 8371/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2098 - accuracy: 0.2998 - val_loss: 2.2117 - val_accuracy: 0.2922\n",
            "Epoch 8372/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2098 - accuracy: 0.2999 - val_loss: 2.2117 - val_accuracy: 0.2922\n",
            "Epoch 8373/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2098 - accuracy: 0.2999 - val_loss: 2.2117 - val_accuracy: 0.2922\n",
            "Epoch 8374/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2098 - accuracy: 0.2999 - val_loss: 2.2117 - val_accuracy: 0.2922\n",
            "Epoch 8375/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2097 - accuracy: 0.2999 - val_loss: 2.2116 - val_accuracy: 0.2922\n",
            "Epoch 8376/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2097 - accuracy: 0.2999 - val_loss: 2.2116 - val_accuracy: 0.2922\n",
            "Epoch 8377/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2097 - accuracy: 0.3000 - val_loss: 2.2116 - val_accuracy: 0.2922\n",
            "Epoch 8378/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2097 - accuracy: 0.3000 - val_loss: 2.2116 - val_accuracy: 0.2922\n",
            "Epoch 8379/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2097 - accuracy: 0.3000 - val_loss: 2.2116 - val_accuracy: 0.2923\n",
            "Epoch 8380/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2097 - accuracy: 0.3000 - val_loss: 2.2116 - val_accuracy: 0.2924\n",
            "Epoch 8381/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2097 - accuracy: 0.3000 - val_loss: 2.2116 - val_accuracy: 0.2924\n",
            "Epoch 8382/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2097 - accuracy: 0.3000 - val_loss: 2.2116 - val_accuracy: 0.2924\n",
            "Epoch 8383/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2097 - accuracy: 0.3001 - val_loss: 2.2116 - val_accuracy: 0.2925\n",
            "Epoch 8384/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2097 - accuracy: 0.3001 - val_loss: 2.2116 - val_accuracy: 0.2925\n",
            "Epoch 8385/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2097 - accuracy: 0.3001 - val_loss: 2.2116 - val_accuracy: 0.2925\n",
            "Epoch 8386/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2096 - accuracy: 0.3001 - val_loss: 2.2115 - val_accuracy: 0.2925\n",
            "Epoch 8387/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2096 - accuracy: 0.3001 - val_loss: 2.2115 - val_accuracy: 0.2925\n",
            "Epoch 8388/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2096 - accuracy: 0.3001 - val_loss: 2.2115 - val_accuracy: 0.2925\n",
            "Epoch 8389/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2096 - accuracy: 0.3002 - val_loss: 2.2115 - val_accuracy: 0.2925\n",
            "Epoch 8390/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2096 - accuracy: 0.3002 - val_loss: 2.2115 - val_accuracy: 0.2925\n",
            "Epoch 8391/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2096 - accuracy: 0.3002 - val_loss: 2.2115 - val_accuracy: 0.2925\n",
            "Epoch 8392/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2096 - accuracy: 0.3001 - val_loss: 2.2115 - val_accuracy: 0.2926\n",
            "Epoch 8393/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2096 - accuracy: 0.3002 - val_loss: 2.2115 - val_accuracy: 0.2926\n",
            "Epoch 8394/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2096 - accuracy: 0.3002 - val_loss: 2.2115 - val_accuracy: 0.2926\n",
            "Epoch 8395/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2096 - accuracy: 0.3003 - val_loss: 2.2115 - val_accuracy: 0.2927\n",
            "Epoch 8396/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2096 - accuracy: 0.3003 - val_loss: 2.2115 - val_accuracy: 0.2927\n",
            "Epoch 8397/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2095 - accuracy: 0.3003 - val_loss: 2.2114 - val_accuracy: 0.2927\n",
            "Epoch 8398/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2095 - accuracy: 0.3004 - val_loss: 2.2114 - val_accuracy: 0.2927\n",
            "Epoch 8399/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2095 - accuracy: 0.3004 - val_loss: 2.2114 - val_accuracy: 0.2927\n",
            "Epoch 8400/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2095 - accuracy: 0.3004 - val_loss: 2.2114 - val_accuracy: 0.2927\n",
            "Epoch 8401/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2095 - accuracy: 0.3005 - val_loss: 2.2114 - val_accuracy: 0.2927\n",
            "Epoch 8402/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2095 - accuracy: 0.3005 - val_loss: 2.2114 - val_accuracy: 0.2928\n",
            "Epoch 8403/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2095 - accuracy: 0.3005 - val_loss: 2.2114 - val_accuracy: 0.2928\n",
            "Epoch 8404/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2095 - accuracy: 0.3005 - val_loss: 2.2114 - val_accuracy: 0.2928\n",
            "Epoch 8405/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2095 - accuracy: 0.3005 - val_loss: 2.2114 - val_accuracy: 0.2928\n",
            "Epoch 8406/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.2095 - accuracy: 0.3006 - val_loss: 2.2114 - val_accuracy: 0.2928\n",
            "Epoch 8407/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2095 - accuracy: 0.3006 - val_loss: 2.2114 - val_accuracy: 0.2929\n",
            "Epoch 8408/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2094 - accuracy: 0.3006 - val_loss: 2.2113 - val_accuracy: 0.2930\n",
            "Epoch 8409/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2094 - accuracy: 0.3006 - val_loss: 2.2113 - val_accuracy: 0.2930\n",
            "Epoch 8410/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2094 - accuracy: 0.3006 - val_loss: 2.2113 - val_accuracy: 0.2930\n",
            "Epoch 8411/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2094 - accuracy: 0.3007 - val_loss: 2.2113 - val_accuracy: 0.2930\n",
            "Epoch 8412/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2094 - accuracy: 0.3007 - val_loss: 2.2113 - val_accuracy: 0.2930\n",
            "Epoch 8413/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2094 - accuracy: 0.3007 - val_loss: 2.2113 - val_accuracy: 0.2930\n",
            "Epoch 8414/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2094 - accuracy: 0.3008 - val_loss: 2.2113 - val_accuracy: 0.2930\n",
            "Epoch 8415/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2094 - accuracy: 0.3007 - val_loss: 2.2113 - val_accuracy: 0.2930\n",
            "Epoch 8416/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2094 - accuracy: 0.3008 - val_loss: 2.2113 - val_accuracy: 0.2930\n",
            "Epoch 8417/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2094 - accuracy: 0.3008 - val_loss: 2.2113 - val_accuracy: 0.2930\n",
            "Epoch 8418/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2094 - accuracy: 0.3009 - val_loss: 2.2113 - val_accuracy: 0.2931\n",
            "Epoch 8419/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2093 - accuracy: 0.3009 - val_loss: 2.2112 - val_accuracy: 0.2931\n",
            "Epoch 8420/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2093 - accuracy: 0.3009 - val_loss: 2.2112 - val_accuracy: 0.2932\n",
            "Epoch 8421/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2093 - accuracy: 0.3009 - val_loss: 2.2112 - val_accuracy: 0.2932\n",
            "Epoch 8422/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2093 - accuracy: 0.3009 - val_loss: 2.2112 - val_accuracy: 0.2932\n",
            "Epoch 8423/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2093 - accuracy: 0.3009 - val_loss: 2.2112 - val_accuracy: 0.2932\n",
            "Epoch 8424/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2093 - accuracy: 0.3009 - val_loss: 2.2112 - val_accuracy: 0.2933\n",
            "Epoch 8425/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2093 - accuracy: 0.3009 - val_loss: 2.2112 - val_accuracy: 0.2934\n",
            "Epoch 8426/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2093 - accuracy: 0.3009 - val_loss: 2.2112 - val_accuracy: 0.2934\n",
            "Epoch 8427/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2093 - accuracy: 0.3010 - val_loss: 2.2112 - val_accuracy: 0.2934\n",
            "Epoch 8428/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2093 - accuracy: 0.3010 - val_loss: 2.2112 - val_accuracy: 0.2934\n",
            "Epoch 8429/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2093 - accuracy: 0.3010 - val_loss: 2.2112 - val_accuracy: 0.2936\n",
            "Epoch 8430/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2092 - accuracy: 0.3010 - val_loss: 2.2111 - val_accuracy: 0.2937\n",
            "Epoch 8431/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2092 - accuracy: 0.3010 - val_loss: 2.2111 - val_accuracy: 0.2937\n",
            "Epoch 8432/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2092 - accuracy: 0.3011 - val_loss: 2.2111 - val_accuracy: 0.2938\n",
            "Epoch 8433/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2092 - accuracy: 0.3011 - val_loss: 2.2111 - val_accuracy: 0.2938\n",
            "Epoch 8434/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2092 - accuracy: 0.3011 - val_loss: 2.2111 - val_accuracy: 0.2938\n",
            "Epoch 8435/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2092 - accuracy: 0.3011 - val_loss: 2.2111 - val_accuracy: 0.2938\n",
            "Epoch 8436/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2092 - accuracy: 0.3011 - val_loss: 2.2111 - val_accuracy: 0.2938\n",
            "Epoch 8437/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2092 - accuracy: 0.3012 - val_loss: 2.2111 - val_accuracy: 0.2939\n",
            "Epoch 8438/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2092 - accuracy: 0.3012 - val_loss: 2.2111 - val_accuracy: 0.2939\n",
            "Epoch 8439/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2092 - accuracy: 0.3012 - val_loss: 2.2111 - val_accuracy: 0.2939\n",
            "Epoch 8440/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2091 - accuracy: 0.3012 - val_loss: 2.2111 - val_accuracy: 0.2939\n",
            "Epoch 8441/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2091 - accuracy: 0.3012 - val_loss: 2.2110 - val_accuracy: 0.2939\n",
            "Epoch 8442/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2091 - accuracy: 0.3013 - val_loss: 2.2110 - val_accuracy: 0.2939\n",
            "Epoch 8443/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2091 - accuracy: 0.3013 - val_loss: 2.2110 - val_accuracy: 0.2939\n",
            "Epoch 8444/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2091 - accuracy: 0.3014 - val_loss: 2.2110 - val_accuracy: 0.2940\n",
            "Epoch 8445/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2091 - accuracy: 0.3014 - val_loss: 2.2110 - val_accuracy: 0.2940\n",
            "Epoch 8446/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2091 - accuracy: 0.3014 - val_loss: 2.2110 - val_accuracy: 0.2941\n",
            "Epoch 8447/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2091 - accuracy: 0.3015 - val_loss: 2.2110 - val_accuracy: 0.2941\n",
            "Epoch 8448/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2091 - accuracy: 0.3015 - val_loss: 2.2110 - val_accuracy: 0.2941\n",
            "Epoch 8449/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2091 - accuracy: 0.3015 - val_loss: 2.2110 - val_accuracy: 0.2941\n",
            "Epoch 8450/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2091 - accuracy: 0.3016 - val_loss: 2.2110 - val_accuracy: 0.2941\n",
            "Epoch 8451/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2090 - accuracy: 0.3016 - val_loss: 2.2110 - val_accuracy: 0.2941\n",
            "Epoch 8452/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2090 - accuracy: 0.3017 - val_loss: 2.2109 - val_accuracy: 0.2942\n",
            "Epoch 8453/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2090 - accuracy: 0.3017 - val_loss: 2.2109 - val_accuracy: 0.2942\n",
            "Epoch 8454/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2090 - accuracy: 0.3017 - val_loss: 2.2109 - val_accuracy: 0.2944\n",
            "Epoch 8455/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2090 - accuracy: 0.3017 - val_loss: 2.2109 - val_accuracy: 0.2945\n",
            "Epoch 8456/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2090 - accuracy: 0.3017 - val_loss: 2.2109 - val_accuracy: 0.2945\n",
            "Epoch 8457/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2090 - accuracy: 0.3017 - val_loss: 2.2109 - val_accuracy: 0.2945\n",
            "Epoch 8458/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2090 - accuracy: 0.3017 - val_loss: 2.2109 - val_accuracy: 0.2945\n",
            "Epoch 8459/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2090 - accuracy: 0.3018 - val_loss: 2.2109 - val_accuracy: 0.2946\n",
            "Epoch 8460/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2090 - accuracy: 0.3018 - val_loss: 2.2109 - val_accuracy: 0.2947\n",
            "Epoch 8461/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2090 - accuracy: 0.3018 - val_loss: 2.2109 - val_accuracy: 0.2947\n",
            "Epoch 8462/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2089 - accuracy: 0.3018 - val_loss: 2.2108 - val_accuracy: 0.2947\n",
            "Epoch 8463/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2089 - accuracy: 0.3019 - val_loss: 2.2108 - val_accuracy: 0.2947\n",
            "Epoch 8464/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2089 - accuracy: 0.3018 - val_loss: 2.2108 - val_accuracy: 0.2947\n",
            "Epoch 8465/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2089 - accuracy: 0.3018 - val_loss: 2.2108 - val_accuracy: 0.2948\n",
            "Epoch 8466/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2089 - accuracy: 0.3018 - val_loss: 2.2108 - val_accuracy: 0.2950\n",
            "Epoch 8467/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2089 - accuracy: 0.3018 - val_loss: 2.2108 - val_accuracy: 0.2950\n",
            "Epoch 8468/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2089 - accuracy: 0.3019 - val_loss: 2.2108 - val_accuracy: 0.2950\n",
            "Epoch 8469/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2089 - accuracy: 0.3019 - val_loss: 2.2108 - val_accuracy: 0.2950\n",
            "Epoch 8470/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2089 - accuracy: 0.3019 - val_loss: 2.2108 - val_accuracy: 0.2950\n",
            "Epoch 8471/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2089 - accuracy: 0.3019 - val_loss: 2.2108 - val_accuracy: 0.2950\n",
            "Epoch 8472/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2089 - accuracy: 0.3020 - val_loss: 2.2108 - val_accuracy: 0.2951\n",
            "Epoch 8473/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2088 - accuracy: 0.3020 - val_loss: 2.2107 - val_accuracy: 0.2952\n",
            "Epoch 8474/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2088 - accuracy: 0.3020 - val_loss: 2.2107 - val_accuracy: 0.2952\n",
            "Epoch 8475/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2088 - accuracy: 0.3020 - val_loss: 2.2107 - val_accuracy: 0.2952\n",
            "Epoch 8476/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2088 - accuracy: 0.3020 - val_loss: 2.2107 - val_accuracy: 0.2952\n",
            "Epoch 8477/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2088 - accuracy: 0.3020 - val_loss: 2.2107 - val_accuracy: 0.2953\n",
            "Epoch 8478/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2088 - accuracy: 0.3020 - val_loss: 2.2107 - val_accuracy: 0.2953\n",
            "Epoch 8479/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2088 - accuracy: 0.3020 - val_loss: 2.2107 - val_accuracy: 0.2954\n",
            "Epoch 8480/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2088 - accuracy: 0.3020 - val_loss: 2.2107 - val_accuracy: 0.2954\n",
            "Epoch 8481/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2088 - accuracy: 0.3020 - val_loss: 2.2107 - val_accuracy: 0.2954\n",
            "Epoch 8482/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2088 - accuracy: 0.3021 - val_loss: 2.2107 - val_accuracy: 0.2954\n",
            "Epoch 8483/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2088 - accuracy: 0.3021 - val_loss: 2.2107 - val_accuracy: 0.2954\n",
            "Epoch 8484/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2087 - accuracy: 0.3021 - val_loss: 2.2106 - val_accuracy: 0.2954\n",
            "Epoch 8485/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2087 - accuracy: 0.3021 - val_loss: 2.2106 - val_accuracy: 0.2954\n",
            "Epoch 8486/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2087 - accuracy: 0.3022 - val_loss: 2.2106 - val_accuracy: 0.2955\n",
            "Epoch 8487/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2087 - accuracy: 0.3022 - val_loss: 2.2106 - val_accuracy: 0.2955\n",
            "Epoch 8488/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2087 - accuracy: 0.3022 - val_loss: 2.2106 - val_accuracy: 0.2955\n",
            "Epoch 8489/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2087 - accuracy: 0.3022 - val_loss: 2.2106 - val_accuracy: 0.2955\n",
            "Epoch 8490/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2087 - accuracy: 0.3023 - val_loss: 2.2106 - val_accuracy: 0.2956\n",
            "Epoch 8491/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2087 - accuracy: 0.3023 - val_loss: 2.2106 - val_accuracy: 0.2957\n",
            "Epoch 8492/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2087 - accuracy: 0.3023 - val_loss: 2.2106 - val_accuracy: 0.2958\n",
            "Epoch 8493/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2087 - accuracy: 0.3024 - val_loss: 2.2106 - val_accuracy: 0.2958\n",
            "Epoch 8494/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2087 - accuracy: 0.3024 - val_loss: 2.2106 - val_accuracy: 0.2958\n",
            "Epoch 8495/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2086 - accuracy: 0.3024 - val_loss: 2.2105 - val_accuracy: 0.2958\n",
            "Epoch 8496/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2086 - accuracy: 0.3024 - val_loss: 2.2105 - val_accuracy: 0.2958\n",
            "Epoch 8497/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2086 - accuracy: 0.3025 - val_loss: 2.2105 - val_accuracy: 0.2958\n",
            "Epoch 8498/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2086 - accuracy: 0.3025 - val_loss: 2.2105 - val_accuracy: 0.2959\n",
            "Epoch 8499/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2086 - accuracy: 0.3025 - val_loss: 2.2105 - val_accuracy: 0.2959\n",
            "Epoch 8500/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2086 - accuracy: 0.3025 - val_loss: 2.2105 - val_accuracy: 0.2959\n",
            "Epoch 8501/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2086 - accuracy: 0.3025 - val_loss: 2.2105 - val_accuracy: 0.2959\n",
            "Epoch 8502/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2086 - accuracy: 0.3025 - val_loss: 2.2105 - val_accuracy: 0.2959\n",
            "Epoch 8503/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2086 - accuracy: 0.3025 - val_loss: 2.2105 - val_accuracy: 0.2960\n",
            "Epoch 8504/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2086 - accuracy: 0.3025 - val_loss: 2.2105 - val_accuracy: 0.2960\n",
            "Epoch 8505/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2086 - accuracy: 0.3026 - val_loss: 2.2105 - val_accuracy: 0.2960\n",
            "Epoch 8506/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2085 - accuracy: 0.3026 - val_loss: 2.2104 - val_accuracy: 0.2960\n",
            "Epoch 8507/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2085 - accuracy: 0.3026 - val_loss: 2.2104 - val_accuracy: 0.2960\n",
            "Epoch 8508/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2085 - accuracy: 0.3026 - val_loss: 2.2104 - val_accuracy: 0.2960\n",
            "Epoch 8509/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2085 - accuracy: 0.3027 - val_loss: 2.2104 - val_accuracy: 0.2960\n",
            "Epoch 8510/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2085 - accuracy: 0.3027 - val_loss: 2.2104 - val_accuracy: 0.2961\n",
            "Epoch 8511/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2085 - accuracy: 0.3027 - val_loss: 2.2104 - val_accuracy: 0.2961\n",
            "Epoch 8512/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2085 - accuracy: 0.3027 - val_loss: 2.2104 - val_accuracy: 0.2961\n",
            "Epoch 8513/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2085 - accuracy: 0.3028 - val_loss: 2.2104 - val_accuracy: 0.2961\n",
            "Epoch 8514/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2085 - accuracy: 0.3028 - val_loss: 2.2104 - val_accuracy: 0.2961\n",
            "Epoch 8515/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2085 - accuracy: 0.3029 - val_loss: 2.2104 - val_accuracy: 0.2961\n",
            "Epoch 8516/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2085 - accuracy: 0.3029 - val_loss: 2.2104 - val_accuracy: 0.2961\n",
            "Epoch 8517/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2084 - accuracy: 0.3029 - val_loss: 2.2103 - val_accuracy: 0.2961\n",
            "Epoch 8518/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2084 - accuracy: 0.3029 - val_loss: 2.2103 - val_accuracy: 0.2963\n",
            "Epoch 8519/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2084 - accuracy: 0.3029 - val_loss: 2.2103 - val_accuracy: 0.2963\n",
            "Epoch 8520/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2084 - accuracy: 0.3029 - val_loss: 2.2103 - val_accuracy: 0.2963\n",
            "Epoch 8521/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2084 - accuracy: 0.3029 - val_loss: 2.2103 - val_accuracy: 0.2963\n",
            "Epoch 8522/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2084 - accuracy: 0.3030 - val_loss: 2.2103 - val_accuracy: 0.2963\n",
            "Epoch 8523/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2084 - accuracy: 0.3030 - val_loss: 2.2103 - val_accuracy: 0.2963\n",
            "Epoch 8524/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2084 - accuracy: 0.3030 - val_loss: 2.2103 - val_accuracy: 0.2963\n",
            "Epoch 8525/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2084 - accuracy: 0.3031 - val_loss: 2.2103 - val_accuracy: 0.2963\n",
            "Epoch 8526/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2084 - accuracy: 0.3031 - val_loss: 2.2103 - val_accuracy: 0.2963\n",
            "Epoch 8527/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2084 - accuracy: 0.3031 - val_loss: 2.2103 - val_accuracy: 0.2963\n",
            "Epoch 8528/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2083 - accuracy: 0.3032 - val_loss: 2.2102 - val_accuracy: 0.2963\n",
            "Epoch 8529/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2083 - accuracy: 0.3032 - val_loss: 2.2102 - val_accuracy: 0.2964\n",
            "Epoch 8530/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2083 - accuracy: 0.3032 - val_loss: 2.2102 - val_accuracy: 0.2964\n",
            "Epoch 8531/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2083 - accuracy: 0.3032 - val_loss: 2.2102 - val_accuracy: 0.2964\n",
            "Epoch 8532/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2083 - accuracy: 0.3033 - val_loss: 2.2102 - val_accuracy: 0.2964\n",
            "Epoch 8533/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2083 - accuracy: 0.3033 - val_loss: 2.2102 - val_accuracy: 0.2964\n",
            "Epoch 8534/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2083 - accuracy: 0.3033 - val_loss: 2.2102 - val_accuracy: 0.2965\n",
            "Epoch 8535/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2083 - accuracy: 0.3033 - val_loss: 2.2102 - val_accuracy: 0.2965\n",
            "Epoch 8536/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2083 - accuracy: 0.3033 - val_loss: 2.2102 - val_accuracy: 0.2966\n",
            "Epoch 8537/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2083 - accuracy: 0.3033 - val_loss: 2.2102 - val_accuracy: 0.2966\n",
            "Epoch 8538/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2083 - accuracy: 0.3034 - val_loss: 2.2102 - val_accuracy: 0.2968\n",
            "Epoch 8539/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2082 - accuracy: 0.3034 - val_loss: 2.2101 - val_accuracy: 0.2968\n",
            "Epoch 8540/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2082 - accuracy: 0.3034 - val_loss: 2.2101 - val_accuracy: 0.2969\n",
            "Epoch 8541/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2082 - accuracy: 0.3035 - val_loss: 2.2101 - val_accuracy: 0.2969\n",
            "Epoch 8542/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2082 - accuracy: 0.3035 - val_loss: 2.2101 - val_accuracy: 0.2970\n",
            "Epoch 8543/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2082 - accuracy: 0.3035 - val_loss: 2.2101 - val_accuracy: 0.2970\n",
            "Epoch 8544/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2082 - accuracy: 0.3035 - val_loss: 2.2101 - val_accuracy: 0.2970\n",
            "Epoch 8545/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2082 - accuracy: 0.3036 - val_loss: 2.2101 - val_accuracy: 0.2972\n",
            "Epoch 8546/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2082 - accuracy: 0.3036 - val_loss: 2.2101 - val_accuracy: 0.2972\n",
            "Epoch 8547/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2082 - accuracy: 0.3036 - val_loss: 2.2101 - val_accuracy: 0.2972\n",
            "Epoch 8548/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2082 - accuracy: 0.3036 - val_loss: 2.2101 - val_accuracy: 0.2972\n",
            "Epoch 8549/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2081 - accuracy: 0.3036 - val_loss: 2.2101 - val_accuracy: 0.2972\n",
            "Epoch 8550/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2081 - accuracy: 0.3036 - val_loss: 2.2101 - val_accuracy: 0.2972\n",
            "Epoch 8551/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2081 - accuracy: 0.3036 - val_loss: 2.2100 - val_accuracy: 0.2972\n",
            "Epoch 8552/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2081 - accuracy: 0.3036 - val_loss: 2.2100 - val_accuracy: 0.2972\n",
            "Epoch 8553/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2081 - accuracy: 0.3037 - val_loss: 2.2100 - val_accuracy: 0.2972\n",
            "Epoch 8554/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2081 - accuracy: 0.3037 - val_loss: 2.2100 - val_accuracy: 0.2972\n",
            "Epoch 8555/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2081 - accuracy: 0.3037 - val_loss: 2.2100 - val_accuracy: 0.2972\n",
            "Epoch 8556/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2081 - accuracy: 0.3037 - val_loss: 2.2100 - val_accuracy: 0.2972\n",
            "Epoch 8557/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2081 - accuracy: 0.3037 - val_loss: 2.2100 - val_accuracy: 0.2973\n",
            "Epoch 8558/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2081 - accuracy: 0.3037 - val_loss: 2.2100 - val_accuracy: 0.2973\n",
            "Epoch 8559/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2081 - accuracy: 0.3037 - val_loss: 2.2100 - val_accuracy: 0.2973\n",
            "Epoch 8560/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2080 - accuracy: 0.3037 - val_loss: 2.2100 - val_accuracy: 0.2973\n",
            "Epoch 8561/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2080 - accuracy: 0.3038 - val_loss: 2.2100 - val_accuracy: 0.2974\n",
            "Epoch 8562/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2080 - accuracy: 0.3038 - val_loss: 2.2099 - val_accuracy: 0.2975\n",
            "Epoch 8563/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2080 - accuracy: 0.3038 - val_loss: 2.2099 - val_accuracy: 0.2975\n",
            "Epoch 8564/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2080 - accuracy: 0.3038 - val_loss: 2.2099 - val_accuracy: 0.2976\n",
            "Epoch 8565/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2080 - accuracy: 0.3038 - val_loss: 2.2099 - val_accuracy: 0.2976\n",
            "Epoch 8566/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2080 - accuracy: 0.3039 - val_loss: 2.2099 - val_accuracy: 0.2976\n",
            "Epoch 8567/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2080 - accuracy: 0.3039 - val_loss: 2.2099 - val_accuracy: 0.2976\n",
            "Epoch 8568/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2080 - accuracy: 0.3039 - val_loss: 2.2099 - val_accuracy: 0.2977\n",
            "Epoch 8569/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2080 - accuracy: 0.3040 - val_loss: 2.2099 - val_accuracy: 0.2977\n",
            "Epoch 8570/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2080 - accuracy: 0.3040 - val_loss: 2.2099 - val_accuracy: 0.2977\n",
            "Epoch 8571/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2079 - accuracy: 0.3040 - val_loss: 2.2099 - val_accuracy: 0.2977\n",
            "Epoch 8572/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2079 - accuracy: 0.3040 - val_loss: 2.2099 - val_accuracy: 0.2977\n",
            "Epoch 8573/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2079 - accuracy: 0.3041 - val_loss: 2.2098 - val_accuracy: 0.2977\n",
            "Epoch 8574/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2079 - accuracy: 0.3041 - val_loss: 2.2098 - val_accuracy: 0.2977\n",
            "Epoch 8575/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2079 - accuracy: 0.3041 - val_loss: 2.2098 - val_accuracy: 0.2977\n",
            "Epoch 8576/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2079 - accuracy: 0.3041 - val_loss: 2.2098 - val_accuracy: 0.2977\n",
            "Epoch 8577/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2079 - accuracy: 0.3041 - val_loss: 2.2098 - val_accuracy: 0.2977\n",
            "Epoch 8578/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2079 - accuracy: 0.3041 - val_loss: 2.2098 - val_accuracy: 0.2977\n",
            "Epoch 8579/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2079 - accuracy: 0.3042 - val_loss: 2.2098 - val_accuracy: 0.2977\n",
            "Epoch 8580/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2079 - accuracy: 0.3042 - val_loss: 2.2098 - val_accuracy: 0.2977\n",
            "Epoch 8581/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2079 - accuracy: 0.3043 - val_loss: 2.2098 - val_accuracy: 0.2977\n",
            "Epoch 8582/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2078 - accuracy: 0.3043 - val_loss: 2.2098 - val_accuracy: 0.2977\n",
            "Epoch 8583/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2078 - accuracy: 0.3043 - val_loss: 2.2098 - val_accuracy: 0.2977\n",
            "Epoch 8584/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2078 - accuracy: 0.3043 - val_loss: 2.2097 - val_accuracy: 0.2977\n",
            "Epoch 8585/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2078 - accuracy: 0.3043 - val_loss: 2.2097 - val_accuracy: 0.2977\n",
            "Epoch 8586/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2078 - accuracy: 0.3043 - val_loss: 2.2097 - val_accuracy: 0.2977\n",
            "Epoch 8587/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2078 - accuracy: 0.3044 - val_loss: 2.2097 - val_accuracy: 0.2977\n",
            "Epoch 8588/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2078 - accuracy: 0.3044 - val_loss: 2.2097 - val_accuracy: 0.2978\n",
            "Epoch 8589/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2078 - accuracy: 0.3045 - val_loss: 2.2097 - val_accuracy: 0.2978\n",
            "Epoch 8590/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2078 - accuracy: 0.3045 - val_loss: 2.2097 - val_accuracy: 0.2978\n",
            "Epoch 8591/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2078 - accuracy: 0.3045 - val_loss: 2.2097 - val_accuracy: 0.2978\n",
            "Epoch 8592/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2078 - accuracy: 0.3045 - val_loss: 2.2097 - val_accuracy: 0.2978\n",
            "Epoch 8593/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2077 - accuracy: 0.3046 - val_loss: 2.2097 - val_accuracy: 0.2978\n",
            "Epoch 8594/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2077 - accuracy: 0.3046 - val_loss: 2.2097 - val_accuracy: 0.2978\n",
            "Epoch 8595/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2077 - accuracy: 0.3046 - val_loss: 2.2096 - val_accuracy: 0.2978\n",
            "Epoch 8596/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2077 - accuracy: 0.3047 - val_loss: 2.2096 - val_accuracy: 0.2978\n",
            "Epoch 8597/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2077 - accuracy: 0.3047 - val_loss: 2.2096 - val_accuracy: 0.2978\n",
            "Epoch 8598/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2077 - accuracy: 0.3047 - val_loss: 2.2096 - val_accuracy: 0.2978\n",
            "Epoch 8599/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2077 - accuracy: 0.3047 - val_loss: 2.2096 - val_accuracy: 0.2979\n",
            "Epoch 8600/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2077 - accuracy: 0.3047 - val_loss: 2.2096 - val_accuracy: 0.2979\n",
            "Epoch 8601/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2077 - accuracy: 0.3047 - val_loss: 2.2096 - val_accuracy: 0.2979\n",
            "Epoch 8602/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2077 - accuracy: 0.3048 - val_loss: 2.2096 - val_accuracy: 0.2979\n",
            "Epoch 8603/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2077 - accuracy: 0.3048 - val_loss: 2.2096 - val_accuracy: 0.2980\n",
            "Epoch 8604/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2076 - accuracy: 0.3048 - val_loss: 2.2096 - val_accuracy: 0.2980\n",
            "Epoch 8605/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2076 - accuracy: 0.3048 - val_loss: 2.2096 - val_accuracy: 0.2980\n",
            "Epoch 8606/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2076 - accuracy: 0.3049 - val_loss: 2.2095 - val_accuracy: 0.2981\n",
            "Epoch 8607/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2076 - accuracy: 0.3049 - val_loss: 2.2095 - val_accuracy: 0.2982\n",
            "Epoch 8608/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2076 - accuracy: 0.3049 - val_loss: 2.2095 - val_accuracy: 0.2983\n",
            "Epoch 8609/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2076 - accuracy: 0.3049 - val_loss: 2.2095 - val_accuracy: 0.2983\n",
            "Epoch 8610/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2076 - accuracy: 0.3049 - val_loss: 2.2095 - val_accuracy: 0.2983\n",
            "Epoch 8611/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2076 - accuracy: 0.3049 - val_loss: 2.2095 - val_accuracy: 0.2983\n",
            "Epoch 8612/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2076 - accuracy: 0.3049 - val_loss: 2.2095 - val_accuracy: 0.2984\n",
            "Epoch 8613/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2076 - accuracy: 0.3050 - val_loss: 2.2095 - val_accuracy: 0.2984\n",
            "Epoch 8614/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2076 - accuracy: 0.3050 - val_loss: 2.2095 - val_accuracy: 0.2984\n",
            "Epoch 8615/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2075 - accuracy: 0.3050 - val_loss: 2.2095 - val_accuracy: 0.2984\n",
            "Epoch 8616/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2075 - accuracy: 0.3050 - val_loss: 2.2095 - val_accuracy: 0.2984\n",
            "Epoch 8617/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2075 - accuracy: 0.3050 - val_loss: 2.2094 - val_accuracy: 0.2984\n",
            "Epoch 8618/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2075 - accuracy: 0.3051 - val_loss: 2.2094 - val_accuracy: 0.2984\n",
            "Epoch 8619/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2075 - accuracy: 0.3051 - val_loss: 2.2094 - val_accuracy: 0.2984\n",
            "Epoch 8620/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2075 - accuracy: 0.3051 - val_loss: 2.2094 - val_accuracy: 0.2984\n",
            "Epoch 8621/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2075 - accuracy: 0.3052 - val_loss: 2.2094 - val_accuracy: 0.2984\n",
            "Epoch 8622/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2075 - accuracy: 0.3052 - val_loss: 2.2094 - val_accuracy: 0.2984\n",
            "Epoch 8623/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2075 - accuracy: 0.3052 - val_loss: 2.2094 - val_accuracy: 0.2984\n",
            "Epoch 8624/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2075 - accuracy: 0.3052 - val_loss: 2.2094 - val_accuracy: 0.2984\n",
            "Epoch 8625/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2075 - accuracy: 0.3052 - val_loss: 2.2094 - val_accuracy: 0.2984\n",
            "Epoch 8626/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2074 - accuracy: 0.3052 - val_loss: 2.2094 - val_accuracy: 0.2984\n",
            "Epoch 8627/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2074 - accuracy: 0.3052 - val_loss: 2.2094 - val_accuracy: 0.2984\n",
            "Epoch 8628/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2074 - accuracy: 0.3052 - val_loss: 2.2093 - val_accuracy: 0.2984\n",
            "Epoch 8629/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2074 - accuracy: 0.3052 - val_loss: 2.2093 - val_accuracy: 0.2984\n",
            "Epoch 8630/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2074 - accuracy: 0.3053 - val_loss: 2.2093 - val_accuracy: 0.2984\n",
            "Epoch 8631/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2074 - accuracy: 0.3053 - val_loss: 2.2093 - val_accuracy: 0.2985\n",
            "Epoch 8632/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2074 - accuracy: 0.3053 - val_loss: 2.2093 - val_accuracy: 0.2985\n",
            "Epoch 8633/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2074 - accuracy: 0.3054 - val_loss: 2.2093 - val_accuracy: 0.2985\n",
            "Epoch 8634/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2074 - accuracy: 0.3054 - val_loss: 2.2093 - val_accuracy: 0.2985\n",
            "Epoch 8635/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2074 - accuracy: 0.3054 - val_loss: 2.2093 - val_accuracy: 0.2985\n",
            "Epoch 8636/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2074 - accuracy: 0.3054 - val_loss: 2.2093 - val_accuracy: 0.2985\n",
            "Epoch 8637/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.2073 - accuracy: 0.3054 - val_loss: 2.2093 - val_accuracy: 0.2985\n",
            "Epoch 8638/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2073 - accuracy: 0.3054 - val_loss: 2.2093 - val_accuracy: 0.2985\n",
            "Epoch 8639/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2073 - accuracy: 0.3054 - val_loss: 2.2092 - val_accuracy: 0.2985\n",
            "Epoch 8640/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2073 - accuracy: 0.3054 - val_loss: 2.2092 - val_accuracy: 0.2985\n",
            "Epoch 8641/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2073 - accuracy: 0.3054 - val_loss: 2.2092 - val_accuracy: 0.2985\n",
            "Epoch 8642/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2073 - accuracy: 0.3054 - val_loss: 2.2092 - val_accuracy: 0.2985\n",
            "Epoch 8643/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2073 - accuracy: 0.3054 - val_loss: 2.2092 - val_accuracy: 0.2985\n",
            "Epoch 8644/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2073 - accuracy: 0.3055 - val_loss: 2.2092 - val_accuracy: 0.2985\n",
            "Epoch 8645/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2073 - accuracy: 0.3055 - val_loss: 2.2092 - val_accuracy: 0.2985\n",
            "Epoch 8646/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2073 - accuracy: 0.3055 - val_loss: 2.2092 - val_accuracy: 0.2985\n",
            "Epoch 8647/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2073 - accuracy: 0.3055 - val_loss: 2.2092 - val_accuracy: 0.2985\n",
            "Epoch 8648/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2072 - accuracy: 0.3055 - val_loss: 2.2092 - val_accuracy: 0.2985\n",
            "Epoch 8649/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2072 - accuracy: 0.3056 - val_loss: 2.2092 - val_accuracy: 0.2985\n",
            "Epoch 8650/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2072 - accuracy: 0.3056 - val_loss: 2.2091 - val_accuracy: 0.2986\n",
            "Epoch 8651/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2072 - accuracy: 0.3056 - val_loss: 2.2091 - val_accuracy: 0.2986\n",
            "Epoch 8652/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2072 - accuracy: 0.3056 - val_loss: 2.2091 - val_accuracy: 0.2987\n",
            "Epoch 8653/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2072 - accuracy: 0.3056 - val_loss: 2.2091 - val_accuracy: 0.2987\n",
            "Epoch 8654/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2072 - accuracy: 0.3056 - val_loss: 2.2091 - val_accuracy: 0.2987\n",
            "Epoch 8655/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2072 - accuracy: 0.3056 - val_loss: 2.2091 - val_accuracy: 0.2987\n",
            "Epoch 8656/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2072 - accuracy: 0.3056 - val_loss: 2.2091 - val_accuracy: 0.2988\n",
            "Epoch 8657/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2072 - accuracy: 0.3057 - val_loss: 2.2091 - val_accuracy: 0.2988\n",
            "Epoch 8658/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2072 - accuracy: 0.3057 - val_loss: 2.2091 - val_accuracy: 0.2988\n",
            "Epoch 8659/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2071 - accuracy: 0.3057 - val_loss: 2.2091 - val_accuracy: 0.2988\n",
            "Epoch 8660/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2071 - accuracy: 0.3057 - val_loss: 2.2091 - val_accuracy: 0.2988\n",
            "Epoch 8661/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2071 - accuracy: 0.3058 - val_loss: 2.2090 - val_accuracy: 0.2989\n",
            "Epoch 8662/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2071 - accuracy: 0.3058 - val_loss: 2.2090 - val_accuracy: 0.2989\n",
            "Epoch 8663/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2071 - accuracy: 0.3058 - val_loss: 2.2090 - val_accuracy: 0.2989\n",
            "Epoch 8664/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2071 - accuracy: 0.3058 - val_loss: 2.2090 - val_accuracy: 0.2989\n",
            "Epoch 8665/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2071 - accuracy: 0.3058 - val_loss: 2.2090 - val_accuracy: 0.2990\n",
            "Epoch 8666/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2071 - accuracy: 0.3058 - val_loss: 2.2090 - val_accuracy: 0.2990\n",
            "Epoch 8667/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2071 - accuracy: 0.3058 - val_loss: 2.2090 - val_accuracy: 0.2990\n",
            "Epoch 8668/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2071 - accuracy: 0.3058 - val_loss: 2.2090 - val_accuracy: 0.2990\n",
            "Epoch 8669/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2071 - accuracy: 0.3059 - val_loss: 2.2090 - val_accuracy: 0.2990\n",
            "Epoch 8670/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2071 - accuracy: 0.3059 - val_loss: 2.2090 - val_accuracy: 0.2991\n",
            "Epoch 8671/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2070 - accuracy: 0.3059 - val_loss: 2.2090 - val_accuracy: 0.2991\n",
            "Epoch 8672/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2070 - accuracy: 0.3059 - val_loss: 2.2090 - val_accuracy: 0.2991\n",
            "Epoch 8673/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2070 - accuracy: 0.3059 - val_loss: 2.2089 - val_accuracy: 0.2991\n",
            "Epoch 8674/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2070 - accuracy: 0.3059 - val_loss: 2.2089 - val_accuracy: 0.2991\n",
            "Epoch 8675/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2070 - accuracy: 0.3059 - val_loss: 2.2089 - val_accuracy: 0.2991\n",
            "Epoch 8676/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2070 - accuracy: 0.3059 - val_loss: 2.2089 - val_accuracy: 0.2991\n",
            "Epoch 8677/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2070 - accuracy: 0.3060 - val_loss: 2.2089 - val_accuracy: 0.2991\n",
            "Epoch 8678/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2070 - accuracy: 0.3060 - val_loss: 2.2089 - val_accuracy: 0.2992\n",
            "Epoch 8679/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2070 - accuracy: 0.3060 - val_loss: 2.2089 - val_accuracy: 0.2992\n",
            "Epoch 8680/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2070 - accuracy: 0.3061 - val_loss: 2.2089 - val_accuracy: 0.2992\n",
            "Epoch 8681/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2070 - accuracy: 0.3061 - val_loss: 2.2089 - val_accuracy: 0.2992\n",
            "Epoch 8682/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2069 - accuracy: 0.3061 - val_loss: 2.2089 - val_accuracy: 0.2992\n",
            "Epoch 8683/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2069 - accuracy: 0.3062 - val_loss: 2.2089 - val_accuracy: 0.2992\n",
            "Epoch 8684/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2069 - accuracy: 0.3062 - val_loss: 2.2088 - val_accuracy: 0.2993\n",
            "Epoch 8685/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2069 - accuracy: 0.3063 - val_loss: 2.2088 - val_accuracy: 0.2994\n",
            "Epoch 8686/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2069 - accuracy: 0.3063 - val_loss: 2.2088 - val_accuracy: 0.2994\n",
            "Epoch 8687/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2069 - accuracy: 0.3063 - val_loss: 2.2088 - val_accuracy: 0.2994\n",
            "Epoch 8688/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2069 - accuracy: 0.3063 - val_loss: 2.2088 - val_accuracy: 0.2994\n",
            "Epoch 8689/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2069 - accuracy: 0.3063 - val_loss: 2.2088 - val_accuracy: 0.2994\n",
            "Epoch 8690/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2069 - accuracy: 0.3063 - val_loss: 2.2088 - val_accuracy: 0.2995\n",
            "Epoch 8691/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2069 - accuracy: 0.3063 - val_loss: 2.2088 - val_accuracy: 0.2995\n",
            "Epoch 8692/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2069 - accuracy: 0.3063 - val_loss: 2.2088 - val_accuracy: 0.2995\n",
            "Epoch 8693/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2068 - accuracy: 0.3064 - val_loss: 2.2088 - val_accuracy: 0.2996\n",
            "Epoch 8694/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2068 - accuracy: 0.3064 - val_loss: 2.2088 - val_accuracy: 0.2996\n",
            "Epoch 8695/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2068 - accuracy: 0.3064 - val_loss: 2.2087 - val_accuracy: 0.2996\n",
            "Epoch 8696/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2068 - accuracy: 0.3064 - val_loss: 2.2087 - val_accuracy: 0.2996\n",
            "Epoch 8697/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2068 - accuracy: 0.3064 - val_loss: 2.2087 - val_accuracy: 0.2996\n",
            "Epoch 8698/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2068 - accuracy: 0.3065 - val_loss: 2.2087 - val_accuracy: 0.2996\n",
            "Epoch 8699/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2068 - accuracy: 0.3065 - val_loss: 2.2087 - val_accuracy: 0.2996\n",
            "Epoch 8700/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2068 - accuracy: 0.3065 - val_loss: 2.2087 - val_accuracy: 0.2997\n",
            "Epoch 8701/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2068 - accuracy: 0.3066 - val_loss: 2.2087 - val_accuracy: 0.2997\n",
            "Epoch 8702/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2068 - accuracy: 0.3067 - val_loss: 2.2087 - val_accuracy: 0.2997\n",
            "Epoch 8703/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2068 - accuracy: 0.3067 - val_loss: 2.2087 - val_accuracy: 0.2997\n",
            "Epoch 8704/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2067 - accuracy: 0.3067 - val_loss: 2.2087 - val_accuracy: 0.2997\n",
            "Epoch 8705/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2067 - accuracy: 0.3067 - val_loss: 2.2087 - val_accuracy: 0.2997\n",
            "Epoch 8706/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2067 - accuracy: 0.3067 - val_loss: 2.2086 - val_accuracy: 0.2997\n",
            "Epoch 8707/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2067 - accuracy: 0.3067 - val_loss: 2.2086 - val_accuracy: 0.2997\n",
            "Epoch 8708/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2067 - accuracy: 0.3067 - val_loss: 2.2086 - val_accuracy: 0.2997\n",
            "Epoch 8709/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2067 - accuracy: 0.3067 - val_loss: 2.2086 - val_accuracy: 0.2997\n",
            "Epoch 8710/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2067 - accuracy: 0.3067 - val_loss: 2.2086 - val_accuracy: 0.2997\n",
            "Epoch 8711/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2067 - accuracy: 0.3067 - val_loss: 2.2086 - val_accuracy: 0.2997\n",
            "Epoch 8712/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2067 - accuracy: 0.3068 - val_loss: 2.2086 - val_accuracy: 0.2997\n",
            "Epoch 8713/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2067 - accuracy: 0.3068 - val_loss: 2.2086 - val_accuracy: 0.2998\n",
            "Epoch 8714/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2067 - accuracy: 0.3068 - val_loss: 2.2086 - val_accuracy: 0.2998\n",
            "Epoch 8715/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2066 - accuracy: 0.3068 - val_loss: 2.2086 - val_accuracy: 0.2998\n",
            "Epoch 8716/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2066 - accuracy: 0.3068 - val_loss: 2.2086 - val_accuracy: 0.2998\n",
            "Epoch 8717/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2066 - accuracy: 0.3069 - val_loss: 2.2085 - val_accuracy: 0.2998\n",
            "Epoch 8718/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2066 - accuracy: 0.3069 - val_loss: 2.2085 - val_accuracy: 0.2998\n",
            "Epoch 8719/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2066 - accuracy: 0.3069 - val_loss: 2.2085 - val_accuracy: 0.2998\n",
            "Epoch 8720/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2066 - accuracy: 0.3070 - val_loss: 2.2085 - val_accuracy: 0.2999\n",
            "Epoch 8721/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2066 - accuracy: 0.3070 - val_loss: 2.2085 - val_accuracy: 0.3000\n",
            "Epoch 8722/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2066 - accuracy: 0.3070 - val_loss: 2.2085 - val_accuracy: 0.3000\n",
            "Epoch 8723/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2066 - accuracy: 0.3070 - val_loss: 2.2085 - val_accuracy: 0.3001\n",
            "Epoch 8724/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2066 - accuracy: 0.3070 - val_loss: 2.2085 - val_accuracy: 0.3001\n",
            "Epoch 8725/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2066 - accuracy: 0.3070 - val_loss: 2.2085 - val_accuracy: 0.3001\n",
            "Epoch 8726/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2065 - accuracy: 0.3070 - val_loss: 2.2085 - val_accuracy: 0.3001\n",
            "Epoch 8727/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2065 - accuracy: 0.3070 - val_loss: 2.2085 - val_accuracy: 0.3002\n",
            "Epoch 8728/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2065 - accuracy: 0.3071 - val_loss: 2.2084 - val_accuracy: 0.3002\n",
            "Epoch 8729/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2065 - accuracy: 0.3071 - val_loss: 2.2084 - val_accuracy: 0.3002\n",
            "Epoch 8730/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2065 - accuracy: 0.3071 - val_loss: 2.2084 - val_accuracy: 0.3002\n",
            "Epoch 8731/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2065 - accuracy: 0.3071 - val_loss: 2.2084 - val_accuracy: 0.3002\n",
            "Epoch 8732/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2065 - accuracy: 0.3072 - val_loss: 2.2084 - val_accuracy: 0.3003\n",
            "Epoch 8733/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2065 - accuracy: 0.3072 - val_loss: 2.2084 - val_accuracy: 0.3003\n",
            "Epoch 8734/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2065 - accuracy: 0.3072 - val_loss: 2.2084 - val_accuracy: 0.3003\n",
            "Epoch 8735/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2065 - accuracy: 0.3072 - val_loss: 2.2084 - val_accuracy: 0.3003\n",
            "Epoch 8736/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2065 - accuracy: 0.3073 - val_loss: 2.2084 - val_accuracy: 0.3003\n",
            "Epoch 8737/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2064 - accuracy: 0.3073 - val_loss: 2.2084 - val_accuracy: 0.3003\n",
            "Epoch 8738/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2064 - accuracy: 0.3073 - val_loss: 2.2084 - val_accuracy: 0.3003\n",
            "Epoch 8739/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2064 - accuracy: 0.3074 - val_loss: 2.2084 - val_accuracy: 0.3004\n",
            "Epoch 8740/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2064 - accuracy: 0.3074 - val_loss: 2.2083 - val_accuracy: 0.3004\n",
            "Epoch 8741/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2064 - accuracy: 0.3074 - val_loss: 2.2083 - val_accuracy: 0.3003\n",
            "Epoch 8742/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2064 - accuracy: 0.3075 - val_loss: 2.2083 - val_accuracy: 0.3004\n",
            "Epoch 8743/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2064 - accuracy: 0.3074 - val_loss: 2.2083 - val_accuracy: 0.3005\n",
            "Epoch 8744/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2064 - accuracy: 0.3075 - val_loss: 2.2083 - val_accuracy: 0.3005\n",
            "Epoch 8745/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2064 - accuracy: 0.3075 - val_loss: 2.2083 - val_accuracy: 0.3005\n",
            "Epoch 8746/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2064 - accuracy: 0.3075 - val_loss: 2.2083 - val_accuracy: 0.3005\n",
            "Epoch 8747/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2064 - accuracy: 0.3076 - val_loss: 2.2083 - val_accuracy: 0.3006\n",
            "Epoch 8748/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2063 - accuracy: 0.3076 - val_loss: 2.2083 - val_accuracy: 0.3006\n",
            "Epoch 8749/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2063 - accuracy: 0.3076 - val_loss: 2.2083 - val_accuracy: 0.3006\n",
            "Epoch 8750/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2063 - accuracy: 0.3076 - val_loss: 2.2083 - val_accuracy: 0.3006\n",
            "Epoch 8751/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2063 - accuracy: 0.3076 - val_loss: 2.2082 - val_accuracy: 0.3006\n",
            "Epoch 8752/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2063 - accuracy: 0.3076 - val_loss: 2.2082 - val_accuracy: 0.3006\n",
            "Epoch 8753/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2063 - accuracy: 0.3076 - val_loss: 2.2082 - val_accuracy: 0.3006\n",
            "Epoch 8754/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2063 - accuracy: 0.3077 - val_loss: 2.2082 - val_accuracy: 0.3006\n",
            "Epoch 8755/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2063 - accuracy: 0.3077 - val_loss: 2.2082 - val_accuracy: 0.3008\n",
            "Epoch 8756/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2063 - accuracy: 0.3078 - val_loss: 2.2082 - val_accuracy: 0.3008\n",
            "Epoch 8757/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2063 - accuracy: 0.3078 - val_loss: 2.2082 - val_accuracy: 0.3009\n",
            "Epoch 8758/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2063 - accuracy: 0.3079 - val_loss: 2.2082 - val_accuracy: 0.3009\n",
            "Epoch 8759/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2062 - accuracy: 0.3079 - val_loss: 2.2082 - val_accuracy: 0.3010\n",
            "Epoch 8760/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2062 - accuracy: 0.3080 - val_loss: 2.2082 - val_accuracy: 0.3010\n",
            "Epoch 8761/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2062 - accuracy: 0.3080 - val_loss: 2.2082 - val_accuracy: 0.3010\n",
            "Epoch 8762/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2062 - accuracy: 0.3080 - val_loss: 2.2081 - val_accuracy: 0.3010\n",
            "Epoch 8763/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2062 - accuracy: 0.3080 - val_loss: 2.2081 - val_accuracy: 0.3011\n",
            "Epoch 8764/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2062 - accuracy: 0.3080 - val_loss: 2.2081 - val_accuracy: 0.3011\n",
            "Epoch 8765/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2062 - accuracy: 0.3081 - val_loss: 2.2081 - val_accuracy: 0.3011\n",
            "Epoch 8766/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2062 - accuracy: 0.3081 - val_loss: 2.2081 - val_accuracy: 0.3011\n",
            "Epoch 8767/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2062 - accuracy: 0.3081 - val_loss: 2.2081 - val_accuracy: 0.3011\n",
            "Epoch 8768/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2062 - accuracy: 0.3082 - val_loss: 2.2081 - val_accuracy: 0.3011\n",
            "Epoch 8769/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2062 - accuracy: 0.3082 - val_loss: 2.2081 - val_accuracy: 0.3011\n",
            "Epoch 8770/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2061 - accuracy: 0.3083 - val_loss: 2.2081 - val_accuracy: 0.3011\n",
            "Epoch 8771/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.2061 - accuracy: 0.3083 - val_loss: 2.2081 - val_accuracy: 0.3011\n",
            "Epoch 8772/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2061 - accuracy: 0.3083 - val_loss: 2.2081 - val_accuracy: 0.3011\n",
            "Epoch 8773/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2061 - accuracy: 0.3083 - val_loss: 2.2080 - val_accuracy: 0.3011\n",
            "Epoch 8774/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2061 - accuracy: 0.3084 - val_loss: 2.2080 - val_accuracy: 0.3011\n",
            "Epoch 8775/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2061 - accuracy: 0.3084 - val_loss: 2.2080 - val_accuracy: 0.3011\n",
            "Epoch 8776/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2061 - accuracy: 0.3085 - val_loss: 2.2080 - val_accuracy: 0.3011\n",
            "Epoch 8777/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2061 - accuracy: 0.3085 - val_loss: 2.2080 - val_accuracy: 0.3011\n",
            "Epoch 8778/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2061 - accuracy: 0.3085 - val_loss: 2.2080 - val_accuracy: 0.3011\n",
            "Epoch 8779/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2061 - accuracy: 0.3085 - val_loss: 2.2080 - val_accuracy: 0.3011\n",
            "Epoch 8780/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2061 - accuracy: 0.3086 - val_loss: 2.2080 - val_accuracy: 0.3011\n",
            "Epoch 8781/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.2061 - accuracy: 0.3086 - val_loss: 2.2080 - val_accuracy: 0.3011\n",
            "Epoch 8782/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2060 - accuracy: 0.3086 - val_loss: 2.2080 - val_accuracy: 0.3011\n",
            "Epoch 8783/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2060 - accuracy: 0.3086 - val_loss: 2.2080 - val_accuracy: 0.3011\n",
            "Epoch 8784/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2060 - accuracy: 0.3086 - val_loss: 2.2079 - val_accuracy: 0.3011\n",
            "Epoch 8785/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2060 - accuracy: 0.3087 - val_loss: 2.2079 - val_accuracy: 0.3012\n",
            "Epoch 8786/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2060 - accuracy: 0.3087 - val_loss: 2.2079 - val_accuracy: 0.3012\n",
            "Epoch 8787/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2060 - accuracy: 0.3087 - val_loss: 2.2079 - val_accuracy: 0.3012\n",
            "Epoch 8788/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2060 - accuracy: 0.3088 - val_loss: 2.2079 - val_accuracy: 0.3012\n",
            "Epoch 8789/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2060 - accuracy: 0.3088 - val_loss: 2.2079 - val_accuracy: 0.3012\n",
            "Epoch 8790/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2060 - accuracy: 0.3088 - val_loss: 2.2079 - val_accuracy: 0.3013\n",
            "Epoch 8791/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2060 - accuracy: 0.3089 - val_loss: 2.2079 - val_accuracy: 0.3013\n",
            "Epoch 8792/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2060 - accuracy: 0.3089 - val_loss: 2.2079 - val_accuracy: 0.3013\n",
            "Epoch 8793/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2059 - accuracy: 0.3090 - val_loss: 2.2079 - val_accuracy: 0.3013\n",
            "Epoch 8794/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2059 - accuracy: 0.3090 - val_loss: 2.2079 - val_accuracy: 0.3013\n",
            "Epoch 8795/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2059 - accuracy: 0.3090 - val_loss: 2.2079 - val_accuracy: 0.3013\n",
            "Epoch 8796/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2059 - accuracy: 0.3090 - val_loss: 2.2078 - val_accuracy: 0.3014\n",
            "Epoch 8797/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2059 - accuracy: 0.3091 - val_loss: 2.2078 - val_accuracy: 0.3015\n",
            "Epoch 8798/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2059 - accuracy: 0.3091 - val_loss: 2.2078 - val_accuracy: 0.3015\n",
            "Epoch 8799/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2059 - accuracy: 0.3091 - val_loss: 2.2078 - val_accuracy: 0.3015\n",
            "Epoch 8800/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2059 - accuracy: 0.3091 - val_loss: 2.2078 - val_accuracy: 0.3015\n",
            "Epoch 8801/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2059 - accuracy: 0.3091 - val_loss: 2.2078 - val_accuracy: 0.3015\n",
            "Epoch 8802/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2059 - accuracy: 0.3092 - val_loss: 2.2078 - val_accuracy: 0.3015\n",
            "Epoch 8803/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2059 - accuracy: 0.3092 - val_loss: 2.2078 - val_accuracy: 0.3015\n",
            "Epoch 8804/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2058 - accuracy: 0.3093 - val_loss: 2.2078 - val_accuracy: 0.3015\n",
            "Epoch 8805/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2058 - accuracy: 0.3093 - val_loss: 2.2078 - val_accuracy: 0.3015\n",
            "Epoch 8806/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2058 - accuracy: 0.3094 - val_loss: 2.2078 - val_accuracy: 0.3015\n",
            "Epoch 8807/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2058 - accuracy: 0.3094 - val_loss: 2.2077 - val_accuracy: 0.3016\n",
            "Epoch 8808/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2058 - accuracy: 0.3094 - val_loss: 2.2077 - val_accuracy: 0.3016\n",
            "Epoch 8809/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2058 - accuracy: 0.3094 - val_loss: 2.2077 - val_accuracy: 0.3016\n",
            "Epoch 8810/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2058 - accuracy: 0.3095 - val_loss: 2.2077 - val_accuracy: 0.3016\n",
            "Epoch 8811/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2058 - accuracy: 0.3095 - val_loss: 2.2077 - val_accuracy: 0.3016\n",
            "Epoch 8812/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2058 - accuracy: 0.3095 - val_loss: 2.2077 - val_accuracy: 0.3017\n",
            "Epoch 8813/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2058 - accuracy: 0.3096 - val_loss: 2.2077 - val_accuracy: 0.3017\n",
            "Epoch 8814/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2058 - accuracy: 0.3096 - val_loss: 2.2077 - val_accuracy: 0.3017\n",
            "Epoch 8815/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2057 - accuracy: 0.3096 - val_loss: 2.2077 - val_accuracy: 0.3017\n",
            "Epoch 8816/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2057 - accuracy: 0.3096 - val_loss: 2.2077 - val_accuracy: 0.3017\n",
            "Epoch 8817/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2057 - accuracy: 0.3097 - val_loss: 2.2077 - val_accuracy: 0.3016\n",
            "Epoch 8818/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2057 - accuracy: 0.3097 - val_loss: 2.2076 - val_accuracy: 0.3016\n",
            "Epoch 8819/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2057 - accuracy: 0.3097 - val_loss: 2.2076 - val_accuracy: 0.3016\n",
            "Epoch 8820/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2057 - accuracy: 0.3098 - val_loss: 2.2076 - val_accuracy: 0.3016\n",
            "Epoch 8821/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2057 - accuracy: 0.3098 - val_loss: 2.2076 - val_accuracy: 0.3016\n",
            "Epoch 8822/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2057 - accuracy: 0.3098 - val_loss: 2.2076 - val_accuracy: 0.3016\n",
            "Epoch 8823/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2057 - accuracy: 0.3098 - val_loss: 2.2076 - val_accuracy: 0.3016\n",
            "Epoch 8824/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2057 - accuracy: 0.3099 - val_loss: 2.2076 - val_accuracy: 0.3017\n",
            "Epoch 8825/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2057 - accuracy: 0.3099 - val_loss: 2.2076 - val_accuracy: 0.3017\n",
            "Epoch 8826/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2056 - accuracy: 0.3099 - val_loss: 2.2076 - val_accuracy: 0.3017\n",
            "Epoch 8827/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2056 - accuracy: 0.3099 - val_loss: 2.2076 - val_accuracy: 0.3017\n",
            "Epoch 8828/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2056 - accuracy: 0.3100 - val_loss: 2.2076 - val_accuracy: 0.3018\n",
            "Epoch 8829/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2056 - accuracy: 0.3100 - val_loss: 2.2075 - val_accuracy: 0.3019\n",
            "Epoch 8830/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2056 - accuracy: 0.3100 - val_loss: 2.2075 - val_accuracy: 0.3019\n",
            "Epoch 8831/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2056 - accuracy: 0.3101 - val_loss: 2.2075 - val_accuracy: 0.3020\n",
            "Epoch 8832/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2056 - accuracy: 0.3101 - val_loss: 2.2075 - val_accuracy: 0.3021\n",
            "Epoch 8833/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2056 - accuracy: 0.3101 - val_loss: 2.2075 - val_accuracy: 0.3022\n",
            "Epoch 8834/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2056 - accuracy: 0.3102 - val_loss: 2.2075 - val_accuracy: 0.3022\n",
            "Epoch 8835/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2056 - accuracy: 0.3102 - val_loss: 2.2075 - val_accuracy: 0.3022\n",
            "Epoch 8836/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2056 - accuracy: 0.3102 - val_loss: 2.2075 - val_accuracy: 0.3024\n",
            "Epoch 8837/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2055 - accuracy: 0.3103 - val_loss: 2.2075 - val_accuracy: 0.3024\n",
            "Epoch 8838/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2055 - accuracy: 0.3103 - val_loss: 2.2075 - val_accuracy: 0.3024\n",
            "Epoch 8839/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2055 - accuracy: 0.3103 - val_loss: 2.2075 - val_accuracy: 0.3024\n",
            "Epoch 8840/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2055 - accuracy: 0.3104 - val_loss: 2.2075 - val_accuracy: 0.3024\n",
            "Epoch 8841/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2055 - accuracy: 0.3104 - val_loss: 2.2074 - val_accuracy: 0.3024\n",
            "Epoch 8842/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2055 - accuracy: 0.3104 - val_loss: 2.2074 - val_accuracy: 0.3026\n",
            "Epoch 8843/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2055 - accuracy: 0.3105 - val_loss: 2.2074 - val_accuracy: 0.3029\n",
            "Epoch 8844/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2055 - accuracy: 0.3105 - val_loss: 2.2074 - val_accuracy: 0.3029\n",
            "Epoch 8845/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2055 - accuracy: 0.3105 - val_loss: 2.2074 - val_accuracy: 0.3029\n",
            "Epoch 8846/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2055 - accuracy: 0.3105 - val_loss: 2.2074 - val_accuracy: 0.3029\n",
            "Epoch 8847/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2055 - accuracy: 0.3105 - val_loss: 2.2074 - val_accuracy: 0.3029\n",
            "Epoch 8848/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2055 - accuracy: 0.3106 - val_loss: 2.2074 - val_accuracy: 0.3029\n",
            "Epoch 8849/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2054 - accuracy: 0.3106 - val_loss: 2.2074 - val_accuracy: 0.3029\n",
            "Epoch 8850/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2054 - accuracy: 0.3105 - val_loss: 2.2074 - val_accuracy: 0.3030\n",
            "Epoch 8851/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2054 - accuracy: 0.3106 - val_loss: 2.2074 - val_accuracy: 0.3030\n",
            "Epoch 8852/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2054 - accuracy: 0.3106 - val_loss: 2.2073 - val_accuracy: 0.3030\n",
            "Epoch 8853/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2054 - accuracy: 0.3106 - val_loss: 2.2073 - val_accuracy: 0.3031\n",
            "Epoch 8854/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2054 - accuracy: 0.3107 - val_loss: 2.2073 - val_accuracy: 0.3031\n",
            "Epoch 8855/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2054 - accuracy: 0.3107 - val_loss: 2.2073 - val_accuracy: 0.3030\n",
            "Epoch 8856/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2054 - accuracy: 0.3107 - val_loss: 2.2073 - val_accuracy: 0.3030\n",
            "Epoch 8857/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2054 - accuracy: 0.3107 - val_loss: 2.2073 - val_accuracy: 0.3031\n",
            "Epoch 8858/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2054 - accuracy: 0.3107 - val_loss: 2.2073 - val_accuracy: 0.3031\n",
            "Epoch 8859/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2054 - accuracy: 0.3107 - val_loss: 2.2073 - val_accuracy: 0.3032\n",
            "Epoch 8860/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2053 - accuracy: 0.3108 - val_loss: 2.2073 - val_accuracy: 0.3032\n",
            "Epoch 8861/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2053 - accuracy: 0.3108 - val_loss: 2.2073 - val_accuracy: 0.3032\n",
            "Epoch 8862/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2053 - accuracy: 0.3109 - val_loss: 2.2073 - val_accuracy: 0.3032\n",
            "Epoch 8863/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2053 - accuracy: 0.3109 - val_loss: 2.2072 - val_accuracy: 0.3032\n",
            "Epoch 8864/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2053 - accuracy: 0.3109 - val_loss: 2.2072 - val_accuracy: 0.3032\n",
            "Epoch 8865/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2053 - accuracy: 0.3109 - val_loss: 2.2072 - val_accuracy: 0.3032\n",
            "Epoch 8866/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2053 - accuracy: 0.3109 - val_loss: 2.2072 - val_accuracy: 0.3033\n",
            "Epoch 8867/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2053 - accuracy: 0.3109 - val_loss: 2.2072 - val_accuracy: 0.3034\n",
            "Epoch 8868/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2053 - accuracy: 0.3109 - val_loss: 2.2072 - val_accuracy: 0.3034\n",
            "Epoch 8869/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2053 - accuracy: 0.3109 - val_loss: 2.2072 - val_accuracy: 0.3034\n",
            "Epoch 8870/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2053 - accuracy: 0.3109 - val_loss: 2.2072 - val_accuracy: 0.3035\n",
            "Epoch 8871/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2052 - accuracy: 0.3109 - val_loss: 2.2072 - val_accuracy: 0.3035\n",
            "Epoch 8872/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2052 - accuracy: 0.3110 - val_loss: 2.2072 - val_accuracy: 0.3035\n",
            "Epoch 8873/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2052 - accuracy: 0.3110 - val_loss: 2.2072 - val_accuracy: 0.3035\n",
            "Epoch 8874/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2052 - accuracy: 0.3110 - val_loss: 2.2072 - val_accuracy: 0.3035\n",
            "Epoch 8875/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2052 - accuracy: 0.3111 - val_loss: 2.2071 - val_accuracy: 0.3037\n",
            "Epoch 8876/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2052 - accuracy: 0.3111 - val_loss: 2.2071 - val_accuracy: 0.3037\n",
            "Epoch 8877/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2052 - accuracy: 0.3112 - val_loss: 2.2071 - val_accuracy: 0.3037\n",
            "Epoch 8878/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2052 - accuracy: 0.3112 - val_loss: 2.2071 - val_accuracy: 0.3038\n",
            "Epoch 8879/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2052 - accuracy: 0.3112 - val_loss: 2.2071 - val_accuracy: 0.3038\n",
            "Epoch 8880/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2052 - accuracy: 0.3112 - val_loss: 2.2071 - val_accuracy: 0.3038\n",
            "Epoch 8881/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2052 - accuracy: 0.3112 - val_loss: 2.2071 - val_accuracy: 0.3038\n",
            "Epoch 8882/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2051 - accuracy: 0.3112 - val_loss: 2.2071 - val_accuracy: 0.3038\n",
            "Epoch 8883/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2051 - accuracy: 0.3113 - val_loss: 2.2071 - val_accuracy: 0.3038\n",
            "Epoch 8884/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2051 - accuracy: 0.3113 - val_loss: 2.2071 - val_accuracy: 0.3038\n",
            "Epoch 8885/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2051 - accuracy: 0.3113 - val_loss: 2.2071 - val_accuracy: 0.3038\n",
            "Epoch 8886/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2051 - accuracy: 0.3113 - val_loss: 2.2070 - val_accuracy: 0.3038\n",
            "Epoch 8887/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2051 - accuracy: 0.3114 - val_loss: 2.2070 - val_accuracy: 0.3039\n",
            "Epoch 8888/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2051 - accuracy: 0.3114 - val_loss: 2.2070 - val_accuracy: 0.3039\n",
            "Epoch 8889/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2051 - accuracy: 0.3114 - val_loss: 2.2070 - val_accuracy: 0.3039\n",
            "Epoch 8890/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2051 - accuracy: 0.3114 - val_loss: 2.2070 - val_accuracy: 0.3039\n",
            "Epoch 8891/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2051 - accuracy: 0.3115 - val_loss: 2.2070 - val_accuracy: 0.3039\n",
            "Epoch 8892/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2051 - accuracy: 0.3115 - val_loss: 2.2070 - val_accuracy: 0.3039\n",
            "Epoch 8893/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2050 - accuracy: 0.3115 - val_loss: 2.2070 - val_accuracy: 0.3040\n",
            "Epoch 8894/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2050 - accuracy: 0.3116 - val_loss: 2.2070 - val_accuracy: 0.3041\n",
            "Epoch 8895/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2050 - accuracy: 0.3116 - val_loss: 2.2070 - val_accuracy: 0.3041\n",
            "Epoch 8896/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2050 - accuracy: 0.3116 - val_loss: 2.2070 - val_accuracy: 0.3041\n",
            "Epoch 8897/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.2050 - accuracy: 0.3116 - val_loss: 2.2069 - val_accuracy: 0.3041\n",
            "Epoch 8898/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2050 - accuracy: 0.3117 - val_loss: 2.2069 - val_accuracy: 0.3041\n",
            "Epoch 8899/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2050 - accuracy: 0.3117 - val_loss: 2.2069 - val_accuracy: 0.3041\n",
            "Epoch 8900/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2050 - accuracy: 0.3117 - val_loss: 2.2069 - val_accuracy: 0.3041\n",
            "Epoch 8901/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2050 - accuracy: 0.3117 - val_loss: 2.2069 - val_accuracy: 0.3041\n",
            "Epoch 8902/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2050 - accuracy: 0.3117 - val_loss: 2.2069 - val_accuracy: 0.3042\n",
            "Epoch 8903/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2050 - accuracy: 0.3117 - val_loss: 2.2069 - val_accuracy: 0.3042\n",
            "Epoch 8904/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2050 - accuracy: 0.3118 - val_loss: 2.2069 - val_accuracy: 0.3042\n",
            "Epoch 8905/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2049 - accuracy: 0.3119 - val_loss: 2.2069 - val_accuracy: 0.3042\n",
            "Epoch 8906/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2049 - accuracy: 0.3119 - val_loss: 2.2069 - val_accuracy: 0.3042\n",
            "Epoch 8907/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2049 - accuracy: 0.3119 - val_loss: 2.2069 - val_accuracy: 0.3041\n",
            "Epoch 8908/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2049 - accuracy: 0.3120 - val_loss: 2.2069 - val_accuracy: 0.3041\n",
            "Epoch 8909/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2049 - accuracy: 0.3120 - val_loss: 2.2068 - val_accuracy: 0.3041\n",
            "Epoch 8910/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2049 - accuracy: 0.3121 - val_loss: 2.2068 - val_accuracy: 0.3042\n",
            "Epoch 8911/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2049 - accuracy: 0.3121 - val_loss: 2.2068 - val_accuracy: 0.3042\n",
            "Epoch 8912/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2049 - accuracy: 0.3121 - val_loss: 2.2068 - val_accuracy: 0.3042\n",
            "Epoch 8913/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2049 - accuracy: 0.3121 - val_loss: 2.2068 - val_accuracy: 0.3042\n",
            "Epoch 8914/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2049 - accuracy: 0.3122 - val_loss: 2.2068 - val_accuracy: 0.3042\n",
            "Epoch 8915/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2049 - accuracy: 0.3122 - val_loss: 2.2068 - val_accuracy: 0.3042\n",
            "Epoch 8916/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2048 - accuracy: 0.3122 - val_loss: 2.2068 - val_accuracy: 0.3042\n",
            "Epoch 8917/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2048 - accuracy: 0.3122 - val_loss: 2.2068 - val_accuracy: 0.3042\n",
            "Epoch 8918/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2048 - accuracy: 0.3122 - val_loss: 2.2068 - val_accuracy: 0.3043\n",
            "Epoch 8919/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2048 - accuracy: 0.3123 - val_loss: 2.2068 - val_accuracy: 0.3043\n",
            "Epoch 8920/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2048 - accuracy: 0.3123 - val_loss: 2.2067 - val_accuracy: 0.3043\n",
            "Epoch 8921/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2048 - accuracy: 0.3123 - val_loss: 2.2067 - val_accuracy: 0.3043\n",
            "Epoch 8922/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2048 - accuracy: 0.3124 - val_loss: 2.2067 - val_accuracy: 0.3043\n",
            "Epoch 8923/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2048 - accuracy: 0.3124 - val_loss: 2.2067 - val_accuracy: 0.3043\n",
            "Epoch 8924/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2048 - accuracy: 0.3124 - val_loss: 2.2067 - val_accuracy: 0.3043\n",
            "Epoch 8925/10000\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 2.2048 - accuracy: 0.3124 - val_loss: 2.2067 - val_accuracy: 0.3042\n",
            "Epoch 8926/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2048 - accuracy: 0.3124 - val_loss: 2.2067 - val_accuracy: 0.3042\n",
            "Epoch 8927/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2047 - accuracy: 0.3125 - val_loss: 2.2067 - val_accuracy: 0.3043\n",
            "Epoch 8928/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2047 - accuracy: 0.3125 - val_loss: 2.2067 - val_accuracy: 0.3043\n",
            "Epoch 8929/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2047 - accuracy: 0.3125 - val_loss: 2.2067 - val_accuracy: 0.3043\n",
            "Epoch 8930/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2047 - accuracy: 0.3125 - val_loss: 2.2067 - val_accuracy: 0.3043\n",
            "Epoch 8931/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2047 - accuracy: 0.3125 - val_loss: 2.2066 - val_accuracy: 0.3043\n",
            "Epoch 8932/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2047 - accuracy: 0.3126 - val_loss: 2.2066 - val_accuracy: 0.3043\n",
            "Epoch 8933/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2047 - accuracy: 0.3126 - val_loss: 2.2066 - val_accuracy: 0.3043\n",
            "Epoch 8934/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2047 - accuracy: 0.3126 - val_loss: 2.2066 - val_accuracy: 0.3043\n",
            "Epoch 8935/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2047 - accuracy: 0.3126 - val_loss: 2.2066 - val_accuracy: 0.3043\n",
            "Epoch 8936/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2047 - accuracy: 0.3126 - val_loss: 2.2066 - val_accuracy: 0.3043\n",
            "Epoch 8937/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2047 - accuracy: 0.3126 - val_loss: 2.2066 - val_accuracy: 0.3044\n",
            "Epoch 8938/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2046 - accuracy: 0.3126 - val_loss: 2.2066 - val_accuracy: 0.3044\n",
            "Epoch 8939/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2046 - accuracy: 0.3126 - val_loss: 2.2066 - val_accuracy: 0.3044\n",
            "Epoch 8940/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2046 - accuracy: 0.3126 - val_loss: 2.2066 - val_accuracy: 0.3044\n",
            "Epoch 8941/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2046 - accuracy: 0.3127 - val_loss: 2.2066 - val_accuracy: 0.3044\n",
            "Epoch 8942/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2046 - accuracy: 0.3127 - val_loss: 2.2066 - val_accuracy: 0.3044\n",
            "Epoch 8943/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2046 - accuracy: 0.3127 - val_loss: 2.2065 - val_accuracy: 0.3044\n",
            "Epoch 8944/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2046 - accuracy: 0.3128 - val_loss: 2.2065 - val_accuracy: 0.3044\n",
            "Epoch 8945/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2046 - accuracy: 0.3128 - val_loss: 2.2065 - val_accuracy: 0.3044\n",
            "Epoch 8946/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2046 - accuracy: 0.3128 - val_loss: 2.2065 - val_accuracy: 0.3044\n",
            "Epoch 8947/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2046 - accuracy: 0.3128 - val_loss: 2.2065 - val_accuracy: 0.3044\n",
            "Epoch 8948/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2046 - accuracy: 0.3128 - val_loss: 2.2065 - val_accuracy: 0.3044\n",
            "Epoch 8949/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2046 - accuracy: 0.3128 - val_loss: 2.2065 - val_accuracy: 0.3044\n",
            "Epoch 8950/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2045 - accuracy: 0.3128 - val_loss: 2.2065 - val_accuracy: 0.3044\n",
            "Epoch 8951/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2045 - accuracy: 0.3129 - val_loss: 2.2065 - val_accuracy: 0.3044\n",
            "Epoch 8952/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2045 - accuracy: 0.3129 - val_loss: 2.2065 - val_accuracy: 0.3044\n",
            "Epoch 8953/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2045 - accuracy: 0.3129 - val_loss: 2.2065 - val_accuracy: 0.3045\n",
            "Epoch 8954/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2045 - accuracy: 0.3130 - val_loss: 2.2064 - val_accuracy: 0.3046\n",
            "Epoch 8955/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2045 - accuracy: 0.3130 - val_loss: 2.2064 - val_accuracy: 0.3046\n",
            "Epoch 8956/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2045 - accuracy: 0.3130 - val_loss: 2.2064 - val_accuracy: 0.3046\n",
            "Epoch 8957/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2045 - accuracy: 0.3130 - val_loss: 2.2064 - val_accuracy: 0.3046\n",
            "Epoch 8958/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2045 - accuracy: 0.3130 - val_loss: 2.2064 - val_accuracy: 0.3047\n",
            "Epoch 8959/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2045 - accuracy: 0.3130 - val_loss: 2.2064 - val_accuracy: 0.3047\n",
            "Epoch 8960/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2045 - accuracy: 0.3131 - val_loss: 2.2064 - val_accuracy: 0.3046\n",
            "Epoch 8961/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2044 - accuracy: 0.3131 - val_loss: 2.2064 - val_accuracy: 0.3046\n",
            "Epoch 8962/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2044 - accuracy: 0.3131 - val_loss: 2.2064 - val_accuracy: 0.3046\n",
            "Epoch 8963/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2044 - accuracy: 0.3131 - val_loss: 2.2064 - val_accuracy: 0.3046\n",
            "Epoch 8964/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2044 - accuracy: 0.3131 - val_loss: 2.2064 - val_accuracy: 0.3046\n",
            "Epoch 8965/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2044 - accuracy: 0.3131 - val_loss: 2.2063 - val_accuracy: 0.3046\n",
            "Epoch 8966/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2044 - accuracy: 0.3131 - val_loss: 2.2063 - val_accuracy: 0.3046\n",
            "Epoch 8967/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2044 - accuracy: 0.3131 - val_loss: 2.2063 - val_accuracy: 0.3046\n",
            "Epoch 8968/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2044 - accuracy: 0.3132 - val_loss: 2.2063 - val_accuracy: 0.3046\n",
            "Epoch 8969/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2044 - accuracy: 0.3132 - val_loss: 2.2063 - val_accuracy: 0.3046\n",
            "Epoch 8970/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2044 - accuracy: 0.3132 - val_loss: 2.2063 - val_accuracy: 0.3046\n",
            "Epoch 8971/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2044 - accuracy: 0.3132 - val_loss: 2.2063 - val_accuracy: 0.3046\n",
            "Epoch 8972/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2043 - accuracy: 0.3132 - val_loss: 2.2063 - val_accuracy: 0.3046\n",
            "Epoch 8973/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2043 - accuracy: 0.3133 - val_loss: 2.2063 - val_accuracy: 0.3046\n",
            "Epoch 8974/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2043 - accuracy: 0.3133 - val_loss: 2.2063 - val_accuracy: 0.3047\n",
            "Epoch 8975/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2043 - accuracy: 0.3133 - val_loss: 2.2063 - val_accuracy: 0.3049\n",
            "Epoch 8976/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2043 - accuracy: 0.3133 - val_loss: 2.2063 - val_accuracy: 0.3050\n",
            "Epoch 8977/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2043 - accuracy: 0.3133 - val_loss: 2.2062 - val_accuracy: 0.3050\n",
            "Epoch 8978/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2043 - accuracy: 0.3133 - val_loss: 2.2062 - val_accuracy: 0.3050\n",
            "Epoch 8979/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2043 - accuracy: 0.3133 - val_loss: 2.2062 - val_accuracy: 0.3051\n",
            "Epoch 8980/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2043 - accuracy: 0.3133 - val_loss: 2.2062 - val_accuracy: 0.3051\n",
            "Epoch 8981/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2043 - accuracy: 0.3133 - val_loss: 2.2062 - val_accuracy: 0.3051\n",
            "Epoch 8982/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2043 - accuracy: 0.3134 - val_loss: 2.2062 - val_accuracy: 0.3051\n",
            "Epoch 8983/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2043 - accuracy: 0.3134 - val_loss: 2.2062 - val_accuracy: 0.3051\n",
            "Epoch 8984/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2042 - accuracy: 0.3134 - val_loss: 2.2062 - val_accuracy: 0.3051\n",
            "Epoch 8985/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2042 - accuracy: 0.3134 - val_loss: 2.2062 - val_accuracy: 0.3052\n",
            "Epoch 8986/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2042 - accuracy: 0.3134 - val_loss: 2.2062 - val_accuracy: 0.3052\n",
            "Epoch 8987/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2042 - accuracy: 0.3135 - val_loss: 2.2062 - val_accuracy: 0.3052\n",
            "Epoch 8988/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2042 - accuracy: 0.3135 - val_loss: 2.2061 - val_accuracy: 0.3051\n",
            "Epoch 8989/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2042 - accuracy: 0.3135 - val_loss: 2.2061 - val_accuracy: 0.3052\n",
            "Epoch 8990/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2042 - accuracy: 0.3135 - val_loss: 2.2061 - val_accuracy: 0.3051\n",
            "Epoch 8991/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2042 - accuracy: 0.3135 - val_loss: 2.2061 - val_accuracy: 0.3052\n",
            "Epoch 8992/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2042 - accuracy: 0.3136 - val_loss: 2.2061 - val_accuracy: 0.3052\n",
            "Epoch 8993/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2042 - accuracy: 0.3136 - val_loss: 2.2061 - val_accuracy: 0.3052\n",
            "Epoch 8994/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2042 - accuracy: 0.3137 - val_loss: 2.2061 - val_accuracy: 0.3053\n",
            "Epoch 8995/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2041 - accuracy: 0.3137 - val_loss: 2.2061 - val_accuracy: 0.3053\n",
            "Epoch 8996/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2041 - accuracy: 0.3138 - val_loss: 2.2061 - val_accuracy: 0.3053\n",
            "Epoch 8997/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2041 - accuracy: 0.3138 - val_loss: 2.2061 - val_accuracy: 0.3054\n",
            "Epoch 8998/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2041 - accuracy: 0.3138 - val_loss: 2.2061 - val_accuracy: 0.3056\n",
            "Epoch 8999/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2041 - accuracy: 0.3138 - val_loss: 2.2061 - val_accuracy: 0.3056\n",
            "Epoch 9000/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2041 - accuracy: 0.3139 - val_loss: 2.2060 - val_accuracy: 0.3056\n",
            "Epoch 9001/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2041 - accuracy: 0.3139 - val_loss: 2.2060 - val_accuracy: 0.3056\n",
            "Epoch 9002/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2041 - accuracy: 0.3139 - val_loss: 2.2060 - val_accuracy: 0.3056\n",
            "Epoch 9003/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2041 - accuracy: 0.3139 - val_loss: 2.2060 - val_accuracy: 0.3056\n",
            "Epoch 9004/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2041 - accuracy: 0.3140 - val_loss: 2.2060 - val_accuracy: 0.3057\n",
            "Epoch 9005/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2041 - accuracy: 0.3140 - val_loss: 2.2060 - val_accuracy: 0.3061\n",
            "Epoch 9006/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2040 - accuracy: 0.3140 - val_loss: 2.2060 - val_accuracy: 0.3063\n",
            "Epoch 9007/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2040 - accuracy: 0.3140 - val_loss: 2.2060 - val_accuracy: 0.3064\n",
            "Epoch 9008/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2040 - accuracy: 0.3140 - val_loss: 2.2060 - val_accuracy: 0.3065\n",
            "Epoch 9009/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2040 - accuracy: 0.3141 - val_loss: 2.2060 - val_accuracy: 0.3065\n",
            "Epoch 9010/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2040 - accuracy: 0.3141 - val_loss: 2.2060 - val_accuracy: 0.3065\n",
            "Epoch 9011/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2040 - accuracy: 0.3141 - val_loss: 2.2059 - val_accuracy: 0.3065\n",
            "Epoch 9012/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2040 - accuracy: 0.3142 - val_loss: 2.2059 - val_accuracy: 0.3065\n",
            "Epoch 9013/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2040 - accuracy: 0.3142 - val_loss: 2.2059 - val_accuracy: 0.3066\n",
            "Epoch 9014/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2040 - accuracy: 0.3142 - val_loss: 2.2059 - val_accuracy: 0.3066\n",
            "Epoch 9015/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2040 - accuracy: 0.3142 - val_loss: 2.2059 - val_accuracy: 0.3067\n",
            "Epoch 9016/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2040 - accuracy: 0.3142 - val_loss: 2.2059 - val_accuracy: 0.3067\n",
            "Epoch 9017/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2040 - accuracy: 0.3142 - val_loss: 2.2059 - val_accuracy: 0.3068\n",
            "Epoch 9018/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2039 - accuracy: 0.3142 - val_loss: 2.2059 - val_accuracy: 0.3068\n",
            "Epoch 9019/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2039 - accuracy: 0.3143 - val_loss: 2.2059 - val_accuracy: 0.3068\n",
            "Epoch 9020/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2039 - accuracy: 0.3143 - val_loss: 2.2059 - val_accuracy: 0.3068\n",
            "Epoch 9021/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2039 - accuracy: 0.3144 - val_loss: 2.2059 - val_accuracy: 0.3068\n",
            "Epoch 9022/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2039 - accuracy: 0.3144 - val_loss: 2.2058 - val_accuracy: 0.3068\n",
            "Epoch 9023/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2039 - accuracy: 0.3144 - val_loss: 2.2058 - val_accuracy: 0.3069\n",
            "Epoch 9024/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2039 - accuracy: 0.3144 - val_loss: 2.2058 - val_accuracy: 0.3069\n",
            "Epoch 9025/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2039 - accuracy: 0.3144 - val_loss: 2.2058 - val_accuracy: 0.3069\n",
            "Epoch 9026/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2039 - accuracy: 0.3144 - val_loss: 2.2058 - val_accuracy: 0.3069\n",
            "Epoch 9027/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2039 - accuracy: 0.3144 - val_loss: 2.2058 - val_accuracy: 0.3069\n",
            "Epoch 9028/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2039 - accuracy: 0.3144 - val_loss: 2.2058 - val_accuracy: 0.3069\n",
            "Epoch 9029/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2038 - accuracy: 0.3145 - val_loss: 2.2058 - val_accuracy: 0.3069\n",
            "Epoch 9030/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2038 - accuracy: 0.3145 - val_loss: 2.2058 - val_accuracy: 0.3069\n",
            "Epoch 9031/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2038 - accuracy: 0.3145 - val_loss: 2.2058 - val_accuracy: 0.3069\n",
            "Epoch 9032/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2038 - accuracy: 0.3145 - val_loss: 2.2058 - val_accuracy: 0.3069\n",
            "Epoch 9033/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2038 - accuracy: 0.3145 - val_loss: 2.2058 - val_accuracy: 0.3071\n",
            "Epoch 9034/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2038 - accuracy: 0.3146 - val_loss: 2.2057 - val_accuracy: 0.3071\n",
            "Epoch 9035/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2038 - accuracy: 0.3146 - val_loss: 2.2057 - val_accuracy: 0.3071\n",
            "Epoch 9036/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2038 - accuracy: 0.3146 - val_loss: 2.2057 - val_accuracy: 0.3071\n",
            "Epoch 9037/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2038 - accuracy: 0.3146 - val_loss: 2.2057 - val_accuracy: 0.3071\n",
            "Epoch 9038/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2038 - accuracy: 0.3147 - val_loss: 2.2057 - val_accuracy: 0.3071\n",
            "Epoch 9039/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2038 - accuracy: 0.3147 - val_loss: 2.2057 - val_accuracy: 0.3071\n",
            "Epoch 9040/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2037 - accuracy: 0.3147 - val_loss: 2.2057 - val_accuracy: 0.3071\n",
            "Epoch 9041/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2037 - accuracy: 0.3147 - val_loss: 2.2057 - val_accuracy: 0.3071\n",
            "Epoch 9042/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2037 - accuracy: 0.3148 - val_loss: 2.2057 - val_accuracy: 0.3071\n",
            "Epoch 9043/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2037 - accuracy: 0.3148 - val_loss: 2.2057 - val_accuracy: 0.3071\n",
            "Epoch 9044/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2037 - accuracy: 0.3148 - val_loss: 2.2057 - val_accuracy: 0.3071\n",
            "Epoch 9045/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2037 - accuracy: 0.3148 - val_loss: 2.2056 - val_accuracy: 0.3071\n",
            "Epoch 9046/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2037 - accuracy: 0.3148 - val_loss: 2.2056 - val_accuracy: 0.3071\n",
            "Epoch 9047/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2037 - accuracy: 0.3149 - val_loss: 2.2056 - val_accuracy: 0.3071\n",
            "Epoch 9048/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2037 - accuracy: 0.3149 - val_loss: 2.2056 - val_accuracy: 0.3071\n",
            "Epoch 9049/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2037 - accuracy: 0.3149 - val_loss: 2.2056 - val_accuracy: 0.3072\n",
            "Epoch 9050/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2037 - accuracy: 0.3149 - val_loss: 2.2056 - val_accuracy: 0.3073\n",
            "Epoch 9051/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2037 - accuracy: 0.3149 - val_loss: 2.2056 - val_accuracy: 0.3073\n",
            "Epoch 9052/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2036 - accuracy: 0.3149 - val_loss: 2.2056 - val_accuracy: 0.3073\n",
            "Epoch 9053/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2036 - accuracy: 0.3149 - val_loss: 2.2056 - val_accuracy: 0.3074\n",
            "Epoch 9054/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2036 - accuracy: 0.3149 - val_loss: 2.2056 - val_accuracy: 0.3074\n",
            "Epoch 9055/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2036 - accuracy: 0.3149 - val_loss: 2.2056 - val_accuracy: 0.3074\n",
            "Epoch 9056/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2036 - accuracy: 0.3150 - val_loss: 2.2056 - val_accuracy: 0.3074\n",
            "Epoch 9057/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2036 - accuracy: 0.3150 - val_loss: 2.2055 - val_accuracy: 0.3074\n",
            "Epoch 9058/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2036 - accuracy: 0.3150 - val_loss: 2.2055 - val_accuracy: 0.3074\n",
            "Epoch 9059/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2036 - accuracy: 0.3151 - val_loss: 2.2055 - val_accuracy: 0.3074\n",
            "Epoch 9060/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2036 - accuracy: 0.3151 - val_loss: 2.2055 - val_accuracy: 0.3074\n",
            "Epoch 9061/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2036 - accuracy: 0.3151 - val_loss: 2.2055 - val_accuracy: 0.3074\n",
            "Epoch 9062/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2036 - accuracy: 0.3151 - val_loss: 2.2055 - val_accuracy: 0.3074\n",
            "Epoch 9063/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2035 - accuracy: 0.3151 - val_loss: 2.2055 - val_accuracy: 0.3074\n",
            "Epoch 9064/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2035 - accuracy: 0.3152 - val_loss: 2.2055 - val_accuracy: 0.3074\n",
            "Epoch 9065/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2035 - accuracy: 0.3152 - val_loss: 2.2055 - val_accuracy: 0.3075\n",
            "Epoch 9066/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2035 - accuracy: 0.3152 - val_loss: 2.2055 - val_accuracy: 0.3075\n",
            "Epoch 9067/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2035 - accuracy: 0.3153 - val_loss: 2.2055 - val_accuracy: 0.3075\n",
            "Epoch 9068/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2035 - accuracy: 0.3153 - val_loss: 2.2054 - val_accuracy: 0.3075\n",
            "Epoch 9069/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2035 - accuracy: 0.3153 - val_loss: 2.2054 - val_accuracy: 0.3076\n",
            "Epoch 9070/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2035 - accuracy: 0.3153 - val_loss: 2.2054 - val_accuracy: 0.3076\n",
            "Epoch 9071/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2035 - accuracy: 0.3153 - val_loss: 2.2054 - val_accuracy: 0.3076\n",
            "Epoch 9072/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2035 - accuracy: 0.3153 - val_loss: 2.2054 - val_accuracy: 0.3077\n",
            "Epoch 9073/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2035 - accuracy: 0.3154 - val_loss: 2.2054 - val_accuracy: 0.3077\n",
            "Epoch 9074/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2034 - accuracy: 0.3154 - val_loss: 2.2054 - val_accuracy: 0.3077\n",
            "Epoch 9075/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2034 - accuracy: 0.3155 - val_loss: 2.2054 - val_accuracy: 0.3077\n",
            "Epoch 9076/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2034 - accuracy: 0.3155 - val_loss: 2.2054 - val_accuracy: 0.3077\n",
            "Epoch 9077/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2034 - accuracy: 0.3155 - val_loss: 2.2054 - val_accuracy: 0.3077\n",
            "Epoch 9078/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2034 - accuracy: 0.3155 - val_loss: 2.2054 - val_accuracy: 0.3077\n",
            "Epoch 9079/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2034 - accuracy: 0.3155 - val_loss: 2.2054 - val_accuracy: 0.3078\n",
            "Epoch 9080/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2034 - accuracy: 0.3155 - val_loss: 2.2053 - val_accuracy: 0.3079\n",
            "Epoch 9081/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2034 - accuracy: 0.3155 - val_loss: 2.2053 - val_accuracy: 0.3079\n",
            "Epoch 9082/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2034 - accuracy: 0.3155 - val_loss: 2.2053 - val_accuracy: 0.3079\n",
            "Epoch 9083/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2034 - accuracy: 0.3155 - val_loss: 2.2053 - val_accuracy: 0.3079\n",
            "Epoch 9084/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2034 - accuracy: 0.3156 - val_loss: 2.2053 - val_accuracy: 0.3078\n",
            "Epoch 9085/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2034 - accuracy: 0.3156 - val_loss: 2.2053 - val_accuracy: 0.3078\n",
            "Epoch 9086/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2033 - accuracy: 0.3156 - val_loss: 2.2053 - val_accuracy: 0.3078\n",
            "Epoch 9087/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2033 - accuracy: 0.3157 - val_loss: 2.2053 - val_accuracy: 0.3078\n",
            "Epoch 9088/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2033 - accuracy: 0.3157 - val_loss: 2.2053 - val_accuracy: 0.3078\n",
            "Epoch 9089/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2033 - accuracy: 0.3157 - val_loss: 2.2053 - val_accuracy: 0.3077\n",
            "Epoch 9090/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2033 - accuracy: 0.3158 - val_loss: 2.2053 - val_accuracy: 0.3077\n",
            "Epoch 9091/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2033 - accuracy: 0.3158 - val_loss: 2.2052 - val_accuracy: 0.3077\n",
            "Epoch 9092/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2033 - accuracy: 0.3158 - val_loss: 2.2052 - val_accuracy: 0.3077\n",
            "Epoch 9093/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2033 - accuracy: 0.3158 - val_loss: 2.2052 - val_accuracy: 0.3077\n",
            "Epoch 9094/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2033 - accuracy: 0.3158 - val_loss: 2.2052 - val_accuracy: 0.3077\n",
            "Epoch 9095/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2033 - accuracy: 0.3158 - val_loss: 2.2052 - val_accuracy: 0.3078\n",
            "Epoch 9096/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2033 - accuracy: 0.3158 - val_loss: 2.2052 - val_accuracy: 0.3078\n",
            "Epoch 9097/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2032 - accuracy: 0.3158 - val_loss: 2.2052 - val_accuracy: 0.3079\n",
            "Epoch 9098/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2032 - accuracy: 0.3159 - val_loss: 2.2052 - val_accuracy: 0.3080\n",
            "Epoch 9099/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2032 - accuracy: 0.3159 - val_loss: 2.2052 - val_accuracy: 0.3080\n",
            "Epoch 9100/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2032 - accuracy: 0.3160 - val_loss: 2.2052 - val_accuracy: 0.3080\n",
            "Epoch 9101/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2032 - accuracy: 0.3160 - val_loss: 2.2052 - val_accuracy: 0.3080\n",
            "Epoch 9102/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2032 - accuracy: 0.3160 - val_loss: 2.2052 - val_accuracy: 0.3081\n",
            "Epoch 9103/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2032 - accuracy: 0.3160 - val_loss: 2.2051 - val_accuracy: 0.3081\n",
            "Epoch 9104/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2032 - accuracy: 0.3160 - val_loss: 2.2051 - val_accuracy: 0.3081\n",
            "Epoch 9105/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2032 - accuracy: 0.3160 - val_loss: 2.2051 - val_accuracy: 0.3081\n",
            "Epoch 9106/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2032 - accuracy: 0.3161 - val_loss: 2.2051 - val_accuracy: 0.3081\n",
            "Epoch 9107/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2032 - accuracy: 0.3161 - val_loss: 2.2051 - val_accuracy: 0.3081\n",
            "Epoch 9108/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2032 - accuracy: 0.3161 - val_loss: 2.2051 - val_accuracy: 0.3082\n",
            "Epoch 9109/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2031 - accuracy: 0.3161 - val_loss: 2.2051 - val_accuracy: 0.3082\n",
            "Epoch 9110/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2031 - accuracy: 0.3161 - val_loss: 2.2051 - val_accuracy: 0.3083\n",
            "Epoch 9111/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2031 - accuracy: 0.3161 - val_loss: 2.2051 - val_accuracy: 0.3083\n",
            "Epoch 9112/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2031 - accuracy: 0.3161 - val_loss: 2.2051 - val_accuracy: 0.3083\n",
            "Epoch 9113/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2031 - accuracy: 0.3162 - val_loss: 2.2051 - val_accuracy: 0.3083\n",
            "Epoch 9114/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2031 - accuracy: 0.3162 - val_loss: 2.2050 - val_accuracy: 0.3083\n",
            "Epoch 9115/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2031 - accuracy: 0.3162 - val_loss: 2.2050 - val_accuracy: 0.3083\n",
            "Epoch 9116/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2031 - accuracy: 0.3163 - val_loss: 2.2050 - val_accuracy: 0.3085\n",
            "Epoch 9117/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2031 - accuracy: 0.3163 - val_loss: 2.2050 - val_accuracy: 0.3085\n",
            "Epoch 9118/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2031 - accuracy: 0.3163 - val_loss: 2.2050 - val_accuracy: 0.3085\n",
            "Epoch 9119/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2031 - accuracy: 0.3164 - val_loss: 2.2050 - val_accuracy: 0.3085\n",
            "Epoch 9120/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2030 - accuracy: 0.3164 - val_loss: 2.2050 - val_accuracy: 0.3084\n",
            "Epoch 9121/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2030 - accuracy: 0.3164 - val_loss: 2.2050 - val_accuracy: 0.3085\n",
            "Epoch 9122/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2030 - accuracy: 0.3165 - val_loss: 2.2050 - val_accuracy: 0.3086\n",
            "Epoch 9123/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2030 - accuracy: 0.3165 - val_loss: 2.2050 - val_accuracy: 0.3086\n",
            "Epoch 9124/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2030 - accuracy: 0.3165 - val_loss: 2.2050 - val_accuracy: 0.3086\n",
            "Epoch 9125/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2030 - accuracy: 0.3165 - val_loss: 2.2050 - val_accuracy: 0.3086\n",
            "Epoch 9126/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2030 - accuracy: 0.3166 - val_loss: 2.2049 - val_accuracy: 0.3086\n",
            "Epoch 9127/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2030 - accuracy: 0.3166 - val_loss: 2.2049 - val_accuracy: 0.3086\n",
            "Epoch 9128/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2030 - accuracy: 0.3166 - val_loss: 2.2049 - val_accuracy: 0.3087\n",
            "Epoch 9129/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2030 - accuracy: 0.3167 - val_loss: 2.2049 - val_accuracy: 0.3088\n",
            "Epoch 9130/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2030 - accuracy: 0.3167 - val_loss: 2.2049 - val_accuracy: 0.3088\n",
            "Epoch 9131/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2030 - accuracy: 0.3167 - val_loss: 2.2049 - val_accuracy: 0.3088\n",
            "Epoch 9132/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2029 - accuracy: 0.3167 - val_loss: 2.2049 - val_accuracy: 0.3088\n",
            "Epoch 9133/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2029 - accuracy: 0.3167 - val_loss: 2.2049 - val_accuracy: 0.3088\n",
            "Epoch 9134/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2029 - accuracy: 0.3167 - val_loss: 2.2049 - val_accuracy: 0.3088\n",
            "Epoch 9135/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2029 - accuracy: 0.3168 - val_loss: 2.2049 - val_accuracy: 0.3089\n",
            "Epoch 9136/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2029 - accuracy: 0.3168 - val_loss: 2.2049 - val_accuracy: 0.3089\n",
            "Epoch 9137/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.2029 - accuracy: 0.3168 - val_loss: 2.2048 - val_accuracy: 0.3089\n",
            "Epoch 9138/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2029 - accuracy: 0.3168 - val_loss: 2.2048 - val_accuracy: 0.3089\n",
            "Epoch 9139/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2029 - accuracy: 0.3168 - val_loss: 2.2048 - val_accuracy: 0.3089\n",
            "Epoch 9140/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2029 - accuracy: 0.3168 - val_loss: 2.2048 - val_accuracy: 0.3089\n",
            "Epoch 9141/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2029 - accuracy: 0.3168 - val_loss: 2.2048 - val_accuracy: 0.3089\n",
            "Epoch 9142/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2029 - accuracy: 0.3169 - val_loss: 2.2048 - val_accuracy: 0.3089\n",
            "Epoch 9143/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2028 - accuracy: 0.3169 - val_loss: 2.2048 - val_accuracy: 0.3089\n",
            "Epoch 9144/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2028 - accuracy: 0.3169 - val_loss: 2.2048 - val_accuracy: 0.3089\n",
            "Epoch 9145/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2028 - accuracy: 0.3170 - val_loss: 2.2048 - val_accuracy: 0.3090\n",
            "Epoch 9146/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2028 - accuracy: 0.3170 - val_loss: 2.2048 - val_accuracy: 0.3090\n",
            "Epoch 9147/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2028 - accuracy: 0.3170 - val_loss: 2.2048 - val_accuracy: 0.3090\n",
            "Epoch 9148/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2028 - accuracy: 0.3170 - val_loss: 2.2048 - val_accuracy: 0.3090\n",
            "Epoch 9149/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2028 - accuracy: 0.3171 - val_loss: 2.2047 - val_accuracy: 0.3090\n",
            "Epoch 9150/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2028 - accuracy: 0.3171 - val_loss: 2.2047 - val_accuracy: 0.3090\n",
            "Epoch 9151/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2028 - accuracy: 0.3171 - val_loss: 2.2047 - val_accuracy: 0.3091\n",
            "Epoch 9152/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2028 - accuracy: 0.3171 - val_loss: 2.2047 - val_accuracy: 0.3091\n",
            "Epoch 9153/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2028 - accuracy: 0.3171 - val_loss: 2.2047 - val_accuracy: 0.3092\n",
            "Epoch 9154/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2027 - accuracy: 0.3171 - val_loss: 2.2047 - val_accuracy: 0.3092\n",
            "Epoch 9155/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2027 - accuracy: 0.3171 - val_loss: 2.2047 - val_accuracy: 0.3092\n",
            "Epoch 9156/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2027 - accuracy: 0.3171 - val_loss: 2.2047 - val_accuracy: 0.3092\n",
            "Epoch 9157/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2027 - accuracy: 0.3171 - val_loss: 2.2047 - val_accuracy: 0.3092\n",
            "Epoch 9158/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2027 - accuracy: 0.3172 - val_loss: 2.2047 - val_accuracy: 0.3092\n",
            "Epoch 9159/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2027 - accuracy: 0.3172 - val_loss: 2.2047 - val_accuracy: 0.3092\n",
            "Epoch 9160/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2027 - accuracy: 0.3172 - val_loss: 2.2046 - val_accuracy: 0.3092\n",
            "Epoch 9161/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2027 - accuracy: 0.3172 - val_loss: 2.2046 - val_accuracy: 0.3092\n",
            "Epoch 9162/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2027 - accuracy: 0.3173 - val_loss: 2.2046 - val_accuracy: 0.3092\n",
            "Epoch 9163/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2027 - accuracy: 0.3173 - val_loss: 2.2046 - val_accuracy: 0.3093\n",
            "Epoch 9164/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2027 - accuracy: 0.3173 - val_loss: 2.2046 - val_accuracy: 0.3094\n",
            "Epoch 9165/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2027 - accuracy: 0.3173 - val_loss: 2.2046 - val_accuracy: 0.3094\n",
            "Epoch 9166/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2026 - accuracy: 0.3173 - val_loss: 2.2046 - val_accuracy: 0.3094\n",
            "Epoch 9167/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2026 - accuracy: 0.3173 - val_loss: 2.2046 - val_accuracy: 0.3094\n",
            "Epoch 9168/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2026 - accuracy: 0.3173 - val_loss: 2.2046 - val_accuracy: 0.3094\n",
            "Epoch 9169/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2026 - accuracy: 0.3173 - val_loss: 2.2046 - val_accuracy: 0.3095\n",
            "Epoch 9170/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2026 - accuracy: 0.3174 - val_loss: 2.2046 - val_accuracy: 0.3095\n",
            "Epoch 9171/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2026 - accuracy: 0.3174 - val_loss: 2.2046 - val_accuracy: 0.3095\n",
            "Epoch 9172/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2026 - accuracy: 0.3174 - val_loss: 2.2045 - val_accuracy: 0.3095\n",
            "Epoch 9173/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2026 - accuracy: 0.3174 - val_loss: 2.2045 - val_accuracy: 0.3096\n",
            "Epoch 9174/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.2026 - accuracy: 0.3175 - val_loss: 2.2045 - val_accuracy: 0.3097\n",
            "Epoch 9175/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2026 - accuracy: 0.3175 - val_loss: 2.2045 - val_accuracy: 0.3097\n",
            "Epoch 9176/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2026 - accuracy: 0.3176 - val_loss: 2.2045 - val_accuracy: 0.3097\n",
            "Epoch 9177/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2025 - accuracy: 0.3176 - val_loss: 2.2045 - val_accuracy: 0.3097\n",
            "Epoch 9178/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2025 - accuracy: 0.3176 - val_loss: 2.2045 - val_accuracy: 0.3097\n",
            "Epoch 9179/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2025 - accuracy: 0.3176 - val_loss: 2.2045 - val_accuracy: 0.3097\n",
            "Epoch 9180/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2025 - accuracy: 0.3176 - val_loss: 2.2045 - val_accuracy: 0.3098\n",
            "Epoch 9181/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2025 - accuracy: 0.3176 - val_loss: 2.2045 - val_accuracy: 0.3098\n",
            "Epoch 9182/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2025 - accuracy: 0.3177 - val_loss: 2.2045 - val_accuracy: 0.3098\n",
            "Epoch 9183/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2025 - accuracy: 0.3177 - val_loss: 2.2045 - val_accuracy: 0.3099\n",
            "Epoch 9184/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.2025 - accuracy: 0.3177 - val_loss: 2.2044 - val_accuracy: 0.3099\n",
            "Epoch 9185/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2025 - accuracy: 0.3177 - val_loss: 2.2044 - val_accuracy: 0.3099\n",
            "Epoch 9186/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2025 - accuracy: 0.3178 - val_loss: 2.2044 - val_accuracy: 0.3099\n",
            "Epoch 9187/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2025 - accuracy: 0.3178 - val_loss: 2.2044 - val_accuracy: 0.3099\n",
            "Epoch 9188/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2025 - accuracy: 0.3179 - val_loss: 2.2044 - val_accuracy: 0.3099\n",
            "Epoch 9189/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2024 - accuracy: 0.3179 - val_loss: 2.2044 - val_accuracy: 0.3099\n",
            "Epoch 9190/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2024 - accuracy: 0.3179 - val_loss: 2.2044 - val_accuracy: 0.3099\n",
            "Epoch 9191/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2024 - accuracy: 0.3180 - val_loss: 2.2044 - val_accuracy: 0.3100\n",
            "Epoch 9192/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2024 - accuracy: 0.3180 - val_loss: 2.2044 - val_accuracy: 0.3101\n",
            "Epoch 9193/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2024 - accuracy: 0.3180 - val_loss: 2.2044 - val_accuracy: 0.3101\n",
            "Epoch 9194/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2024 - accuracy: 0.3181 - val_loss: 2.2044 - val_accuracy: 0.3101\n",
            "Epoch 9195/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2024 - accuracy: 0.3181 - val_loss: 2.2043 - val_accuracy: 0.3101\n",
            "Epoch 9196/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2024 - accuracy: 0.3181 - val_loss: 2.2043 - val_accuracy: 0.3101\n",
            "Epoch 9197/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2024 - accuracy: 0.3181 - val_loss: 2.2043 - val_accuracy: 0.3102\n",
            "Epoch 9198/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2024 - accuracy: 0.3182 - val_loss: 2.2043 - val_accuracy: 0.3104\n",
            "Epoch 9199/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2024 - accuracy: 0.3182 - val_loss: 2.2043 - val_accuracy: 0.3105\n",
            "Epoch 9200/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2023 - accuracy: 0.3182 - val_loss: 2.2043 - val_accuracy: 0.3105\n",
            "Epoch 9201/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2023 - accuracy: 0.3182 - val_loss: 2.2043 - val_accuracy: 0.3105\n",
            "Epoch 9202/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2023 - accuracy: 0.3182 - val_loss: 2.2043 - val_accuracy: 0.3106\n",
            "Epoch 9203/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2023 - accuracy: 0.3182 - val_loss: 2.2043 - val_accuracy: 0.3106\n",
            "Epoch 9204/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2023 - accuracy: 0.3183 - val_loss: 2.2043 - val_accuracy: 0.3106\n",
            "Epoch 9205/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2023 - accuracy: 0.3183 - val_loss: 2.2043 - val_accuracy: 0.3106\n",
            "Epoch 9206/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2023 - accuracy: 0.3183 - val_loss: 2.2043 - val_accuracy: 0.3106\n",
            "Epoch 9207/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2023 - accuracy: 0.3183 - val_loss: 2.2042 - val_accuracy: 0.3106\n",
            "Epoch 9208/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2023 - accuracy: 0.3183 - val_loss: 2.2042 - val_accuracy: 0.3107\n",
            "Epoch 9209/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2023 - accuracy: 0.3184 - val_loss: 2.2042 - val_accuracy: 0.3107\n",
            "Epoch 9210/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2023 - accuracy: 0.3184 - val_loss: 2.2042 - val_accuracy: 0.3107\n",
            "Epoch 9211/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2023 - accuracy: 0.3185 - val_loss: 2.2042 - val_accuracy: 0.3108\n",
            "Epoch 9212/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2022 - accuracy: 0.3185 - val_loss: 2.2042 - val_accuracy: 0.3108\n",
            "Epoch 9213/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2022 - accuracy: 0.3185 - val_loss: 2.2042 - val_accuracy: 0.3108\n",
            "Epoch 9214/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2022 - accuracy: 0.3185 - val_loss: 2.2042 - val_accuracy: 0.3108\n",
            "Epoch 9215/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2022 - accuracy: 0.3185 - val_loss: 2.2042 - val_accuracy: 0.3108\n",
            "Epoch 9216/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2022 - accuracy: 0.3185 - val_loss: 2.2042 - val_accuracy: 0.3108\n",
            "Epoch 9217/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2022 - accuracy: 0.3186 - val_loss: 2.2042 - val_accuracy: 0.3108\n",
            "Epoch 9218/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2022 - accuracy: 0.3186 - val_loss: 2.2041 - val_accuracy: 0.3108\n",
            "Epoch 9219/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2022 - accuracy: 0.3187 - val_loss: 2.2041 - val_accuracy: 0.3108\n",
            "Epoch 9220/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2022 - accuracy: 0.3187 - val_loss: 2.2041 - val_accuracy: 0.3108\n",
            "Epoch 9221/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2022 - accuracy: 0.3187 - val_loss: 2.2041 - val_accuracy: 0.3109\n",
            "Epoch 9222/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2022 - accuracy: 0.3187 - val_loss: 2.2041 - val_accuracy: 0.3110\n",
            "Epoch 9223/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2021 - accuracy: 0.3188 - val_loss: 2.2041 - val_accuracy: 0.3110\n",
            "Epoch 9224/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2021 - accuracy: 0.3189 - val_loss: 2.2041 - val_accuracy: 0.3110\n",
            "Epoch 9225/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2021 - accuracy: 0.3189 - val_loss: 2.2041 - val_accuracy: 0.3110\n",
            "Epoch 9226/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2021 - accuracy: 0.3189 - val_loss: 2.2041 - val_accuracy: 0.3110\n",
            "Epoch 9227/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2021 - accuracy: 0.3189 - val_loss: 2.2041 - val_accuracy: 0.3110\n",
            "Epoch 9228/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2021 - accuracy: 0.3189 - val_loss: 2.2041 - val_accuracy: 0.3110\n",
            "Epoch 9229/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2021 - accuracy: 0.3189 - val_loss: 2.2041 - val_accuracy: 0.3110\n",
            "Epoch 9230/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2021 - accuracy: 0.3189 - val_loss: 2.2040 - val_accuracy: 0.3111\n",
            "Epoch 9231/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2021 - accuracy: 0.3189 - val_loss: 2.2040 - val_accuracy: 0.3112\n",
            "Epoch 9232/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2021 - accuracy: 0.3189 - val_loss: 2.2040 - val_accuracy: 0.3112\n",
            "Epoch 9233/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2021 - accuracy: 0.3189 - val_loss: 2.2040 - val_accuracy: 0.3113\n",
            "Epoch 9234/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2021 - accuracy: 0.3190 - val_loss: 2.2040 - val_accuracy: 0.3113\n",
            "Epoch 9235/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2020 - accuracy: 0.3190 - val_loss: 2.2040 - val_accuracy: 0.3113\n",
            "Epoch 9236/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2020 - accuracy: 0.3191 - val_loss: 2.2040 - val_accuracy: 0.3113\n",
            "Epoch 9237/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2020 - accuracy: 0.3191 - val_loss: 2.2040 - val_accuracy: 0.3113\n",
            "Epoch 9238/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2020 - accuracy: 0.3191 - val_loss: 2.2040 - val_accuracy: 0.3113\n",
            "Epoch 9239/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2020 - accuracy: 0.3192 - val_loss: 2.2040 - val_accuracy: 0.3113\n",
            "Epoch 9240/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2020 - accuracy: 0.3192 - val_loss: 2.2040 - val_accuracy: 0.3113\n",
            "Epoch 9241/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2020 - accuracy: 0.3192 - val_loss: 2.2039 - val_accuracy: 0.3113\n",
            "Epoch 9242/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2020 - accuracy: 0.3192 - val_loss: 2.2039 - val_accuracy: 0.3113\n",
            "Epoch 9243/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2020 - accuracy: 0.3193 - val_loss: 2.2039 - val_accuracy: 0.3113\n",
            "Epoch 9244/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2020 - accuracy: 0.3194 - val_loss: 2.2039 - val_accuracy: 0.3113\n",
            "Epoch 9245/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2020 - accuracy: 0.3194 - val_loss: 2.2039 - val_accuracy: 0.3113\n",
            "Epoch 9246/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2019 - accuracy: 0.3194 - val_loss: 2.2039 - val_accuracy: 0.3113\n",
            "Epoch 9247/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2019 - accuracy: 0.3194 - val_loss: 2.2039 - val_accuracy: 0.3113\n",
            "Epoch 9248/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2019 - accuracy: 0.3194 - val_loss: 2.2039 - val_accuracy: 0.3113\n",
            "Epoch 9249/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2019 - accuracy: 0.3195 - val_loss: 2.2039 - val_accuracy: 0.3113\n",
            "Epoch 9250/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2019 - accuracy: 0.3195 - val_loss: 2.2039 - val_accuracy: 0.3113\n",
            "Epoch 9251/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2019 - accuracy: 0.3196 - val_loss: 2.2039 - val_accuracy: 0.3114\n",
            "Epoch 9252/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2019 - accuracy: 0.3196 - val_loss: 2.2039 - val_accuracy: 0.3114\n",
            "Epoch 9253/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2019 - accuracy: 0.3196 - val_loss: 2.2038 - val_accuracy: 0.3114\n",
            "Epoch 9254/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2019 - accuracy: 0.3196 - val_loss: 2.2038 - val_accuracy: 0.3114\n",
            "Epoch 9255/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2019 - accuracy: 0.3197 - val_loss: 2.2038 - val_accuracy: 0.3114\n",
            "Epoch 9256/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2019 - accuracy: 0.3197 - val_loss: 2.2038 - val_accuracy: 0.3114\n",
            "Epoch 9257/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2019 - accuracy: 0.3197 - val_loss: 2.2038 - val_accuracy: 0.3114\n",
            "Epoch 9258/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2018 - accuracy: 0.3198 - val_loss: 2.2038 - val_accuracy: 0.3114\n",
            "Epoch 9259/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2018 - accuracy: 0.3198 - val_loss: 2.2038 - val_accuracy: 0.3114\n",
            "Epoch 9260/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2018 - accuracy: 0.3198 - val_loss: 2.2038 - val_accuracy: 0.3114\n",
            "Epoch 9261/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2018 - accuracy: 0.3198 - val_loss: 2.2038 - val_accuracy: 0.3114\n",
            "Epoch 9262/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2018 - accuracy: 0.3199 - val_loss: 2.2038 - val_accuracy: 0.3114\n",
            "Epoch 9263/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2018 - accuracy: 0.3199 - val_loss: 2.2038 - val_accuracy: 0.3116\n",
            "Epoch 9264/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2018 - accuracy: 0.3199 - val_loss: 2.2038 - val_accuracy: 0.3118\n",
            "Epoch 9265/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2018 - accuracy: 0.3199 - val_loss: 2.2037 - val_accuracy: 0.3118\n",
            "Epoch 9266/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2018 - accuracy: 0.3200 - val_loss: 2.2037 - val_accuracy: 0.3119\n",
            "Epoch 9267/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2018 - accuracy: 0.3200 - val_loss: 2.2037 - val_accuracy: 0.3119\n",
            "Epoch 9268/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2018 - accuracy: 0.3200 - val_loss: 2.2037 - val_accuracy: 0.3119\n",
            "Epoch 9269/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2017 - accuracy: 0.3200 - val_loss: 2.2037 - val_accuracy: 0.3121\n",
            "Epoch 9270/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2017 - accuracy: 0.3201 - val_loss: 2.2037 - val_accuracy: 0.3122\n",
            "Epoch 9271/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2017 - accuracy: 0.3201 - val_loss: 2.2037 - val_accuracy: 0.3122\n",
            "Epoch 9272/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2017 - accuracy: 0.3201 - val_loss: 2.2037 - val_accuracy: 0.3122\n",
            "Epoch 9273/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2017 - accuracy: 0.3201 - val_loss: 2.2037 - val_accuracy: 0.3122\n",
            "Epoch 9274/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2017 - accuracy: 0.3201 - val_loss: 2.2037 - val_accuracy: 0.3122\n",
            "Epoch 9275/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2017 - accuracy: 0.3201 - val_loss: 2.2037 - val_accuracy: 0.3124\n",
            "Epoch 9276/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2017 - accuracy: 0.3201 - val_loss: 2.2036 - val_accuracy: 0.3124\n",
            "Epoch 9277/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2017 - accuracy: 0.3201 - val_loss: 2.2036 - val_accuracy: 0.3124\n",
            "Epoch 9278/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2017 - accuracy: 0.3202 - val_loss: 2.2036 - val_accuracy: 0.3125\n",
            "Epoch 9279/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2017 - accuracy: 0.3203 - val_loss: 2.2036 - val_accuracy: 0.3126\n",
            "Epoch 9280/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2017 - accuracy: 0.3203 - val_loss: 2.2036 - val_accuracy: 0.3126\n",
            "Epoch 9281/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2016 - accuracy: 0.3203 - val_loss: 2.2036 - val_accuracy: 0.3126\n",
            "Epoch 9282/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2016 - accuracy: 0.3204 - val_loss: 2.2036 - val_accuracy: 0.3126\n",
            "Epoch 9283/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2016 - accuracy: 0.3204 - val_loss: 2.2036 - val_accuracy: 0.3126\n",
            "Epoch 9284/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2016 - accuracy: 0.3204 - val_loss: 2.2036 - val_accuracy: 0.3126\n",
            "Epoch 9285/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2016 - accuracy: 0.3204 - val_loss: 2.2036 - val_accuracy: 0.3127\n",
            "Epoch 9286/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2016 - accuracy: 0.3204 - val_loss: 2.2036 - val_accuracy: 0.3127\n",
            "Epoch 9287/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2016 - accuracy: 0.3204 - val_loss: 2.2036 - val_accuracy: 0.3127\n",
            "Epoch 9288/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2016 - accuracy: 0.3204 - val_loss: 2.2035 - val_accuracy: 0.3127\n",
            "Epoch 9289/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2016 - accuracy: 0.3204 - val_loss: 2.2035 - val_accuracy: 0.3128\n",
            "Epoch 9290/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2016 - accuracy: 0.3205 - val_loss: 2.2035 - val_accuracy: 0.3128\n",
            "Epoch 9291/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2016 - accuracy: 0.3205 - val_loss: 2.2035 - val_accuracy: 0.3129\n",
            "Epoch 9292/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2015 - accuracy: 0.3205 - val_loss: 2.2035 - val_accuracy: 0.3129\n",
            "Epoch 9293/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2015 - accuracy: 0.3205 - val_loss: 2.2035 - val_accuracy: 0.3129\n",
            "Epoch 9294/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2015 - accuracy: 0.3205 - val_loss: 2.2035 - val_accuracy: 0.3129\n",
            "Epoch 9295/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2015 - accuracy: 0.3205 - val_loss: 2.2035 - val_accuracy: 0.3129\n",
            "Epoch 9296/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2015 - accuracy: 0.3205 - val_loss: 2.2035 - val_accuracy: 0.3129\n",
            "Epoch 9297/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2015 - accuracy: 0.3205 - val_loss: 2.2035 - val_accuracy: 0.3129\n",
            "Epoch 9298/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2015 - accuracy: 0.3206 - val_loss: 2.2035 - val_accuracy: 0.3129\n",
            "Epoch 9299/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2015 - accuracy: 0.3206 - val_loss: 2.2035 - val_accuracy: 0.3129\n",
            "Epoch 9300/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2015 - accuracy: 0.3207 - val_loss: 2.2034 - val_accuracy: 0.3130\n",
            "Epoch 9301/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2015 - accuracy: 0.3207 - val_loss: 2.2034 - val_accuracy: 0.3130\n",
            "Epoch 9302/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2015 - accuracy: 0.3207 - val_loss: 2.2034 - val_accuracy: 0.3131\n",
            "Epoch 9303/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2015 - accuracy: 0.3207 - val_loss: 2.2034 - val_accuracy: 0.3131\n",
            "Epoch 9304/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2014 - accuracy: 0.3208 - val_loss: 2.2034 - val_accuracy: 0.3131\n",
            "Epoch 9305/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2014 - accuracy: 0.3208 - val_loss: 2.2034 - val_accuracy: 0.3132\n",
            "Epoch 9306/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2014 - accuracy: 0.3208 - val_loss: 2.2034 - val_accuracy: 0.3132\n",
            "Epoch 9307/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2014 - accuracy: 0.3209 - val_loss: 2.2034 - val_accuracy: 0.3132\n",
            "Epoch 9308/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2014 - accuracy: 0.3209 - val_loss: 2.2034 - val_accuracy: 0.3133\n",
            "Epoch 9309/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2014 - accuracy: 0.3209 - val_loss: 2.2034 - val_accuracy: 0.3133\n",
            "Epoch 9310/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2014 - accuracy: 0.3209 - val_loss: 2.2034 - val_accuracy: 0.3133\n",
            "Epoch 9311/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2014 - accuracy: 0.3209 - val_loss: 2.2033 - val_accuracy: 0.3133\n",
            "Epoch 9312/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2014 - accuracy: 0.3210 - val_loss: 2.2033 - val_accuracy: 0.3133\n",
            "Epoch 9313/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2014 - accuracy: 0.3210 - val_loss: 2.2033 - val_accuracy: 0.3133\n",
            "Epoch 9314/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2014 - accuracy: 0.3210 - val_loss: 2.2033 - val_accuracy: 0.3134\n",
            "Epoch 9315/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2014 - accuracy: 0.3210 - val_loss: 2.2033 - val_accuracy: 0.3134\n",
            "Epoch 9316/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2013 - accuracy: 0.3210 - val_loss: 2.2033 - val_accuracy: 0.3134\n",
            "Epoch 9317/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2013 - accuracy: 0.3210 - val_loss: 2.2033 - val_accuracy: 0.3134\n",
            "Epoch 9318/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2013 - accuracy: 0.3210 - val_loss: 2.2033 - val_accuracy: 0.3134\n",
            "Epoch 9319/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2013 - accuracy: 0.3210 - val_loss: 2.2033 - val_accuracy: 0.3134\n",
            "Epoch 9320/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2013 - accuracy: 0.3211 - val_loss: 2.2033 - val_accuracy: 0.3135\n",
            "Epoch 9321/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2013 - accuracy: 0.3211 - val_loss: 2.2033 - val_accuracy: 0.3136\n",
            "Epoch 9322/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2013 - accuracy: 0.3212 - val_loss: 2.2033 - val_accuracy: 0.3136\n",
            "Epoch 9323/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2013 - accuracy: 0.3212 - val_loss: 2.2032 - val_accuracy: 0.3136\n",
            "Epoch 9324/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2013 - accuracy: 0.3212 - val_loss: 2.2032 - val_accuracy: 0.3136\n",
            "Epoch 9325/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2013 - accuracy: 0.3212 - val_loss: 2.2032 - val_accuracy: 0.3136\n",
            "Epoch 9326/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2013 - accuracy: 0.3212 - val_loss: 2.2032 - val_accuracy: 0.3137\n",
            "Epoch 9327/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2012 - accuracy: 0.3213 - val_loss: 2.2032 - val_accuracy: 0.3138\n",
            "Epoch 9328/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2012 - accuracy: 0.3213 - val_loss: 2.2032 - val_accuracy: 0.3138\n",
            "Epoch 9329/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2012 - accuracy: 0.3213 - val_loss: 2.2032 - val_accuracy: 0.3139\n",
            "Epoch 9330/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2012 - accuracy: 0.3213 - val_loss: 2.2032 - val_accuracy: 0.3139\n",
            "Epoch 9331/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2012 - accuracy: 0.3213 - val_loss: 2.2032 - val_accuracy: 0.3140\n",
            "Epoch 9332/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2012 - accuracy: 0.3213 - val_loss: 2.2032 - val_accuracy: 0.3140\n",
            "Epoch 9333/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2012 - accuracy: 0.3213 - val_loss: 2.2032 - val_accuracy: 0.3140\n",
            "Epoch 9334/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2012 - accuracy: 0.3214 - val_loss: 2.2032 - val_accuracy: 0.3140\n",
            "Epoch 9335/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2012 - accuracy: 0.3214 - val_loss: 2.2031 - val_accuracy: 0.3140\n",
            "Epoch 9336/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2012 - accuracy: 0.3214 - val_loss: 2.2031 - val_accuracy: 0.3140\n",
            "Epoch 9337/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2012 - accuracy: 0.3214 - val_loss: 2.2031 - val_accuracy: 0.3140\n",
            "Epoch 9338/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2012 - accuracy: 0.3214 - val_loss: 2.2031 - val_accuracy: 0.3140\n",
            "Epoch 9339/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2011 - accuracy: 0.3215 - val_loss: 2.2031 - val_accuracy: 0.3140\n",
            "Epoch 9340/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2011 - accuracy: 0.3215 - val_loss: 2.2031 - val_accuracy: 0.3140\n",
            "Epoch 9341/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2011 - accuracy: 0.3215 - val_loss: 2.2031 - val_accuracy: 0.3140\n",
            "Epoch 9342/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2011 - accuracy: 0.3216 - val_loss: 2.2031 - val_accuracy: 0.3140\n",
            "Epoch 9343/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2011 - accuracy: 0.3216 - val_loss: 2.2031 - val_accuracy: 0.3140\n",
            "Epoch 9344/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2011 - accuracy: 0.3216 - val_loss: 2.2031 - val_accuracy: 0.3140\n",
            "Epoch 9345/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2011 - accuracy: 0.3216 - val_loss: 2.2031 - val_accuracy: 0.3141\n",
            "Epoch 9346/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2011 - accuracy: 0.3216 - val_loss: 2.2030 - val_accuracy: 0.3141\n",
            "Epoch 9347/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2011 - accuracy: 0.3217 - val_loss: 2.2030 - val_accuracy: 0.3141\n",
            "Epoch 9348/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2011 - accuracy: 0.3217 - val_loss: 2.2030 - val_accuracy: 0.3141\n",
            "Epoch 9349/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2011 - accuracy: 0.3217 - val_loss: 2.2030 - val_accuracy: 0.3141\n",
            "Epoch 9350/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2010 - accuracy: 0.3217 - val_loss: 2.2030 - val_accuracy: 0.3143\n",
            "Epoch 9351/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2010 - accuracy: 0.3217 - val_loss: 2.2030 - val_accuracy: 0.3143\n",
            "Epoch 9352/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2010 - accuracy: 0.3217 - val_loss: 2.2030 - val_accuracy: 0.3143\n",
            "Epoch 9353/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2010 - accuracy: 0.3218 - val_loss: 2.2030 - val_accuracy: 0.3143\n",
            "Epoch 9354/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2010 - accuracy: 0.3218 - val_loss: 2.2030 - val_accuracy: 0.3143\n",
            "Epoch 9355/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2010 - accuracy: 0.3218 - val_loss: 2.2030 - val_accuracy: 0.3143\n",
            "Epoch 9356/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2010 - accuracy: 0.3219 - val_loss: 2.2030 - val_accuracy: 0.3143\n",
            "Epoch 9357/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2010 - accuracy: 0.3219 - val_loss: 2.2030 - val_accuracy: 0.3144\n",
            "Epoch 9358/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2010 - accuracy: 0.3219 - val_loss: 2.2029 - val_accuracy: 0.3145\n",
            "Epoch 9359/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2010 - accuracy: 0.3220 - val_loss: 2.2029 - val_accuracy: 0.3145\n",
            "Epoch 9360/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2010 - accuracy: 0.3220 - val_loss: 2.2029 - val_accuracy: 0.3145\n",
            "Epoch 9361/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2010 - accuracy: 0.3220 - val_loss: 2.2029 - val_accuracy: 0.3145\n",
            "Epoch 9362/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2009 - accuracy: 0.3221 - val_loss: 2.2029 - val_accuracy: 0.3146\n",
            "Epoch 9363/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2009 - accuracy: 0.3221 - val_loss: 2.2029 - val_accuracy: 0.3146\n",
            "Epoch 9364/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2009 - accuracy: 0.3221 - val_loss: 2.2029 - val_accuracy: 0.3146\n",
            "Epoch 9365/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2009 - accuracy: 0.3222 - val_loss: 2.2029 - val_accuracy: 0.3146\n",
            "Epoch 9366/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2009 - accuracy: 0.3222 - val_loss: 2.2029 - val_accuracy: 0.3146\n",
            "Epoch 9367/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2009 - accuracy: 0.3222 - val_loss: 2.2029 - val_accuracy: 0.3147\n",
            "Epoch 9368/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2009 - accuracy: 0.3223 - val_loss: 2.2029 - val_accuracy: 0.3148\n",
            "Epoch 9369/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2009 - accuracy: 0.3223 - val_loss: 2.2029 - val_accuracy: 0.3149\n",
            "Epoch 9370/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2009 - accuracy: 0.3223 - val_loss: 2.2028 - val_accuracy: 0.3150\n",
            "Epoch 9371/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2009 - accuracy: 0.3223 - val_loss: 2.2028 - val_accuracy: 0.3150\n",
            "Epoch 9372/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2009 - accuracy: 0.3223 - val_loss: 2.2028 - val_accuracy: 0.3150\n",
            "Epoch 9373/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2009 - accuracy: 0.3223 - val_loss: 2.2028 - val_accuracy: 0.3151\n",
            "Epoch 9374/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2008 - accuracy: 0.3223 - val_loss: 2.2028 - val_accuracy: 0.3151\n",
            "Epoch 9375/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2008 - accuracy: 0.3223 - val_loss: 2.2028 - val_accuracy: 0.3151\n",
            "Epoch 9376/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2008 - accuracy: 0.3223 - val_loss: 2.2028 - val_accuracy: 0.3151\n",
            "Epoch 9377/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2008 - accuracy: 0.3223 - val_loss: 2.2028 - val_accuracy: 0.3151\n",
            "Epoch 9378/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2008 - accuracy: 0.3224 - val_loss: 2.2028 - val_accuracy: 0.3151\n",
            "Epoch 9379/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2008 - accuracy: 0.3224 - val_loss: 2.2028 - val_accuracy: 0.3151\n",
            "Epoch 9380/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2008 - accuracy: 0.3225 - val_loss: 2.2028 - val_accuracy: 0.3151\n",
            "Epoch 9381/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2008 - accuracy: 0.3225 - val_loss: 2.2028 - val_accuracy: 0.3151\n",
            "Epoch 9382/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2008 - accuracy: 0.3225 - val_loss: 2.2027 - val_accuracy: 0.3151\n",
            "Epoch 9383/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2008 - accuracy: 0.3225 - val_loss: 2.2027 - val_accuracy: 0.3151\n",
            "Epoch 9384/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2008 - accuracy: 0.3225 - val_loss: 2.2027 - val_accuracy: 0.3152\n",
            "Epoch 9385/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2007 - accuracy: 0.3225 - val_loss: 2.2027 - val_accuracy: 0.3152\n",
            "Epoch 9386/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2007 - accuracy: 0.3225 - val_loss: 2.2027 - val_accuracy: 0.3152\n",
            "Epoch 9387/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2007 - accuracy: 0.3225 - val_loss: 2.2027 - val_accuracy: 0.3151\n",
            "Epoch 9388/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2007 - accuracy: 0.3225 - val_loss: 2.2027 - val_accuracy: 0.3151\n",
            "Epoch 9389/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2007 - accuracy: 0.3225 - val_loss: 2.2027 - val_accuracy: 0.3151\n",
            "Epoch 9390/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2007 - accuracy: 0.3225 - val_loss: 2.2027 - val_accuracy: 0.3151\n",
            "Epoch 9391/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2007 - accuracy: 0.3225 - val_loss: 2.2027 - val_accuracy: 0.3151\n",
            "Epoch 9392/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2007 - accuracy: 0.3226 - val_loss: 2.2027 - val_accuracy: 0.3151\n",
            "Epoch 9393/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2007 - accuracy: 0.3226 - val_loss: 2.2026 - val_accuracy: 0.3151\n",
            "Epoch 9394/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2007 - accuracy: 0.3226 - val_loss: 2.2026 - val_accuracy: 0.3152\n",
            "Epoch 9395/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2007 - accuracy: 0.3227 - val_loss: 2.2026 - val_accuracy: 0.3152\n",
            "Epoch 9396/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2007 - accuracy: 0.3226 - val_loss: 2.2026 - val_accuracy: 0.3152\n",
            "Epoch 9397/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2006 - accuracy: 0.3227 - val_loss: 2.2026 - val_accuracy: 0.3152\n",
            "Epoch 9398/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2006 - accuracy: 0.3227 - val_loss: 2.2026 - val_accuracy: 0.3152\n",
            "Epoch 9399/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2006 - accuracy: 0.3227 - val_loss: 2.2026 - val_accuracy: 0.3154\n",
            "Epoch 9400/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2006 - accuracy: 0.3228 - val_loss: 2.2026 - val_accuracy: 0.3155\n",
            "Epoch 9401/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2006 - accuracy: 0.3228 - val_loss: 2.2026 - val_accuracy: 0.3156\n",
            "Epoch 9402/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2006 - accuracy: 0.3228 - val_loss: 2.2026 - val_accuracy: 0.3156\n",
            "Epoch 9403/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2006 - accuracy: 0.3228 - val_loss: 2.2026 - val_accuracy: 0.3156\n",
            "Epoch 9404/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2006 - accuracy: 0.3228 - val_loss: 2.2026 - val_accuracy: 0.3156\n",
            "Epoch 9405/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2006 - accuracy: 0.3228 - val_loss: 2.2025 - val_accuracy: 0.3157\n",
            "Epoch 9406/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2006 - accuracy: 0.3229 - val_loss: 2.2025 - val_accuracy: 0.3157\n",
            "Epoch 9407/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2006 - accuracy: 0.3229 - val_loss: 2.2025 - val_accuracy: 0.3157\n",
            "Epoch 9408/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2006 - accuracy: 0.3229 - val_loss: 2.2025 - val_accuracy: 0.3157\n",
            "Epoch 9409/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2005 - accuracy: 0.3229 - val_loss: 2.2025 - val_accuracy: 0.3157\n",
            "Epoch 9410/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2005 - accuracy: 0.3230 - val_loss: 2.2025 - val_accuracy: 0.3157\n",
            "Epoch 9411/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2005 - accuracy: 0.3230 - val_loss: 2.2025 - val_accuracy: 0.3157\n",
            "Epoch 9412/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2005 - accuracy: 0.3230 - val_loss: 2.2025 - val_accuracy: 0.3157\n",
            "Epoch 9413/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2005 - accuracy: 0.3230 - val_loss: 2.2025 - val_accuracy: 0.3157\n",
            "Epoch 9414/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2005 - accuracy: 0.3231 - val_loss: 2.2025 - val_accuracy: 0.3159\n",
            "Epoch 9415/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.2005 - accuracy: 0.3231 - val_loss: 2.2025 - val_accuracy: 0.3159\n",
            "Epoch 9416/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2005 - accuracy: 0.3232 - val_loss: 2.2025 - val_accuracy: 0.3159\n",
            "Epoch 9417/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2005 - accuracy: 0.3232 - val_loss: 2.2024 - val_accuracy: 0.3160\n",
            "Epoch 9418/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2005 - accuracy: 0.3232 - val_loss: 2.2024 - val_accuracy: 0.3161\n",
            "Epoch 9419/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2005 - accuracy: 0.3232 - val_loss: 2.2024 - val_accuracy: 0.3161\n",
            "Epoch 9420/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2004 - accuracy: 0.3233 - val_loss: 2.2024 - val_accuracy: 0.3161\n",
            "Epoch 9421/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2004 - accuracy: 0.3233 - val_loss: 2.2024 - val_accuracy: 0.3161\n",
            "Epoch 9422/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2004 - accuracy: 0.3233 - val_loss: 2.2024 - val_accuracy: 0.3161\n",
            "Epoch 9423/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2004 - accuracy: 0.3234 - val_loss: 2.2024 - val_accuracy: 0.3161\n",
            "Epoch 9424/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.2004 - accuracy: 0.3234 - val_loss: 2.2024 - val_accuracy: 0.3161\n",
            "Epoch 9425/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2004 - accuracy: 0.3234 - val_loss: 2.2024 - val_accuracy: 0.3161\n",
            "Epoch 9426/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2004 - accuracy: 0.3235 - val_loss: 2.2024 - val_accuracy: 0.3161\n",
            "Epoch 9427/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2004 - accuracy: 0.3235 - val_loss: 2.2024 - val_accuracy: 0.3161\n",
            "Epoch 9428/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2004 - accuracy: 0.3235 - val_loss: 2.2024 - val_accuracy: 0.3161\n",
            "Epoch 9429/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2004 - accuracy: 0.3236 - val_loss: 2.2023 - val_accuracy: 0.3161\n",
            "Epoch 9430/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2004 - accuracy: 0.3236 - val_loss: 2.2023 - val_accuracy: 0.3161\n",
            "Epoch 9431/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2004 - accuracy: 0.3236 - val_loss: 2.2023 - val_accuracy: 0.3162\n",
            "Epoch 9432/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2003 - accuracy: 0.3237 - val_loss: 2.2023 - val_accuracy: 0.3163\n",
            "Epoch 9433/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2003 - accuracy: 0.3237 - val_loss: 2.2023 - val_accuracy: 0.3163\n",
            "Epoch 9434/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2003 - accuracy: 0.3237 - val_loss: 2.2023 - val_accuracy: 0.3163\n",
            "Epoch 9435/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2003 - accuracy: 0.3237 - val_loss: 2.2023 - val_accuracy: 0.3163\n",
            "Epoch 9436/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2003 - accuracy: 0.3237 - val_loss: 2.2023 - val_accuracy: 0.3163\n",
            "Epoch 9437/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2003 - accuracy: 0.3237 - val_loss: 2.2023 - val_accuracy: 0.3163\n",
            "Epoch 9438/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2003 - accuracy: 0.3237 - val_loss: 2.2023 - val_accuracy: 0.3163\n",
            "Epoch 9439/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2003 - accuracy: 0.3237 - val_loss: 2.2023 - val_accuracy: 0.3163\n",
            "Epoch 9440/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2003 - accuracy: 0.3238 - val_loss: 2.2022 - val_accuracy: 0.3163\n",
            "Epoch 9441/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2003 - accuracy: 0.3238 - val_loss: 2.2022 - val_accuracy: 0.3163\n",
            "Epoch 9442/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2003 - accuracy: 0.3238 - val_loss: 2.2022 - val_accuracy: 0.3164\n",
            "Epoch 9443/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2003 - accuracy: 0.3238 - val_loss: 2.2022 - val_accuracy: 0.3164\n",
            "Epoch 9444/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2002 - accuracy: 0.3239 - val_loss: 2.2022 - val_accuracy: 0.3164\n",
            "Epoch 9445/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2002 - accuracy: 0.3239 - val_loss: 2.2022 - val_accuracy: 0.3164\n",
            "Epoch 9446/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2002 - accuracy: 0.3239 - val_loss: 2.2022 - val_accuracy: 0.3164\n",
            "Epoch 9447/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2002 - accuracy: 0.3239 - val_loss: 2.2022 - val_accuracy: 0.3165\n",
            "Epoch 9448/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2002 - accuracy: 0.3240 - val_loss: 2.2022 - val_accuracy: 0.3165\n",
            "Epoch 9449/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2002 - accuracy: 0.3240 - val_loss: 2.2022 - val_accuracy: 0.3166\n",
            "Epoch 9450/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2002 - accuracy: 0.3240 - val_loss: 2.2022 - val_accuracy: 0.3167\n",
            "Epoch 9451/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2002 - accuracy: 0.3241 - val_loss: 2.2022 - val_accuracy: 0.3167\n",
            "Epoch 9452/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2002 - accuracy: 0.3241 - val_loss: 2.2021 - val_accuracy: 0.3168\n",
            "Epoch 9453/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2002 - accuracy: 0.3241 - val_loss: 2.2021 - val_accuracy: 0.3168\n",
            "Epoch 9454/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2002 - accuracy: 0.3241 - val_loss: 2.2021 - val_accuracy: 0.3168\n",
            "Epoch 9455/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2001 - accuracy: 0.3241 - val_loss: 2.2021 - val_accuracy: 0.3168\n",
            "Epoch 9456/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2001 - accuracy: 0.3241 - val_loss: 2.2021 - val_accuracy: 0.3169\n",
            "Epoch 9457/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2001 - accuracy: 0.3241 - val_loss: 2.2021 - val_accuracy: 0.3169\n",
            "Epoch 9458/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2001 - accuracy: 0.3242 - val_loss: 2.2021 - val_accuracy: 0.3171\n",
            "Epoch 9459/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2001 - accuracy: 0.3242 - val_loss: 2.2021 - val_accuracy: 0.3171\n",
            "Epoch 9460/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2001 - accuracy: 0.3243 - val_loss: 2.2021 - val_accuracy: 0.3171\n",
            "Epoch 9461/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2001 - accuracy: 0.3243 - val_loss: 2.2021 - val_accuracy: 0.3172\n",
            "Epoch 9462/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2001 - accuracy: 0.3243 - val_loss: 2.2021 - val_accuracy: 0.3172\n",
            "Epoch 9463/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2001 - accuracy: 0.3244 - val_loss: 2.2021 - val_accuracy: 0.3172\n",
            "Epoch 9464/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2001 - accuracy: 0.3244 - val_loss: 2.2020 - val_accuracy: 0.3172\n",
            "Epoch 9465/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2001 - accuracy: 0.3245 - val_loss: 2.2020 - val_accuracy: 0.3172\n",
            "Epoch 9466/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2001 - accuracy: 0.3245 - val_loss: 2.2020 - val_accuracy: 0.3172\n",
            "Epoch 9467/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2000 - accuracy: 0.3245 - val_loss: 2.2020 - val_accuracy: 0.3173\n",
            "Epoch 9468/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2000 - accuracy: 0.3246 - val_loss: 2.2020 - val_accuracy: 0.3173\n",
            "Epoch 9469/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2000 - accuracy: 0.3246 - val_loss: 2.2020 - val_accuracy: 0.3173\n",
            "Epoch 9470/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2000 - accuracy: 0.3246 - val_loss: 2.2020 - val_accuracy: 0.3173\n",
            "Epoch 9471/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2000 - accuracy: 0.3246 - val_loss: 2.2020 - val_accuracy: 0.3173\n",
            "Epoch 9472/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2000 - accuracy: 0.3246 - val_loss: 2.2020 - val_accuracy: 0.3173\n",
            "Epoch 9473/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2000 - accuracy: 0.3246 - val_loss: 2.2020 - val_accuracy: 0.3174\n",
            "Epoch 9474/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2000 - accuracy: 0.3247 - val_loss: 2.2020 - val_accuracy: 0.3175\n",
            "Epoch 9475/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2000 - accuracy: 0.3247 - val_loss: 2.2020 - val_accuracy: 0.3175\n",
            "Epoch 9476/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2000 - accuracy: 0.3247 - val_loss: 2.2019 - val_accuracy: 0.3176\n",
            "Epoch 9477/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2000 - accuracy: 0.3247 - val_loss: 2.2019 - val_accuracy: 0.3178\n",
            "Epoch 9478/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2000 - accuracy: 0.3247 - val_loss: 2.2019 - val_accuracy: 0.3179\n",
            "Epoch 9479/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1999 - accuracy: 0.3247 - val_loss: 2.2019 - val_accuracy: 0.3179\n",
            "Epoch 9480/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1999 - accuracy: 0.3247 - val_loss: 2.2019 - val_accuracy: 0.3179\n",
            "Epoch 9481/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1999 - accuracy: 0.3247 - val_loss: 2.2019 - val_accuracy: 0.3179\n",
            "Epoch 9482/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.1999 - accuracy: 0.3248 - val_loss: 2.2019 - val_accuracy: 0.3179\n",
            "Epoch 9483/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1999 - accuracy: 0.3248 - val_loss: 2.2019 - val_accuracy: 0.3179\n",
            "Epoch 9484/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1999 - accuracy: 0.3248 - val_loss: 2.2019 - val_accuracy: 0.3180\n",
            "Epoch 9485/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1999 - accuracy: 0.3248 - val_loss: 2.2019 - val_accuracy: 0.3180\n",
            "Epoch 9486/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1999 - accuracy: 0.3248 - val_loss: 2.2019 - val_accuracy: 0.3180\n",
            "Epoch 9487/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1999 - accuracy: 0.3249 - val_loss: 2.2019 - val_accuracy: 0.3180\n",
            "Epoch 9488/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1999 - accuracy: 0.3249 - val_loss: 2.2018 - val_accuracy: 0.3181\n",
            "Epoch 9489/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1999 - accuracy: 0.3249 - val_loss: 2.2018 - val_accuracy: 0.3181\n",
            "Epoch 9490/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1998 - accuracy: 0.3250 - val_loss: 2.2018 - val_accuracy: 0.3182\n",
            "Epoch 9491/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.1998 - accuracy: 0.3250 - val_loss: 2.2018 - val_accuracy: 0.3182\n",
            "Epoch 9492/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.1998 - accuracy: 0.3250 - val_loss: 2.2018 - val_accuracy: 0.3183\n",
            "Epoch 9493/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1998 - accuracy: 0.3250 - val_loss: 2.2018 - val_accuracy: 0.3184\n",
            "Epoch 9494/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1998 - accuracy: 0.3251 - val_loss: 2.2018 - val_accuracy: 0.3184\n",
            "Epoch 9495/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1998 - accuracy: 0.3251 - val_loss: 2.2018 - val_accuracy: 0.3184\n",
            "Epoch 9496/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1998 - accuracy: 0.3252 - val_loss: 2.2018 - val_accuracy: 0.3184\n",
            "Epoch 9497/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1998 - accuracy: 0.3252 - val_loss: 2.2018 - val_accuracy: 0.3184\n",
            "Epoch 9498/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1998 - accuracy: 0.3252 - val_loss: 2.2018 - val_accuracy: 0.3184\n",
            "Epoch 9499/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1998 - accuracy: 0.3252 - val_loss: 2.2017 - val_accuracy: 0.3185\n",
            "Epoch 9500/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1998 - accuracy: 0.3252 - val_loss: 2.2017 - val_accuracy: 0.3185\n",
            "Epoch 9501/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.1998 - accuracy: 0.3252 - val_loss: 2.2017 - val_accuracy: 0.3185\n",
            "Epoch 9502/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1997 - accuracy: 0.3252 - val_loss: 2.2017 - val_accuracy: 0.3185\n",
            "Epoch 9503/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1997 - accuracy: 0.3253 - val_loss: 2.2017 - val_accuracy: 0.3184\n",
            "Epoch 9504/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1997 - accuracy: 0.3253 - val_loss: 2.2017 - val_accuracy: 0.3184\n",
            "Epoch 9505/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1997 - accuracy: 0.3254 - val_loss: 2.2017 - val_accuracy: 0.3185\n",
            "Epoch 9506/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1997 - accuracy: 0.3254 - val_loss: 2.2017 - val_accuracy: 0.3186\n",
            "Epoch 9507/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1997 - accuracy: 0.3255 - val_loss: 2.2017 - val_accuracy: 0.3187\n",
            "Epoch 9508/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1997 - accuracy: 0.3255 - val_loss: 2.2017 - val_accuracy: 0.3187\n",
            "Epoch 9509/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1997 - accuracy: 0.3255 - val_loss: 2.2017 - val_accuracy: 0.3187\n",
            "Epoch 9510/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.1997 - accuracy: 0.3255 - val_loss: 2.2017 - val_accuracy: 0.3188\n",
            "Epoch 9511/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1997 - accuracy: 0.3255 - val_loss: 2.2016 - val_accuracy: 0.3189\n",
            "Epoch 9512/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1997 - accuracy: 0.3256 - val_loss: 2.2016 - val_accuracy: 0.3190\n",
            "Epoch 9513/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1997 - accuracy: 0.3257 - val_loss: 2.2016 - val_accuracy: 0.3190\n",
            "Epoch 9514/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1996 - accuracy: 0.3257 - val_loss: 2.2016 - val_accuracy: 0.3190\n",
            "Epoch 9515/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1996 - accuracy: 0.3257 - val_loss: 2.2016 - val_accuracy: 0.3190\n",
            "Epoch 9516/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1996 - accuracy: 0.3258 - val_loss: 2.2016 - val_accuracy: 0.3191\n",
            "Epoch 9517/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.1996 - accuracy: 0.3258 - val_loss: 2.2016 - val_accuracy: 0.3191\n",
            "Epoch 9518/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1996 - accuracy: 0.3258 - val_loss: 2.2016 - val_accuracy: 0.3191\n",
            "Epoch 9519/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1996 - accuracy: 0.3259 - val_loss: 2.2016 - val_accuracy: 0.3191\n",
            "Epoch 9520/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.1996 - accuracy: 0.3259 - val_loss: 2.2016 - val_accuracy: 0.3192\n",
            "Epoch 9521/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1996 - accuracy: 0.3259 - val_loss: 2.2016 - val_accuracy: 0.3192\n",
            "Epoch 9522/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1996 - accuracy: 0.3259 - val_loss: 2.2016 - val_accuracy: 0.3192\n",
            "Epoch 9523/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1996 - accuracy: 0.3260 - val_loss: 2.2015 - val_accuracy: 0.3193\n",
            "Epoch 9524/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1996 - accuracy: 0.3260 - val_loss: 2.2015 - val_accuracy: 0.3193\n",
            "Epoch 9525/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1996 - accuracy: 0.3261 - val_loss: 2.2015 - val_accuracy: 0.3193\n",
            "Epoch 9526/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1995 - accuracy: 0.3261 - val_loss: 2.2015 - val_accuracy: 0.3194\n",
            "Epoch 9527/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1995 - accuracy: 0.3262 - val_loss: 2.2015 - val_accuracy: 0.3194\n",
            "Epoch 9528/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1995 - accuracy: 0.3262 - val_loss: 2.2015 - val_accuracy: 0.3195\n",
            "Epoch 9529/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1995 - accuracy: 0.3262 - val_loss: 2.2015 - val_accuracy: 0.3195\n",
            "Epoch 9530/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.1995 - accuracy: 0.3262 - val_loss: 2.2015 - val_accuracy: 0.3195\n",
            "Epoch 9531/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1995 - accuracy: 0.3262 - val_loss: 2.2015 - val_accuracy: 0.3195\n",
            "Epoch 9532/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1995 - accuracy: 0.3262 - val_loss: 2.2015 - val_accuracy: 0.3195\n",
            "Epoch 9533/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1995 - accuracy: 0.3263 - val_loss: 2.2015 - val_accuracy: 0.3196\n",
            "Epoch 9534/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1995 - accuracy: 0.3263 - val_loss: 2.2015 - val_accuracy: 0.3196\n",
            "Epoch 9535/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1995 - accuracy: 0.3264 - val_loss: 2.2014 - val_accuracy: 0.3197\n",
            "Epoch 9536/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1995 - accuracy: 0.3264 - val_loss: 2.2014 - val_accuracy: 0.3197\n",
            "Epoch 9537/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1994 - accuracy: 0.3265 - val_loss: 2.2014 - val_accuracy: 0.3197\n",
            "Epoch 9538/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1994 - accuracy: 0.3265 - val_loss: 2.2014 - val_accuracy: 0.3197\n",
            "Epoch 9539/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.1994 - accuracy: 0.3266 - val_loss: 2.2014 - val_accuracy: 0.3197\n",
            "Epoch 9540/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.1994 - accuracy: 0.3266 - val_loss: 2.2014 - val_accuracy: 0.3198\n",
            "Epoch 9541/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1994 - accuracy: 0.3266 - val_loss: 2.2014 - val_accuracy: 0.3198\n",
            "Epoch 9542/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1994 - accuracy: 0.3266 - val_loss: 2.2014 - val_accuracy: 0.3198\n",
            "Epoch 9543/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1994 - accuracy: 0.3266 - val_loss: 2.2014 - val_accuracy: 0.3198\n",
            "Epoch 9544/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1994 - accuracy: 0.3266 - val_loss: 2.2014 - val_accuracy: 0.3199\n",
            "Epoch 9545/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1994 - accuracy: 0.3267 - val_loss: 2.2014 - val_accuracy: 0.3199\n",
            "Epoch 9546/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1994 - accuracy: 0.3267 - val_loss: 2.2014 - val_accuracy: 0.3201\n",
            "Epoch 9547/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1994 - accuracy: 0.3267 - val_loss: 2.2013 - val_accuracy: 0.3201\n",
            "Epoch 9548/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1994 - accuracy: 0.3268 - val_loss: 2.2013 - val_accuracy: 0.3202\n",
            "Epoch 9549/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.1993 - accuracy: 0.3268 - val_loss: 2.2013 - val_accuracy: 0.3202\n",
            "Epoch 9550/10000\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 2.1993 - accuracy: 0.3268 - val_loss: 2.2013 - val_accuracy: 0.3202\n",
            "Epoch 9551/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1993 - accuracy: 0.3268 - val_loss: 2.2013 - val_accuracy: 0.3202\n",
            "Epoch 9552/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1993 - accuracy: 0.3268 - val_loss: 2.2013 - val_accuracy: 0.3202\n",
            "Epoch 9553/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1993 - accuracy: 0.3268 - val_loss: 2.2013 - val_accuracy: 0.3202\n",
            "Epoch 9554/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1993 - accuracy: 0.3269 - val_loss: 2.2013 - val_accuracy: 0.3203\n",
            "Epoch 9555/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1993 - accuracy: 0.3270 - val_loss: 2.2013 - val_accuracy: 0.3203\n",
            "Epoch 9556/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.1993 - accuracy: 0.3270 - val_loss: 2.2013 - val_accuracy: 0.3204\n",
            "Epoch 9557/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1993 - accuracy: 0.3271 - val_loss: 2.2013 - val_accuracy: 0.3204\n",
            "Epoch 9558/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1993 - accuracy: 0.3271 - val_loss: 2.2013 - val_accuracy: 0.3204\n",
            "Epoch 9559/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.1993 - accuracy: 0.3271 - val_loss: 2.2012 - val_accuracy: 0.3204\n",
            "Epoch 9560/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1993 - accuracy: 0.3271 - val_loss: 2.2012 - val_accuracy: 0.3204\n",
            "Epoch 9561/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1992 - accuracy: 0.3272 - val_loss: 2.2012 - val_accuracy: 0.3204\n",
            "Epoch 9562/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1992 - accuracy: 0.3272 - val_loss: 2.2012 - val_accuracy: 0.3204\n",
            "Epoch 9563/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1992 - accuracy: 0.3272 - val_loss: 2.2012 - val_accuracy: 0.3204\n",
            "Epoch 9564/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1992 - accuracy: 0.3273 - val_loss: 2.2012 - val_accuracy: 0.3204\n",
            "Epoch 9565/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1992 - accuracy: 0.3273 - val_loss: 2.2012 - val_accuracy: 0.3205\n",
            "Epoch 9566/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1992 - accuracy: 0.3273 - val_loss: 2.2012 - val_accuracy: 0.3205\n",
            "Epoch 9567/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1992 - accuracy: 0.3273 - val_loss: 2.2012 - val_accuracy: 0.3205\n",
            "Epoch 9568/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.1992 - accuracy: 0.3274 - val_loss: 2.2012 - val_accuracy: 0.3206\n",
            "Epoch 9569/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1992 - accuracy: 0.3275 - val_loss: 2.2012 - val_accuracy: 0.3207\n",
            "Epoch 9570/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1992 - accuracy: 0.3275 - val_loss: 2.2012 - val_accuracy: 0.3207\n",
            "Epoch 9571/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1992 - accuracy: 0.3275 - val_loss: 2.2011 - val_accuracy: 0.3208\n",
            "Epoch 9572/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1992 - accuracy: 0.3276 - val_loss: 2.2011 - val_accuracy: 0.3208\n",
            "Epoch 9573/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1991 - accuracy: 0.3276 - val_loss: 2.2011 - val_accuracy: 0.3208\n",
            "Epoch 9574/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1991 - accuracy: 0.3276 - val_loss: 2.2011 - val_accuracy: 0.3208\n",
            "Epoch 9575/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1991 - accuracy: 0.3276 - val_loss: 2.2011 - val_accuracy: 0.3208\n",
            "Epoch 9576/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1991 - accuracy: 0.3276 - val_loss: 2.2011 - val_accuracy: 0.3208\n",
            "Epoch 9577/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1991 - accuracy: 0.3277 - val_loss: 2.2011 - val_accuracy: 0.3208\n",
            "Epoch 9578/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.1991 - accuracy: 0.3277 - val_loss: 2.2011 - val_accuracy: 0.3208\n",
            "Epoch 9579/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1991 - accuracy: 0.3277 - val_loss: 2.2011 - val_accuracy: 0.3208\n",
            "Epoch 9580/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1991 - accuracy: 0.3278 - val_loss: 2.2011 - val_accuracy: 0.3208\n",
            "Epoch 9581/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1991 - accuracy: 0.3278 - val_loss: 2.2011 - val_accuracy: 0.3207\n",
            "Epoch 9582/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1991 - accuracy: 0.3279 - val_loss: 2.2010 - val_accuracy: 0.3207\n",
            "Epoch 9583/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1991 - accuracy: 0.3279 - val_loss: 2.2010 - val_accuracy: 0.3207\n",
            "Epoch 9584/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1991 - accuracy: 0.3279 - val_loss: 2.2010 - val_accuracy: 0.3208\n",
            "Epoch 9585/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1990 - accuracy: 0.3280 - val_loss: 2.2010 - val_accuracy: 0.3209\n",
            "Epoch 9586/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1990 - accuracy: 0.3280 - val_loss: 2.2010 - val_accuracy: 0.3209\n",
            "Epoch 9587/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1990 - accuracy: 0.3280 - val_loss: 2.2010 - val_accuracy: 0.3209\n",
            "Epoch 9588/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.1990 - accuracy: 0.3280 - val_loss: 2.2010 - val_accuracy: 0.3209\n",
            "Epoch 9589/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1990 - accuracy: 0.3280 - val_loss: 2.2010 - val_accuracy: 0.3209\n",
            "Epoch 9590/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1990 - accuracy: 0.3281 - val_loss: 2.2010 - val_accuracy: 0.3209\n",
            "Epoch 9591/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1990 - accuracy: 0.3281 - val_loss: 2.2010 - val_accuracy: 0.3209\n",
            "Epoch 9592/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1990 - accuracy: 0.3281 - val_loss: 2.2010 - val_accuracy: 0.3209\n",
            "Epoch 9593/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1990 - accuracy: 0.3281 - val_loss: 2.2010 - val_accuracy: 0.3210\n",
            "Epoch 9594/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1990 - accuracy: 0.3282 - val_loss: 2.2009 - val_accuracy: 0.3210\n",
            "Epoch 9595/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1990 - accuracy: 0.3282 - val_loss: 2.2009 - val_accuracy: 0.3211\n",
            "Epoch 9596/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1989 - accuracy: 0.3282 - val_loss: 2.2009 - val_accuracy: 0.3211\n",
            "Epoch 9597/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.1989 - accuracy: 0.3282 - val_loss: 2.2009 - val_accuracy: 0.3211\n",
            "Epoch 9598/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1989 - accuracy: 0.3282 - val_loss: 2.2009 - val_accuracy: 0.3211\n",
            "Epoch 9599/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1989 - accuracy: 0.3283 - val_loss: 2.2009 - val_accuracy: 0.3211\n",
            "Epoch 9600/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1989 - accuracy: 0.3283 - val_loss: 2.2009 - val_accuracy: 0.3212\n",
            "Epoch 9601/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1989 - accuracy: 0.3283 - val_loss: 2.2009 - val_accuracy: 0.3212\n",
            "Epoch 9602/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1989 - accuracy: 0.3283 - val_loss: 2.2009 - val_accuracy: 0.3212\n",
            "Epoch 9603/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1989 - accuracy: 0.3284 - val_loss: 2.2009 - val_accuracy: 0.3213\n",
            "Epoch 9604/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.1989 - accuracy: 0.3284 - val_loss: 2.2009 - val_accuracy: 0.3213\n",
            "Epoch 9605/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1989 - accuracy: 0.3285 - val_loss: 2.2009 - val_accuracy: 0.3213\n",
            "Epoch 9606/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1989 - accuracy: 0.3285 - val_loss: 2.2008 - val_accuracy: 0.3213\n",
            "Epoch 9607/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.1989 - accuracy: 0.3285 - val_loss: 2.2008 - val_accuracy: 0.3214\n",
            "Epoch 9608/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1988 - accuracy: 0.3285 - val_loss: 2.2008 - val_accuracy: 0.3214\n",
            "Epoch 9609/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1988 - accuracy: 0.3285 - val_loss: 2.2008 - val_accuracy: 0.3215\n",
            "Epoch 9610/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1988 - accuracy: 0.3286 - val_loss: 2.2008 - val_accuracy: 0.3216\n",
            "Epoch 9611/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1988 - accuracy: 0.3286 - val_loss: 2.2008 - val_accuracy: 0.3217\n",
            "Epoch 9612/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1988 - accuracy: 0.3286 - val_loss: 2.2008 - val_accuracy: 0.3218\n",
            "Epoch 9613/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1988 - accuracy: 0.3286 - val_loss: 2.2008 - val_accuracy: 0.3219\n",
            "Epoch 9614/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1988 - accuracy: 0.3287 - val_loss: 2.2008 - val_accuracy: 0.3219\n",
            "Epoch 9615/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1988 - accuracy: 0.3288 - val_loss: 2.2008 - val_accuracy: 0.3219\n",
            "Epoch 9616/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.1988 - accuracy: 0.3288 - val_loss: 2.2008 - val_accuracy: 0.3220\n",
            "Epoch 9617/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1988 - accuracy: 0.3289 - val_loss: 2.2008 - val_accuracy: 0.3220\n",
            "Epoch 9618/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1988 - accuracy: 0.3289 - val_loss: 2.2007 - val_accuracy: 0.3220\n",
            "Epoch 9619/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1988 - accuracy: 0.3289 - val_loss: 2.2007 - val_accuracy: 0.3220\n",
            "Epoch 9620/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1987 - accuracy: 0.3289 - val_loss: 2.2007 - val_accuracy: 0.3221\n",
            "Epoch 9621/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.1987 - accuracy: 0.3290 - val_loss: 2.2007 - val_accuracy: 0.3221\n",
            "Epoch 9622/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1987 - accuracy: 0.3290 - val_loss: 2.2007 - val_accuracy: 0.3221\n",
            "Epoch 9623/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1987 - accuracy: 0.3290 - val_loss: 2.2007 - val_accuracy: 0.3221\n",
            "Epoch 9624/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1987 - accuracy: 0.3290 - val_loss: 2.2007 - val_accuracy: 0.3221\n",
            "Epoch 9625/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1987 - accuracy: 0.3291 - val_loss: 2.2007 - val_accuracy: 0.3221\n",
            "Epoch 9626/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.1987 - accuracy: 0.3291 - val_loss: 2.2007 - val_accuracy: 0.3221\n",
            "Epoch 9627/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1987 - accuracy: 0.3291 - val_loss: 2.2007 - val_accuracy: 0.3223\n",
            "Epoch 9628/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1987 - accuracy: 0.3291 - val_loss: 2.2007 - val_accuracy: 0.3224\n",
            "Epoch 9629/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1987 - accuracy: 0.3291 - val_loss: 2.2007 - val_accuracy: 0.3224\n",
            "Epoch 9630/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1987 - accuracy: 0.3291 - val_loss: 2.2006 - val_accuracy: 0.3224\n",
            "Epoch 9631/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1987 - accuracy: 0.3292 - val_loss: 2.2006 - val_accuracy: 0.3224\n",
            "Epoch 9632/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1986 - accuracy: 0.3292 - val_loss: 2.2006 - val_accuracy: 0.3224\n",
            "Epoch 9633/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1986 - accuracy: 0.3292 - val_loss: 2.2006 - val_accuracy: 0.3225\n",
            "Epoch 9634/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.1986 - accuracy: 0.3292 - val_loss: 2.2006 - val_accuracy: 0.3225\n",
            "Epoch 9635/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1986 - accuracy: 0.3292 - val_loss: 2.2006 - val_accuracy: 0.3225\n",
            "Epoch 9636/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.1986 - accuracy: 0.3292 - val_loss: 2.2006 - val_accuracy: 0.3225\n",
            "Epoch 9637/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1986 - accuracy: 0.3293 - val_loss: 2.2006 - val_accuracy: 0.3225\n",
            "Epoch 9638/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1986 - accuracy: 0.3293 - val_loss: 2.2006 - val_accuracy: 0.3226\n",
            "Epoch 9639/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1986 - accuracy: 0.3293 - val_loss: 2.2006 - val_accuracy: 0.3226\n",
            "Epoch 9640/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1986 - accuracy: 0.3293 - val_loss: 2.2006 - val_accuracy: 0.3226\n",
            "Epoch 9641/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1986 - accuracy: 0.3293 - val_loss: 2.2006 - val_accuracy: 0.3226\n",
            "Epoch 9642/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1986 - accuracy: 0.3293 - val_loss: 2.2005 - val_accuracy: 0.3226\n",
            "Epoch 9643/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1986 - accuracy: 0.3293 - val_loss: 2.2005 - val_accuracy: 0.3227\n",
            "Epoch 9644/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1985 - accuracy: 0.3294 - val_loss: 2.2005 - val_accuracy: 0.3227\n",
            "Epoch 9645/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.1985 - accuracy: 0.3294 - val_loss: 2.2005 - val_accuracy: 0.3227\n",
            "Epoch 9646/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1985 - accuracy: 0.3294 - val_loss: 2.2005 - val_accuracy: 0.3227\n",
            "Epoch 9647/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1985 - accuracy: 0.3295 - val_loss: 2.2005 - val_accuracy: 0.3229\n",
            "Epoch 9648/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1985 - accuracy: 0.3295 - val_loss: 2.2005 - val_accuracy: 0.3229\n",
            "Epoch 9649/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1985 - accuracy: 0.3295 - val_loss: 2.2005 - val_accuracy: 0.3229\n",
            "Epoch 9650/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.1985 - accuracy: 0.3296 - val_loss: 2.2005 - val_accuracy: 0.3229\n",
            "Epoch 9651/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1985 - accuracy: 0.3296 - val_loss: 2.2005 - val_accuracy: 0.3230\n",
            "Epoch 9652/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1985 - accuracy: 0.3296 - val_loss: 2.2005 - val_accuracy: 0.3230\n",
            "Epoch 9653/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1985 - accuracy: 0.3297 - val_loss: 2.2005 - val_accuracy: 0.3230\n",
            "Epoch 9654/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1985 - accuracy: 0.3297 - val_loss: 2.2004 - val_accuracy: 0.3230\n",
            "Epoch 9655/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.1985 - accuracy: 0.3297 - val_loss: 2.2004 - val_accuracy: 0.3230\n",
            "Epoch 9656/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1984 - accuracy: 0.3297 - val_loss: 2.2004 - val_accuracy: 0.3230\n",
            "Epoch 9657/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1984 - accuracy: 0.3297 - val_loss: 2.2004 - val_accuracy: 0.3230\n",
            "Epoch 9658/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.1984 - accuracy: 0.3298 - val_loss: 2.2004 - val_accuracy: 0.3230\n",
            "Epoch 9659/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1984 - accuracy: 0.3298 - val_loss: 2.2004 - val_accuracy: 0.3230\n",
            "Epoch 9660/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1984 - accuracy: 0.3298 - val_loss: 2.2004 - val_accuracy: 0.3230\n",
            "Epoch 9661/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1984 - accuracy: 0.3298 - val_loss: 2.2004 - val_accuracy: 0.3230\n",
            "Epoch 9662/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1984 - accuracy: 0.3298 - val_loss: 2.2004 - val_accuracy: 0.3230\n",
            "Epoch 9663/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1984 - accuracy: 0.3299 - val_loss: 2.2004 - val_accuracy: 0.3230\n",
            "Epoch 9664/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1984 - accuracy: 0.3299 - val_loss: 2.2004 - val_accuracy: 0.3230\n",
            "Epoch 9665/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.1984 - accuracy: 0.3300 - val_loss: 2.2004 - val_accuracy: 0.3230\n",
            "Epoch 9666/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1984 - accuracy: 0.3300 - val_loss: 2.2003 - val_accuracy: 0.3230\n",
            "Epoch 9667/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.1983 - accuracy: 0.3300 - val_loss: 2.2003 - val_accuracy: 0.3230\n",
            "Epoch 9668/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1983 - accuracy: 0.3300 - val_loss: 2.2003 - val_accuracy: 0.3232\n",
            "Epoch 9669/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1983 - accuracy: 0.3300 - val_loss: 2.2003 - val_accuracy: 0.3233\n",
            "Epoch 9670/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.1983 - accuracy: 0.3300 - val_loss: 2.2003 - val_accuracy: 0.3233\n",
            "Epoch 9671/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1983 - accuracy: 0.3300 - val_loss: 2.2003 - val_accuracy: 0.3233\n",
            "Epoch 9672/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1983 - accuracy: 0.3300 - val_loss: 2.2003 - val_accuracy: 0.3233\n",
            "Epoch 9673/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1983 - accuracy: 0.3301 - val_loss: 2.2003 - val_accuracy: 0.3234\n",
            "Epoch 9674/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.1983 - accuracy: 0.3301 - val_loss: 2.2003 - val_accuracy: 0.3236\n",
            "Epoch 9675/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1983 - accuracy: 0.3302 - val_loss: 2.2003 - val_accuracy: 0.3237\n",
            "Epoch 9676/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1983 - accuracy: 0.3302 - val_loss: 2.2003 - val_accuracy: 0.3237\n",
            "Epoch 9677/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1983 - accuracy: 0.3303 - val_loss: 2.2003 - val_accuracy: 0.3237\n",
            "Epoch 9678/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1983 - accuracy: 0.3303 - val_loss: 2.2002 - val_accuracy: 0.3237\n",
            "Epoch 9679/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1982 - accuracy: 0.3303 - val_loss: 2.2002 - val_accuracy: 0.3238\n",
            "Epoch 9680/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1982 - accuracy: 0.3303 - val_loss: 2.2002 - val_accuracy: 0.3238\n",
            "Epoch 9681/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1982 - accuracy: 0.3304 - val_loss: 2.2002 - val_accuracy: 0.3238\n",
            "Epoch 9682/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1982 - accuracy: 0.3304 - val_loss: 2.2002 - val_accuracy: 0.3238\n",
            "Epoch 9683/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1982 - accuracy: 0.3304 - val_loss: 2.2002 - val_accuracy: 0.3238\n",
            "Epoch 9684/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.1982 - accuracy: 0.3304 - val_loss: 2.2002 - val_accuracy: 0.3238\n",
            "Epoch 9685/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1982 - accuracy: 0.3304 - val_loss: 2.2002 - val_accuracy: 0.3238\n",
            "Epoch 9686/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1982 - accuracy: 0.3304 - val_loss: 2.2002 - val_accuracy: 0.3238\n",
            "Epoch 9687/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1982 - accuracy: 0.3304 - val_loss: 2.2002 - val_accuracy: 0.3238\n",
            "Epoch 9688/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1982 - accuracy: 0.3304 - val_loss: 2.2002 - val_accuracy: 0.3238\n",
            "Epoch 9689/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1982 - accuracy: 0.3305 - val_loss: 2.2002 - val_accuracy: 0.3239\n",
            "Epoch 9690/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1982 - accuracy: 0.3305 - val_loss: 2.2001 - val_accuracy: 0.3239\n",
            "Epoch 9691/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1981 - accuracy: 0.3306 - val_loss: 2.2001 - val_accuracy: 0.3239\n",
            "Epoch 9692/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1981 - accuracy: 0.3306 - val_loss: 2.2001 - val_accuracy: 0.3239\n",
            "Epoch 9693/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.1981 - accuracy: 0.3306 - val_loss: 2.2001 - val_accuracy: 0.3239\n",
            "Epoch 9694/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.1981 - accuracy: 0.3307 - val_loss: 2.2001 - val_accuracy: 0.3240\n",
            "Epoch 9695/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1981 - accuracy: 0.3307 - val_loss: 2.2001 - val_accuracy: 0.3240\n",
            "Epoch 9696/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1981 - accuracy: 0.3307 - val_loss: 2.2001 - val_accuracy: 0.3240\n",
            "Epoch 9697/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1981 - accuracy: 0.3307 - val_loss: 2.2001 - val_accuracy: 0.3240\n",
            "Epoch 9698/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1981 - accuracy: 0.3307 - val_loss: 2.2001 - val_accuracy: 0.3240\n",
            "Epoch 9699/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1981 - accuracy: 0.3307 - val_loss: 2.2001 - val_accuracy: 0.3240\n",
            "Epoch 9700/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1981 - accuracy: 0.3308 - val_loss: 2.2001 - val_accuracy: 0.3240\n",
            "Epoch 9701/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1981 - accuracy: 0.3308 - val_loss: 2.2001 - val_accuracy: 0.3240\n",
            "Epoch 9702/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1981 - accuracy: 0.3308 - val_loss: 2.2000 - val_accuracy: 0.3240\n",
            "Epoch 9703/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.1980 - accuracy: 0.3308 - val_loss: 2.2000 - val_accuracy: 0.3240\n",
            "Epoch 9704/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1980 - accuracy: 0.3308 - val_loss: 2.2000 - val_accuracy: 0.3240\n",
            "Epoch 9705/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1980 - accuracy: 0.3308 - val_loss: 2.2000 - val_accuracy: 0.3241\n",
            "Epoch 9706/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1980 - accuracy: 0.3309 - val_loss: 2.2000 - val_accuracy: 0.3241\n",
            "Epoch 9707/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1980 - accuracy: 0.3309 - val_loss: 2.2000 - val_accuracy: 0.3241\n",
            "Epoch 9708/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1980 - accuracy: 0.3309 - val_loss: 2.2000 - val_accuracy: 0.3241\n",
            "Epoch 9709/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1980 - accuracy: 0.3309 - val_loss: 2.2000 - val_accuracy: 0.3241\n",
            "Epoch 9710/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.1980 - accuracy: 0.3309 - val_loss: 2.2000 - val_accuracy: 0.3241\n",
            "Epoch 9711/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1980 - accuracy: 0.3309 - val_loss: 2.2000 - val_accuracy: 0.3241\n",
            "Epoch 9712/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.1980 - accuracy: 0.3309 - val_loss: 2.2000 - val_accuracy: 0.3242\n",
            "Epoch 9713/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.1980 - accuracy: 0.3310 - val_loss: 2.2000 - val_accuracy: 0.3242\n",
            "Epoch 9714/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1980 - accuracy: 0.3310 - val_loss: 2.1999 - val_accuracy: 0.3242\n",
            "Epoch 9715/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1979 - accuracy: 0.3311 - val_loss: 2.1999 - val_accuracy: 0.3242\n",
            "Epoch 9716/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1979 - accuracy: 0.3311 - val_loss: 2.1999 - val_accuracy: 0.3242\n",
            "Epoch 9717/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1979 - accuracy: 0.3311 - val_loss: 2.1999 - val_accuracy: 0.3242\n",
            "Epoch 9718/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1979 - accuracy: 0.3311 - val_loss: 2.1999 - val_accuracy: 0.3242\n",
            "Epoch 9719/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1979 - accuracy: 0.3311 - val_loss: 2.1999 - val_accuracy: 0.3242\n",
            "Epoch 9720/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1979 - accuracy: 0.3311 - val_loss: 2.1999 - val_accuracy: 0.3243\n",
            "Epoch 9721/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1979 - accuracy: 0.3311 - val_loss: 2.1999 - val_accuracy: 0.3243\n",
            "Epoch 9722/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.1979 - accuracy: 0.3312 - val_loss: 2.1999 - val_accuracy: 0.3243\n",
            "Epoch 9723/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1979 - accuracy: 0.3312 - val_loss: 2.1999 - val_accuracy: 0.3244\n",
            "Epoch 9724/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1979 - accuracy: 0.3312 - val_loss: 2.1999 - val_accuracy: 0.3244\n",
            "Epoch 9725/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1979 - accuracy: 0.3312 - val_loss: 2.1999 - val_accuracy: 0.3244\n",
            "Epoch 9726/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1979 - accuracy: 0.3313 - val_loss: 2.1998 - val_accuracy: 0.3245\n",
            "Epoch 9727/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1978 - accuracy: 0.3313 - val_loss: 2.1998 - val_accuracy: 0.3246\n",
            "Epoch 9728/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1978 - accuracy: 0.3314 - val_loss: 2.1998 - val_accuracy: 0.3248\n",
            "Epoch 9729/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1978 - accuracy: 0.3314 - val_loss: 2.1998 - val_accuracy: 0.3248\n",
            "Epoch 9730/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1978 - accuracy: 0.3314 - val_loss: 2.1998 - val_accuracy: 0.3249\n",
            "Epoch 9731/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1978 - accuracy: 0.3314 - val_loss: 2.1998 - val_accuracy: 0.3250\n",
            "Epoch 9732/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.1978 - accuracy: 0.3314 - val_loss: 2.1998 - val_accuracy: 0.3251\n",
            "Epoch 9733/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1978 - accuracy: 0.3315 - val_loss: 2.1998 - val_accuracy: 0.3251\n",
            "Epoch 9734/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1978 - accuracy: 0.3316 - val_loss: 2.1998 - val_accuracy: 0.3251\n",
            "Epoch 9735/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1978 - accuracy: 0.3316 - val_loss: 2.1998 - val_accuracy: 0.3251\n",
            "Epoch 9736/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1978 - accuracy: 0.3316 - val_loss: 2.1998 - val_accuracy: 0.3251\n",
            "Epoch 9737/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1978 - accuracy: 0.3316 - val_loss: 2.1998 - val_accuracy: 0.3252\n",
            "Epoch 9738/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1978 - accuracy: 0.3316 - val_loss: 2.1997 - val_accuracy: 0.3252\n",
            "Epoch 9739/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1977 - accuracy: 0.3316 - val_loss: 2.1997 - val_accuracy: 0.3252\n",
            "Epoch 9740/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1977 - accuracy: 0.3317 - val_loss: 2.1997 - val_accuracy: 0.3252\n",
            "Epoch 9741/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1977 - accuracy: 0.3317 - val_loss: 2.1997 - val_accuracy: 0.3252\n",
            "Epoch 9742/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.1977 - accuracy: 0.3317 - val_loss: 2.1997 - val_accuracy: 0.3252\n",
            "Epoch 9743/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1977 - accuracy: 0.3318 - val_loss: 2.1997 - val_accuracy: 0.3253\n",
            "Epoch 9744/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1977 - accuracy: 0.3318 - val_loss: 2.1997 - val_accuracy: 0.3253\n",
            "Epoch 9745/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1977 - accuracy: 0.3318 - val_loss: 2.1997 - val_accuracy: 0.3253\n",
            "Epoch 9746/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1977 - accuracy: 0.3318 - val_loss: 2.1997 - val_accuracy: 0.3253\n",
            "Epoch 9747/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1977 - accuracy: 0.3318 - val_loss: 2.1997 - val_accuracy: 0.3254\n",
            "Epoch 9748/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.1977 - accuracy: 0.3318 - val_loss: 2.1997 - val_accuracy: 0.3254\n",
            "Epoch 9749/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1977 - accuracy: 0.3319 - val_loss: 2.1997 - val_accuracy: 0.3254\n",
            "Epoch 9750/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1977 - accuracy: 0.3319 - val_loss: 2.1996 - val_accuracy: 0.3255\n",
            "Epoch 9751/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.1976 - accuracy: 0.3319 - val_loss: 2.1996 - val_accuracy: 0.3255\n",
            "Epoch 9752/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1976 - accuracy: 0.3319 - val_loss: 2.1996 - val_accuracy: 0.3256\n",
            "Epoch 9753/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1976 - accuracy: 0.3319 - val_loss: 2.1996 - val_accuracy: 0.3256\n",
            "Epoch 9754/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1976 - accuracy: 0.3319 - val_loss: 2.1996 - val_accuracy: 0.3256\n",
            "Epoch 9755/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1976 - accuracy: 0.3319 - val_loss: 2.1996 - val_accuracy: 0.3257\n",
            "Epoch 9756/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1976 - accuracy: 0.3320 - val_loss: 2.1996 - val_accuracy: 0.3258\n",
            "Epoch 9757/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1976 - accuracy: 0.3320 - val_loss: 2.1996 - val_accuracy: 0.3258\n",
            "Epoch 9758/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1976 - accuracy: 0.3320 - val_loss: 2.1996 - val_accuracy: 0.3258\n",
            "Epoch 9759/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1976 - accuracy: 0.3320 - val_loss: 2.1996 - val_accuracy: 0.3258\n",
            "Epoch 9760/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1976 - accuracy: 0.3321 - val_loss: 2.1996 - val_accuracy: 0.3258\n",
            "Epoch 9761/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.1976 - accuracy: 0.3321 - val_loss: 2.1996 - val_accuracy: 0.3260\n",
            "Epoch 9762/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1976 - accuracy: 0.3321 - val_loss: 2.1995 - val_accuracy: 0.3261\n",
            "Epoch 9763/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1975 - accuracy: 0.3321 - val_loss: 2.1995 - val_accuracy: 0.3261\n",
            "Epoch 9764/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1975 - accuracy: 0.3322 - val_loss: 2.1995 - val_accuracy: 0.3261\n",
            "Epoch 9765/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1975 - accuracy: 0.3322 - val_loss: 2.1995 - val_accuracy: 0.3261\n",
            "Epoch 9766/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1975 - accuracy: 0.3322 - val_loss: 2.1995 - val_accuracy: 0.3261\n",
            "Epoch 9767/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.1975 - accuracy: 0.3322 - val_loss: 2.1995 - val_accuracy: 0.3261\n",
            "Epoch 9768/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.1975 - accuracy: 0.3322 - val_loss: 2.1995 - val_accuracy: 0.3261\n",
            "Epoch 9769/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1975 - accuracy: 0.3322 - val_loss: 2.1995 - val_accuracy: 0.3261\n",
            "Epoch 9770/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.1975 - accuracy: 0.3323 - val_loss: 2.1995 - val_accuracy: 0.3262\n",
            "Epoch 9771/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1975 - accuracy: 0.3323 - val_loss: 2.1995 - val_accuracy: 0.3262\n",
            "Epoch 9772/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1975 - accuracy: 0.3323 - val_loss: 2.1995 - val_accuracy: 0.3263\n",
            "Epoch 9773/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1975 - accuracy: 0.3323 - val_loss: 2.1995 - val_accuracy: 0.3263\n",
            "Epoch 9774/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1975 - accuracy: 0.3323 - val_loss: 2.1994 - val_accuracy: 0.3263\n",
            "Epoch 9775/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1974 - accuracy: 0.3323 - val_loss: 2.1994 - val_accuracy: 0.3263\n",
            "Epoch 9776/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1974 - accuracy: 0.3324 - val_loss: 2.1994 - val_accuracy: 0.3263\n",
            "Epoch 9777/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1974 - accuracy: 0.3324 - val_loss: 2.1994 - val_accuracy: 0.3263\n",
            "Epoch 9778/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1974 - accuracy: 0.3324 - val_loss: 2.1994 - val_accuracy: 0.3263\n",
            "Epoch 9779/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1974 - accuracy: 0.3324 - val_loss: 2.1994 - val_accuracy: 0.3263\n",
            "Epoch 9780/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.1974 - accuracy: 0.3325 - val_loss: 2.1994 - val_accuracy: 0.3263\n",
            "Epoch 9781/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1974 - accuracy: 0.3325 - val_loss: 2.1994 - val_accuracy: 0.3263\n",
            "Epoch 9782/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1974 - accuracy: 0.3326 - val_loss: 2.1994 - val_accuracy: 0.3263\n",
            "Epoch 9783/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1974 - accuracy: 0.3326 - val_loss: 2.1994 - val_accuracy: 0.3263\n",
            "Epoch 9784/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1974 - accuracy: 0.3326 - val_loss: 2.1994 - val_accuracy: 0.3263\n",
            "Epoch 9785/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1974 - accuracy: 0.3326 - val_loss: 2.1994 - val_accuracy: 0.3263\n",
            "Epoch 9786/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.1974 - accuracy: 0.3326 - val_loss: 2.1993 - val_accuracy: 0.3263\n",
            "Epoch 9787/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1973 - accuracy: 0.3326 - val_loss: 2.1993 - val_accuracy: 0.3263\n",
            "Epoch 9788/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1973 - accuracy: 0.3327 - val_loss: 2.1993 - val_accuracy: 0.3263\n",
            "Epoch 9789/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1973 - accuracy: 0.3327 - val_loss: 2.1993 - val_accuracy: 0.3263\n",
            "Epoch 9790/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.1973 - accuracy: 0.3327 - val_loss: 2.1993 - val_accuracy: 0.3263\n",
            "Epoch 9791/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1973 - accuracy: 0.3327 - val_loss: 2.1993 - val_accuracy: 0.3263\n",
            "Epoch 9792/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1973 - accuracy: 0.3328 - val_loss: 2.1993 - val_accuracy: 0.3263\n",
            "Epoch 9793/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1973 - accuracy: 0.3328 - val_loss: 2.1993 - val_accuracy: 0.3264\n",
            "Epoch 9794/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1973 - accuracy: 0.3329 - val_loss: 2.1993 - val_accuracy: 0.3264\n",
            "Epoch 9795/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1973 - accuracy: 0.3329 - val_loss: 2.1993 - val_accuracy: 0.3264\n",
            "Epoch 9796/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1973 - accuracy: 0.3329 - val_loss: 2.1993 - val_accuracy: 0.3264\n",
            "Epoch 9797/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1973 - accuracy: 0.3329 - val_loss: 2.1993 - val_accuracy: 0.3264\n",
            "Epoch 9798/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1973 - accuracy: 0.3329 - val_loss: 2.1992 - val_accuracy: 0.3264\n",
            "Epoch 9799/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.1972 - accuracy: 0.3329 - val_loss: 2.1992 - val_accuracy: 0.3264\n",
            "Epoch 9800/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1972 - accuracy: 0.3330 - val_loss: 2.1992 - val_accuracy: 0.3264\n",
            "Epoch 9801/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1972 - accuracy: 0.3330 - val_loss: 2.1992 - val_accuracy: 0.3264\n",
            "Epoch 9802/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1972 - accuracy: 0.3330 - val_loss: 2.1992 - val_accuracy: 0.3264\n",
            "Epoch 9803/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1972 - accuracy: 0.3330 - val_loss: 2.1992 - val_accuracy: 0.3264\n",
            "Epoch 9804/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1972 - accuracy: 0.3331 - val_loss: 2.1992 - val_accuracy: 0.3264\n",
            "Epoch 9805/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1972 - accuracy: 0.3331 - val_loss: 2.1992 - val_accuracy: 0.3264\n",
            "Epoch 9806/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1972 - accuracy: 0.3331 - val_loss: 2.1992 - val_accuracy: 0.3264\n",
            "Epoch 9807/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1972 - accuracy: 0.3332 - val_loss: 2.1992 - val_accuracy: 0.3265\n",
            "Epoch 9808/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1972 - accuracy: 0.3332 - val_loss: 2.1992 - val_accuracy: 0.3265\n",
            "Epoch 9809/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.1972 - accuracy: 0.3332 - val_loss: 2.1992 - val_accuracy: 0.3265\n",
            "Epoch 9810/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1972 - accuracy: 0.3332 - val_loss: 2.1991 - val_accuracy: 0.3265\n",
            "Epoch 9811/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1971 - accuracy: 0.3333 - val_loss: 2.1991 - val_accuracy: 0.3266\n",
            "Epoch 9812/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1971 - accuracy: 0.3333 - val_loss: 2.1991 - val_accuracy: 0.3266\n",
            "Epoch 9813/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1971 - accuracy: 0.3333 - val_loss: 2.1991 - val_accuracy: 0.3267\n",
            "Epoch 9814/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1971 - accuracy: 0.3334 - val_loss: 2.1991 - val_accuracy: 0.3267\n",
            "Epoch 9815/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1971 - accuracy: 0.3334 - val_loss: 2.1991 - val_accuracy: 0.3268\n",
            "Epoch 9816/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1971 - accuracy: 0.3334 - val_loss: 2.1991 - val_accuracy: 0.3268\n",
            "Epoch 9817/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1971 - accuracy: 0.3335 - val_loss: 2.1991 - val_accuracy: 0.3268\n",
            "Epoch 9818/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.1971 - accuracy: 0.3335 - val_loss: 2.1991 - val_accuracy: 0.3268\n",
            "Epoch 9819/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1971 - accuracy: 0.3336 - val_loss: 2.1991 - val_accuracy: 0.3268\n",
            "Epoch 9820/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1971 - accuracy: 0.3336 - val_loss: 2.1991 - val_accuracy: 0.3268\n",
            "Epoch 9821/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1971 - accuracy: 0.3336 - val_loss: 2.1991 - val_accuracy: 0.3268\n",
            "Epoch 9822/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1971 - accuracy: 0.3336 - val_loss: 2.1990 - val_accuracy: 0.3268\n",
            "Epoch 9823/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1970 - accuracy: 0.3336 - val_loss: 2.1990 - val_accuracy: 0.3268\n",
            "Epoch 9824/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1970 - accuracy: 0.3337 - val_loss: 2.1990 - val_accuracy: 0.3268\n",
            "Epoch 9825/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1970 - accuracy: 0.3337 - val_loss: 2.1990 - val_accuracy: 0.3268\n",
            "Epoch 9826/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1970 - accuracy: 0.3337 - val_loss: 2.1990 - val_accuracy: 0.3268\n",
            "Epoch 9827/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1970 - accuracy: 0.3338 - val_loss: 2.1990 - val_accuracy: 0.3269\n",
            "Epoch 9828/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.1970 - accuracy: 0.3339 - val_loss: 2.1990 - val_accuracy: 0.3270\n",
            "Epoch 9829/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.1970 - accuracy: 0.3339 - val_loss: 2.1990 - val_accuracy: 0.3271\n",
            "Epoch 9830/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1970 - accuracy: 0.3340 - val_loss: 2.1990 - val_accuracy: 0.3271\n",
            "Epoch 9831/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1970 - accuracy: 0.3340 - val_loss: 2.1990 - val_accuracy: 0.3271\n",
            "Epoch 9832/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1970 - accuracy: 0.3340 - val_loss: 2.1990 - val_accuracy: 0.3271\n",
            "Epoch 9833/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1970 - accuracy: 0.3340 - val_loss: 2.1990 - val_accuracy: 0.3271\n",
            "Epoch 9834/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1970 - accuracy: 0.3340 - val_loss: 2.1989 - val_accuracy: 0.3272\n",
            "Epoch 9835/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1969 - accuracy: 0.3341 - val_loss: 2.1989 - val_accuracy: 0.3272\n",
            "Epoch 9836/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1969 - accuracy: 0.3342 - val_loss: 2.1989 - val_accuracy: 0.3273\n",
            "Epoch 9837/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1969 - accuracy: 0.3342 - val_loss: 2.1989 - val_accuracy: 0.3273\n",
            "Epoch 9838/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.1969 - accuracy: 0.3342 - val_loss: 2.1989 - val_accuracy: 0.3273\n",
            "Epoch 9839/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1969 - accuracy: 0.3342 - val_loss: 2.1989 - val_accuracy: 0.3273\n",
            "Epoch 9840/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1969 - accuracy: 0.3342 - val_loss: 2.1989 - val_accuracy: 0.3273\n",
            "Epoch 9841/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1969 - accuracy: 0.3342 - val_loss: 2.1989 - val_accuracy: 0.3273\n",
            "Epoch 9842/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1969 - accuracy: 0.3342 - val_loss: 2.1989 - val_accuracy: 0.3273\n",
            "Epoch 9843/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1969 - accuracy: 0.3343 - val_loss: 2.1989 - val_accuracy: 0.3274\n",
            "Epoch 9844/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1969 - accuracy: 0.3343 - val_loss: 2.1989 - val_accuracy: 0.3275\n",
            "Epoch 9845/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1969 - accuracy: 0.3343 - val_loss: 2.1989 - val_accuracy: 0.3276\n",
            "Epoch 9846/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1969 - accuracy: 0.3343 - val_loss: 2.1988 - val_accuracy: 0.3277\n",
            "Epoch 9847/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.1968 - accuracy: 0.3343 - val_loss: 2.1988 - val_accuracy: 0.3277\n",
            "Epoch 9848/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1968 - accuracy: 0.3344 - val_loss: 2.1988 - val_accuracy: 0.3277\n",
            "Epoch 9849/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1968 - accuracy: 0.3344 - val_loss: 2.1988 - val_accuracy: 0.3277\n",
            "Epoch 9850/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1968 - accuracy: 0.3344 - val_loss: 2.1988 - val_accuracy: 0.3277\n",
            "Epoch 9851/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1968 - accuracy: 0.3345 - val_loss: 2.1988 - val_accuracy: 0.3277\n",
            "Epoch 9852/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1968 - accuracy: 0.3345 - val_loss: 2.1988 - val_accuracy: 0.3277\n",
            "Epoch 9853/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1968 - accuracy: 0.3345 - val_loss: 2.1988 - val_accuracy: 0.3277\n",
            "Epoch 9854/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1968 - accuracy: 0.3345 - val_loss: 2.1988 - val_accuracy: 0.3277\n",
            "Epoch 9855/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1968 - accuracy: 0.3345 - val_loss: 2.1988 - val_accuracy: 0.3277\n",
            "Epoch 9856/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1968 - accuracy: 0.3345 - val_loss: 2.1988 - val_accuracy: 0.3277\n",
            "Epoch 9857/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.1968 - accuracy: 0.3345 - val_loss: 2.1988 - val_accuracy: 0.3277\n",
            "Epoch 9858/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1968 - accuracy: 0.3345 - val_loss: 2.1988 - val_accuracy: 0.3277\n",
            "Epoch 9859/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1967 - accuracy: 0.3346 - val_loss: 2.1987 - val_accuracy: 0.3278\n",
            "Epoch 9860/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1967 - accuracy: 0.3346 - val_loss: 2.1987 - val_accuracy: 0.3278\n",
            "Epoch 9861/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1967 - accuracy: 0.3346 - val_loss: 2.1987 - val_accuracy: 0.3279\n",
            "Epoch 9862/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1967 - accuracy: 0.3347 - val_loss: 2.1987 - val_accuracy: 0.3280\n",
            "Epoch 9863/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1967 - accuracy: 0.3347 - val_loss: 2.1987 - val_accuracy: 0.3280\n",
            "Epoch 9864/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1967 - accuracy: 0.3347 - val_loss: 2.1987 - val_accuracy: 0.3280\n",
            "Epoch 9865/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1967 - accuracy: 0.3347 - val_loss: 2.1987 - val_accuracy: 0.3280\n",
            "Epoch 9866/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.1967 - accuracy: 0.3347 - val_loss: 2.1987 - val_accuracy: 0.3280\n",
            "Epoch 9867/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1967 - accuracy: 0.3347 - val_loss: 2.1987 - val_accuracy: 0.3280\n",
            "Epoch 9868/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1967 - accuracy: 0.3348 - val_loss: 2.1987 - val_accuracy: 0.3281\n",
            "Epoch 9869/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1967 - accuracy: 0.3348 - val_loss: 2.1987 - val_accuracy: 0.3281\n",
            "Epoch 9870/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1967 - accuracy: 0.3348 - val_loss: 2.1987 - val_accuracy: 0.3282\n",
            "Epoch 9871/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1966 - accuracy: 0.3348 - val_loss: 2.1986 - val_accuracy: 0.3282\n",
            "Epoch 9872/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1966 - accuracy: 0.3348 - val_loss: 2.1986 - val_accuracy: 0.3283\n",
            "Epoch 9873/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1966 - accuracy: 0.3348 - val_loss: 2.1986 - val_accuracy: 0.3284\n",
            "Epoch 9874/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1966 - accuracy: 0.3349 - val_loss: 2.1986 - val_accuracy: 0.3284\n",
            "Epoch 9875/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1966 - accuracy: 0.3350 - val_loss: 2.1986 - val_accuracy: 0.3284\n",
            "Epoch 9876/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.1966 - accuracy: 0.3350 - val_loss: 2.1986 - val_accuracy: 0.3285\n",
            "Epoch 9877/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.1966 - accuracy: 0.3350 - val_loss: 2.1986 - val_accuracy: 0.3286\n",
            "Epoch 9878/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1966 - accuracy: 0.3350 - val_loss: 2.1986 - val_accuracy: 0.3286\n",
            "Epoch 9879/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1966 - accuracy: 0.3350 - val_loss: 2.1986 - val_accuracy: 0.3288\n",
            "Epoch 9880/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1966 - accuracy: 0.3350 - val_loss: 2.1986 - val_accuracy: 0.3288\n",
            "Epoch 9881/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1966 - accuracy: 0.3350 - val_loss: 2.1986 - val_accuracy: 0.3288\n",
            "Epoch 9882/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1966 - accuracy: 0.3351 - val_loss: 2.1986 - val_accuracy: 0.3288\n",
            "Epoch 9883/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1965 - accuracy: 0.3351 - val_loss: 2.1985 - val_accuracy: 0.3288\n",
            "Epoch 9884/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1965 - accuracy: 0.3351 - val_loss: 2.1985 - val_accuracy: 0.3288\n",
            "Epoch 9885/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1965 - accuracy: 0.3351 - val_loss: 2.1985 - val_accuracy: 0.3287\n",
            "Epoch 9886/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.1965 - accuracy: 0.3351 - val_loss: 2.1985 - val_accuracy: 0.3287\n",
            "Epoch 9887/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1965 - accuracy: 0.3352 - val_loss: 2.1985 - val_accuracy: 0.3287\n",
            "Epoch 9888/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.1965 - accuracy: 0.3352 - val_loss: 2.1985 - val_accuracy: 0.3287\n",
            "Epoch 9889/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1965 - accuracy: 0.3352 - val_loss: 2.1985 - val_accuracy: 0.3287\n",
            "Epoch 9890/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1965 - accuracy: 0.3353 - val_loss: 2.1985 - val_accuracy: 0.3287\n",
            "Epoch 9891/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1965 - accuracy: 0.3353 - val_loss: 2.1985 - val_accuracy: 0.3287\n",
            "Epoch 9892/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1965 - accuracy: 0.3353 - val_loss: 2.1985 - val_accuracy: 0.3287\n",
            "Epoch 9893/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.1965 - accuracy: 0.3353 - val_loss: 2.1985 - val_accuracy: 0.3287\n",
            "Epoch 9894/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1965 - accuracy: 0.3354 - val_loss: 2.1985 - val_accuracy: 0.3287\n",
            "Epoch 9895/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.1964 - accuracy: 0.3354 - val_loss: 2.1984 - val_accuracy: 0.3287\n",
            "Epoch 9896/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1964 - accuracy: 0.3354 - val_loss: 2.1984 - val_accuracy: 0.3288\n",
            "Epoch 9897/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1964 - accuracy: 0.3355 - val_loss: 2.1984 - val_accuracy: 0.3288\n",
            "Epoch 9898/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1964 - accuracy: 0.3355 - val_loss: 2.1984 - val_accuracy: 0.3289\n",
            "Epoch 9899/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1964 - accuracy: 0.3354 - val_loss: 2.1984 - val_accuracy: 0.3289\n",
            "Epoch 9900/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1964 - accuracy: 0.3356 - val_loss: 2.1984 - val_accuracy: 0.3290\n",
            "Epoch 9901/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1964 - accuracy: 0.3356 - val_loss: 2.1984 - val_accuracy: 0.3291\n",
            "Epoch 9902/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1964 - accuracy: 0.3356 - val_loss: 2.1984 - val_accuracy: 0.3292\n",
            "Epoch 9903/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1964 - accuracy: 0.3356 - val_loss: 2.1984 - val_accuracy: 0.3293\n",
            "Epoch 9904/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1964 - accuracy: 0.3356 - val_loss: 2.1984 - val_accuracy: 0.3293\n",
            "Epoch 9905/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.1964 - accuracy: 0.3356 - val_loss: 2.1984 - val_accuracy: 0.3293\n",
            "Epoch 9906/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.1964 - accuracy: 0.3356 - val_loss: 2.1984 - val_accuracy: 0.3293\n",
            "Epoch 9907/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.1963 - accuracy: 0.3357 - val_loss: 2.1983 - val_accuracy: 0.3293\n",
            "Epoch 9908/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1963 - accuracy: 0.3357 - val_loss: 2.1983 - val_accuracy: 0.3293\n",
            "Epoch 9909/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1963 - accuracy: 0.3357 - val_loss: 2.1983 - val_accuracy: 0.3293\n",
            "Epoch 9910/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1963 - accuracy: 0.3357 - val_loss: 2.1983 - val_accuracy: 0.3293\n",
            "Epoch 9911/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1963 - accuracy: 0.3358 - val_loss: 2.1983 - val_accuracy: 0.3294\n",
            "Epoch 9912/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1963 - accuracy: 0.3358 - val_loss: 2.1983 - val_accuracy: 0.3294\n",
            "Epoch 9913/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1963 - accuracy: 0.3358 - val_loss: 2.1983 - val_accuracy: 0.3294\n",
            "Epoch 9914/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.1963 - accuracy: 0.3358 - val_loss: 2.1983 - val_accuracy: 0.3294\n",
            "Epoch 9915/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1963 - accuracy: 0.3359 - val_loss: 2.1983 - val_accuracy: 0.3294\n",
            "Epoch 9916/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1963 - accuracy: 0.3359 - val_loss: 2.1983 - val_accuracy: 0.3294\n",
            "Epoch 9917/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.1963 - accuracy: 0.3359 - val_loss: 2.1983 - val_accuracy: 0.3295\n",
            "Epoch 9918/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1963 - accuracy: 0.3360 - val_loss: 2.1983 - val_accuracy: 0.3295\n",
            "Epoch 9919/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1962 - accuracy: 0.3360 - val_loss: 2.1982 - val_accuracy: 0.3295\n",
            "Epoch 9920/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1962 - accuracy: 0.3360 - val_loss: 2.1982 - val_accuracy: 0.3295\n",
            "Epoch 9921/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1962 - accuracy: 0.3361 - val_loss: 2.1982 - val_accuracy: 0.3295\n",
            "Epoch 9922/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1962 - accuracy: 0.3361 - val_loss: 2.1982 - val_accuracy: 0.3296\n",
            "Epoch 9923/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1962 - accuracy: 0.3361 - val_loss: 2.1982 - val_accuracy: 0.3296\n",
            "Epoch 9924/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.1962 - accuracy: 0.3362 - val_loss: 2.1982 - val_accuracy: 0.3296\n",
            "Epoch 9925/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1962 - accuracy: 0.3362 - val_loss: 2.1982 - val_accuracy: 0.3295\n",
            "Epoch 9926/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.1962 - accuracy: 0.3362 - val_loss: 2.1982 - val_accuracy: 0.3295\n",
            "Epoch 9927/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.1962 - accuracy: 0.3363 - val_loss: 2.1982 - val_accuracy: 0.3295\n",
            "Epoch 9928/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1962 - accuracy: 0.3363 - val_loss: 2.1982 - val_accuracy: 0.3296\n",
            "Epoch 9929/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1962 - accuracy: 0.3363 - val_loss: 2.1982 - val_accuracy: 0.3297\n",
            "Epoch 9930/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1962 - accuracy: 0.3363 - val_loss: 2.1982 - val_accuracy: 0.3297\n",
            "Epoch 9931/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1961 - accuracy: 0.3363 - val_loss: 2.1981 - val_accuracy: 0.3297\n",
            "Epoch 9932/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.1961 - accuracy: 0.3363 - val_loss: 2.1981 - val_accuracy: 0.3298\n",
            "Epoch 9933/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1961 - accuracy: 0.3363 - val_loss: 2.1981 - val_accuracy: 0.3298\n",
            "Epoch 9934/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.1961 - accuracy: 0.3363 - val_loss: 2.1981 - val_accuracy: 0.3298\n",
            "Epoch 9935/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1961 - accuracy: 0.3364 - val_loss: 2.1981 - val_accuracy: 0.3299\n",
            "Epoch 9936/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1961 - accuracy: 0.3364 - val_loss: 2.1981 - val_accuracy: 0.3299\n",
            "Epoch 9937/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1961 - accuracy: 0.3364 - val_loss: 2.1981 - val_accuracy: 0.3299\n",
            "Epoch 9938/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1961 - accuracy: 0.3364 - val_loss: 2.1981 - val_accuracy: 0.3299\n",
            "Epoch 9939/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1961 - accuracy: 0.3365 - val_loss: 2.1981 - val_accuracy: 0.3299\n",
            "Epoch 9940/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1961 - accuracy: 0.3365 - val_loss: 2.1981 - val_accuracy: 0.3298\n",
            "Epoch 9941/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1961 - accuracy: 0.3365 - val_loss: 2.1981 - val_accuracy: 0.3298\n",
            "Epoch 9942/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1961 - accuracy: 0.3366 - val_loss: 2.1981 - val_accuracy: 0.3299\n",
            "Epoch 9943/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.1960 - accuracy: 0.3366 - val_loss: 2.1981 - val_accuracy: 0.3300\n",
            "Epoch 9944/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1960 - accuracy: 0.3366 - val_loss: 2.1980 - val_accuracy: 0.3301\n",
            "Epoch 9945/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1960 - accuracy: 0.3366 - val_loss: 2.1980 - val_accuracy: 0.3301\n",
            "Epoch 9946/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1960 - accuracy: 0.3367 - val_loss: 2.1980 - val_accuracy: 0.3301\n",
            "Epoch 9947/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1960 - accuracy: 0.3368 - val_loss: 2.1980 - val_accuracy: 0.3301\n",
            "Epoch 9948/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1960 - accuracy: 0.3368 - val_loss: 2.1980 - val_accuracy: 0.3301\n",
            "Epoch 9949/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1960 - accuracy: 0.3368 - val_loss: 2.1980 - val_accuracy: 0.3301\n",
            "Epoch 9950/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1960 - accuracy: 0.3368 - val_loss: 2.1980 - val_accuracy: 0.3301\n",
            "Epoch 9951/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1960 - accuracy: 0.3368 - val_loss: 2.1980 - val_accuracy: 0.3301\n",
            "Epoch 9952/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1960 - accuracy: 0.3368 - val_loss: 2.1980 - val_accuracy: 0.3301\n",
            "Epoch 9953/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.1960 - accuracy: 0.3369 - val_loss: 2.1980 - val_accuracy: 0.3301\n",
            "Epoch 9954/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1960 - accuracy: 0.3369 - val_loss: 2.1980 - val_accuracy: 0.3301\n",
            "Epoch 9955/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1959 - accuracy: 0.3369 - val_loss: 2.1980 - val_accuracy: 0.3301\n",
            "Epoch 9956/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1959 - accuracy: 0.3369 - val_loss: 2.1979 - val_accuracy: 0.3301\n",
            "Epoch 9957/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1959 - accuracy: 0.3369 - val_loss: 2.1979 - val_accuracy: 0.3301\n",
            "Epoch 9958/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1959 - accuracy: 0.3369 - val_loss: 2.1979 - val_accuracy: 0.3301\n",
            "Epoch 9959/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1959 - accuracy: 0.3369 - val_loss: 2.1979 - val_accuracy: 0.3302\n",
            "Epoch 9960/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1959 - accuracy: 0.3369 - val_loss: 2.1979 - val_accuracy: 0.3303\n",
            "Epoch 9961/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1959 - accuracy: 0.3369 - val_loss: 2.1979 - val_accuracy: 0.3304\n",
            "Epoch 9962/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.1959 - accuracy: 0.3370 - val_loss: 2.1979 - val_accuracy: 0.3304\n",
            "Epoch 9963/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1959 - accuracy: 0.3370 - val_loss: 2.1979 - val_accuracy: 0.3304\n",
            "Epoch 9964/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.1959 - accuracy: 0.3370 - val_loss: 2.1979 - val_accuracy: 0.3304\n",
            "Epoch 9965/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1959 - accuracy: 0.3371 - val_loss: 2.1979 - val_accuracy: 0.3304\n",
            "Epoch 9966/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1959 - accuracy: 0.3371 - val_loss: 2.1979 - val_accuracy: 0.3304\n",
            "Epoch 9967/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1958 - accuracy: 0.3371 - val_loss: 2.1979 - val_accuracy: 0.3304\n",
            "Epoch 9968/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1958 - accuracy: 0.3370 - val_loss: 2.1978 - val_accuracy: 0.3304\n",
            "Epoch 9969/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1958 - accuracy: 0.3371 - val_loss: 2.1978 - val_accuracy: 0.3303\n",
            "Epoch 9970/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1958 - accuracy: 0.3371 - val_loss: 2.1978 - val_accuracy: 0.3303\n",
            "Epoch 9971/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1958 - accuracy: 0.3371 - val_loss: 2.1978 - val_accuracy: 0.3303\n",
            "Epoch 9972/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.1958 - accuracy: 0.3372 - val_loss: 2.1978 - val_accuracy: 0.3303\n",
            "Epoch 9973/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1958 - accuracy: 0.3372 - val_loss: 2.1978 - val_accuracy: 0.3303\n",
            "Epoch 9974/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1958 - accuracy: 0.3372 - val_loss: 2.1978 - val_accuracy: 0.3304\n",
            "Epoch 9975/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1958 - accuracy: 0.3373 - val_loss: 2.1978 - val_accuracy: 0.3304\n",
            "Epoch 9976/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1958 - accuracy: 0.3373 - val_loss: 2.1978 - val_accuracy: 0.3304\n",
            "Epoch 9977/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1958 - accuracy: 0.3374 - val_loss: 2.1978 - val_accuracy: 0.3304\n",
            "Epoch 9978/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1958 - accuracy: 0.3374 - val_loss: 2.1978 - val_accuracy: 0.3303\n",
            "Epoch 9979/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1957 - accuracy: 0.3374 - val_loss: 2.1978 - val_accuracy: 0.3303\n",
            "Epoch 9980/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1957 - accuracy: 0.3374 - val_loss: 2.1977 - val_accuracy: 0.3304\n",
            "Epoch 9981/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1957 - accuracy: 0.3375 - val_loss: 2.1977 - val_accuracy: 0.3304\n",
            "Epoch 9982/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.1957 - accuracy: 0.3376 - val_loss: 2.1977 - val_accuracy: 0.3304\n",
            "Epoch 9983/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.1957 - accuracy: 0.3376 - val_loss: 2.1977 - val_accuracy: 0.3304\n",
            "Epoch 9984/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1957 - accuracy: 0.3376 - val_loss: 2.1977 - val_accuracy: 0.3304\n",
            "Epoch 9985/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1957 - accuracy: 0.3377 - val_loss: 2.1977 - val_accuracy: 0.3305\n",
            "Epoch 9986/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.1957 - accuracy: 0.3377 - val_loss: 2.1977 - val_accuracy: 0.3305\n",
            "Epoch 9987/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1957 - accuracy: 0.3377 - val_loss: 2.1977 - val_accuracy: 0.3305\n",
            "Epoch 9988/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1957 - accuracy: 0.3378 - val_loss: 2.1977 - val_accuracy: 0.3306\n",
            "Epoch 9989/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1957 - accuracy: 0.3378 - val_loss: 2.1977 - val_accuracy: 0.3307\n",
            "Epoch 9990/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1957 - accuracy: 0.3379 - val_loss: 2.1977 - val_accuracy: 0.3307\n",
            "Epoch 9991/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.1957 - accuracy: 0.3379 - val_loss: 2.1977 - val_accuracy: 0.3308\n",
            "Epoch 9992/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1956 - accuracy: 0.3379 - val_loss: 2.1977 - val_accuracy: 0.3308\n",
            "Epoch 9993/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1956 - accuracy: 0.3380 - val_loss: 2.1976 - val_accuracy: 0.3309\n",
            "Epoch 9994/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1956 - accuracy: 0.3380 - val_loss: 2.1976 - val_accuracy: 0.3309\n",
            "Epoch 9995/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1956 - accuracy: 0.3380 - val_loss: 2.1976 - val_accuracy: 0.3309\n",
            "Epoch 9996/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1956 - accuracy: 0.3380 - val_loss: 2.1976 - val_accuracy: 0.3309\n",
            "Epoch 9997/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.1956 - accuracy: 0.3381 - val_loss: 2.1976 - val_accuracy: 0.3309\n",
            "Epoch 9998/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1956 - accuracy: 0.3381 - val_loss: 2.1976 - val_accuracy: 0.3309\n",
            "Epoch 9999/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.1956 - accuracy: 0.3381 - val_loss: 2.1976 - val_accuracy: 0.3309\n",
            "Epoch 10000/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1956 - accuracy: 0.3381 - val_loss: 2.1976 - val_accuracy: 0.3311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiWLPdwhwQHR",
        "colab_type": "code",
        "outputId": "7a69bae5-f767-45c1-de19-82332bb5d3f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Visualization code here... \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Network Training')\n",
        "plt.ylabel('Cost Function')\n",
        "plt.xlabel('Number of Iterations')\n",
        "plt.legend(['Train', 'Test'], loc='upper right')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGO1fzoRf6yw",
        "colab_type": "text"
      },
      "source": [
        "## [30 points] Exercise 3 - PyTorch et al are friends not food!\n",
        "\n",
        "This exercises mirrors the prior approaches taken in **Exercise 1** and **Exercise 2** except written with PyTorch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpJxX0fsgM_8",
        "colab_type": "text"
      },
      "source": [
        "### (a) (10 points) Design the nn module\n",
        "\n",
        "Re-create the neural network structure within _PyTorch_'s `nn` module.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dzZJRA5gL15",
        "colab_type": "code",
        "outputId": "1c99ce45-df81-4f6e-fc7f-6a42bb910cd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchsummary import summary \n",
        "# Detect if a GPU is present with CUDA support\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {} \n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.h1 = nn.Linear(784, 64)\n",
        "    w1 = he_initializer(self.h1.weight.shape[1], self.h1.weight.shape[0]) #he normal initialization\n",
        "    w1 = torch.from_numpy(w1).float().to(device)\n",
        "    self.h1.weight.data = w1 # apply weights to layer\n",
        "\n",
        "    self.h2 = nn.Linear(64, 10)\n",
        "    w2 = he_initializer(self.h2.weight.shape[1], self.h2.weight.shape[0]) #he normal initialization\n",
        "    w2 = torch.from_numpy(w2).float().to(device)\n",
        "    self.h2.weight.data = w2 # apply weights to layer\n",
        "  \n",
        "  def forward(self, x):\n",
        "\n",
        "    x = self.h1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.h2(x)\n",
        "    x = torch.sigmoid(x)\n",
        "    output = F.log_softmax(x, dim = 1)\n",
        "    return output\n",
        "  \n",
        "model = Net().to(device)\n",
        "summary(model, (60000, 784))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1            [-1, 60000, 64]          50,240\n",
            "            Linear-2            [-1, 60000, 10]             650\n",
            "================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 179.44\n",
            "Forward/backward pass size (MB): 33.87\n",
            "Params size (MB): 0.19\n",
            "Estimated Total Size (MB): 213.51\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UkjcSS1gVu2",
        "colab_type": "text"
      },
      "source": [
        "### (b) (10 points) Training and Test functions\n",
        "\n",
        "Wrap the `nn` module work into two functions that cover the training period and the testing behavior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlRpo5EppRw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.FashionMNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])\n",
        "                   ),\n",
        "    batch_size=60000, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.FashionMNIST('../data', train=False, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])\n",
        "                   ),\n",
        "    batch_size=10000, shuffle=True, **kwargs)\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    data = torch.flatten(data, 1)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = F.nll_loss(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  np_loss = loss.cpu().detach().numpy()\n",
        "  if epoch % 100 == 0:\n",
        "    print(f'Epoch: {epoch} - Loss: {loss}')\n",
        "  return np_loss\n",
        "\n",
        "def test(model, device, test_loader, epoch):\n",
        "  # Set model to evaluation mode\n",
        "  model.eval()\n",
        "  # Initialize variables\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  # Perform computation with gradient disabled\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      # Load data on device\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      data = torch.flatten(data, 1)\n",
        "      # Feed the network test data\n",
        "      output = model(data)\n",
        "      # Sum up batch loss\n",
        "      test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "      # Get the index of the max log-probability\n",
        "      pred = output.argmax(dim = 1, keepdim = True)\n",
        "      # Count number of correct classifications\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "  \n",
        "  # Compute test loss\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  if epoch % 100 == 0:\n",
        "    print(f'\\nEpoch: {epoch}',\n",
        "          f'Test set: Loss: {test_loss:.4f}',\n",
        "          f'Accuracy: {correct}/{len(test_loader.dataset)}',\n",
        "          f'({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
        "  return test_loss\n",
        "  \n",
        "optimizer = optim.SGD(model.parameters(), lr = 1e-4)\n",
        "epochs = 1000 # 1000 epochs because training is much, much slower..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuts3jeagayi",
        "colab_type": "text"
      },
      "source": [
        "### (b) (10 points) Model fit and visualization\n",
        "\n",
        "Fit the model and show the visualization results. \n",
        "\n",
        "Please construct a visual graph yourself for this exercise. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp1-k9Z_u1kJ",
        "colab_type": "code",
        "outputId": "8b3f4b4f-086c-42ce-8b73-3d8d6c6e7f7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "train_losses = np.zeros(1000)\n",
        "test_losses = np.zeros(1000)\n",
        "for epoch in range(epochs): \n",
        "\n",
        "  loss = train(model, device, train_loader, optimizer, epoch)\n",
        "  train_losses[epoch] = loss\n",
        "  test_loss = test(model, device, test_loader, epoch)\n",
        "  test_losses[epoch] = test_loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 - Loss: 2.3362956047058105\n",
            "\n",
            "Epoch: 0 Test set: Loss: 2.3353 Accuracy: 1299/10000 (13%)\n",
            "\n",
            "Epoch: 100 - Loss: 2.330995559692383\n",
            "\n",
            "Epoch: 100 Test set: Loss: 2.3300 Accuracy: 1335/10000 (13%)\n",
            "\n",
            "Epoch: 200 - Loss: 2.325589179992676\n",
            "\n",
            "Epoch: 200 Test set: Loss: 2.3247 Accuracy: 1367/10000 (14%)\n",
            "\n",
            "Epoch: 300 - Loss: 2.3200671672821045\n",
            "\n",
            "Epoch: 300 Test set: Loss: 2.3192 Accuracy: 1410/10000 (14%)\n",
            "\n",
            "Epoch: 400 - Loss: 2.3144164085388184\n",
            "\n",
            "Epoch: 400 Test set: Loss: 2.3136 Accuracy: 1442/10000 (14%)\n",
            "\n",
            "Epoch: 500 - Loss: 2.308633804321289\n",
            "\n",
            "Epoch: 500 Test set: Loss: 2.3079 Accuracy: 1493/10000 (15%)\n",
            "\n",
            "Epoch: 600 - Loss: 2.302722930908203\n",
            "\n",
            "Epoch: 600 Test set: Loss: 2.3020 Accuracy: 1528/10000 (15%)\n",
            "\n",
            "Epoch: 700 - Loss: 2.2966935634613037\n",
            "\n",
            "Epoch: 700 Test set: Loss: 2.2961 Accuracy: 1569/10000 (16%)\n",
            "\n",
            "Epoch: 800 - Loss: 2.290560722351074\n",
            "\n",
            "Epoch: 800 Test set: Loss: 2.2900 Accuracy: 1610/10000 (16%)\n",
            "\n",
            "Epoch: 900 - Loss: 2.28434681892395\n",
            "\n",
            "Epoch: 900 Test set: Loss: 2.2838 Accuracy: 1645/10000 (16%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R613YOAyR7LC",
        "colab_type": "code",
        "outputId": "62509087-3791-481f-ccd0-84a9a6c093d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(np.arange(1000), train_losses, color = 'blue', label = 'Training Loss')\n",
        "plt.plot(np.arange(1000), test_losses, color = 'red', label = 'Test Loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}